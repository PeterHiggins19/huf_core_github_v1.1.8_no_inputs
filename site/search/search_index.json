{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Higgins Unity Framework (HUF) \u2014 Documentation","text":"<p>This site is meant to help you run HUF first, then learn the rest in small steps.</p>"},{"location":"#start-here","title":"Start here","text":"<ul> <li>\u2705 Beginner (no GitHub knowledge required): Get Started (Zero GitHub)</li> <li>\u25b6\ufe0f Copy/paste demo runner: Quick Run</li> <li>Recommended reading order: Learning Path</li> <li>Download data (Markham + Toronto): Data Sources &amp; Fetching</li> <li>\u25b6\ufe0f Run examples (\u201ccases\u201d): Cases</li> <li>Fix common problems: Troubleshooting</li> </ul>"},{"location":"#long-tail-accounting-lens","title":"Long tail (accounting lens)","text":"<p>Not ML class imbalance: here \u201clong tail\u201d means mass distribution + exception reweighting (baseline vs filtered view). Start here: Long tail (accounting lens)</p>"},{"location":"#what-is-huf","title":"What is HUF?","text":"<ul> <li>What is the Higgins Unity Framework?</li> </ul>"},{"location":"#for-developers","title":"For developers","text":"<ul> <li>Start Here (Developer)</li> <li>Reference Manual</li> <li>Theory Notes (optional)</li> <li>GitHub for Beginners</li> </ul>"},{"location":"The_Higgins_Unity_Framework/","title":"The Higgins Unity Framework (HUF)","text":"<p>This project is the HUF Core implementation: a practical toolkit you can run to turn messy real\u2011world datasets into consistent, comparable outputs.</p> <p>If you\u2019re not technical, don\u2019t worry \u2014 you can still use HUF by following the step\u2011by\u2011step guides.</p>"},{"location":"The_Higgins_Unity_Framework/#plainenglish-idea","title":"Plain\u2011English idea","text":"<p>Real systems produce lots of different signals:</p> <ul> <li>budgets, traffic timing, anomalies, logs, counts, categories\u2026</li> <li>all with different units, scales, and missing values</li> </ul> <p>HUF\u2019s core trick is to convert those signals into a normalized representation so that:</p> <ul> <li>different sources can be compared fairly</li> <li>changes over time are easier to detect</li> <li>\u201cwhat matters most\u201d can be ranked without hand\u2011tuning every dataset</li> </ul> <p>In this repo, that \u201cnormalization\u201d mostly shows up as:</p> <ul> <li>cleaning inputs</li> <li>mapping columns into a consistent schema</li> <li>producing standardized outputs you can analyze or visualize</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#what-you-get-from-this-repository","title":"What you get from this repository","text":"<ul> <li>Repeatable demos (\u201ccases\u201d) with real civic datasets (Markham + Toronto)</li> <li>A command line tool (<code>huf ...</code>) to run those cases</li> <li>A structure you can copy to add your own data adapters and cases</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#key-concepts-no-math","title":"Key concepts (no math)","text":""},{"location":"The_Higgins_Unity_Framework/#1-inputs-adapters-outputs","title":"1) Inputs \u2192 adapters \u2192 outputs","text":"<p>A \u201ccase\u201d takes some input file(s), runs a transformation, and writes results to an output folder.</p> <ul> <li>Input examples: <code>.xlsx</code>, <code>.csv</code>, large datasets (Planck is guided/manual)</li> <li>Output examples: cleaned tables, normalized metrics, reports</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#2-normalization-the-unity-idea","title":"2) Normalization (the \u201cunity\u201d idea)","text":"<p>Normalization means turning different kinds of numbers into a consistent scale so they can be compared.</p> <p>Example: - Dataset A ranges from 0\u201310 - Dataset B ranges from 0\u201310,000</p> <p>After normalization, both can live on the same scale, so ranking and anomaly detection are meaningful.</p>"},{"location":"The_Higgins_Unity_Framework/#3-cases-are-learning-modules","title":"3) \u201cCases\u201d are learning modules","text":"<p>Each case is both: - a working example you can run today - a template you can copy when adding your own workflow</p>"},{"location":"The_Higgins_Unity_Framework/#where-to-begin","title":"Where to begin","text":"<ol> <li>Follow the beginner path: Learning Path </li> <li>Run a demo: Cases </li> <li>If you hit errors: Troubleshooting</li> </ol>"},{"location":"The_Higgins_Unity_Framework/#advanced-theory-optional","title":"Advanced / theory (optional)","text":"<p>Some HUF writings discuss deeper mathematics (categories, morphisms, topology, etc.). Those are not required to run the tools in this repo.</p> <p>If you want the deeper background, start with: - Theory Notes - Handbook</p>"},{"location":"The_Higgins_Unity_Framework/#glossary","title":"Glossary","text":"<ul> <li>Case: a runnable example workflow (input \u2192 process \u2192 output).</li> <li>Adapter: code that reads a particular dataset shape and maps it into HUF\u2019s expected schema.</li> <li>Normalization: converting values into a consistent scale to compare across sources.</li> <li>Schema: the column names / fields that HUF expects for a given workflow.</li> </ul> <p>Note: The original author notes and drafts existed as <code>.Markdown</code>. This repo now keeps documentation in Markdown (<code>.md</code>) so it renders well on GitHub and GitHub Pages.</p>"},{"location":"cases/","title":"Included cases","text":"<p>These cases are ready-to-run from a fresh clone.</p>"},{"location":"cases/#quick-commands-windows-powershell","title":"Quick commands (Windows PowerShell)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n\n.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"cases/#two-minute-long-tail-demo","title":"Two-minute long-tail demo","text":"<pre><code>.\\.venv\\Scripts\\python scripts/run_long_tail_demo.py --status \"Green Termination\"\n</code></pre> <p>Look for:</p> <ul> <li><code>PROOF: items_to_cover_90pct 37 -&gt; 12</code> (example)</li> </ul>"},{"location":"cases/#traffic-phase-vs-traffic-anomaly-accounting-lens","title":"Traffic Phase vs Traffic Anomaly (accounting lens)","text":"<p>Not ML class imbalance: here \u201clong tail\u201d means mass distribution + exception reweighting (baseline vs filtered view).</p> <p>Full explainer: - Long tail (accounting lens)</p>"},{"location":"cli_huf_reference/","title":"CLI: HUF command lists, labels, terminology","text":"<p>This page is a \u201csingle place\u201d to answer: - what commands exist, - what files they expect, - what artifacts they emit, - and what words mean (regime, \u03c4, active set\u2026).</p>"},{"location":"cli_huf_reference/#run-commands-in-the-shell-powershell-not-inside-python","title":"Run commands in the shell (PowerShell), not inside Python","text":"<p>If your prompt looks like this:</p> <ul> <li><code>&gt;&gt;&gt;</code></li> </ul> <p>\u2026you are inside the Python REPL. Shell commands like <code>huf ...</code> will fail with <code>SyntaxError</code>.</p> <p>Exit back to PowerShell:</p> <ul> <li>type <code>exit()</code> or</li> <li>press Ctrl+Z then Enter</li> </ul> <p>Then run commands like:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"cli_huf_reference/#windowsconda-rule-copypaste-reliability","title":"Windows/Conda rule (copy/paste reliability)","text":"<p>After the repo venv exists, always run tools via the repo executables:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>For file paths inside commands and docs, prefer forward slashes: - \u2705 <code>scripts/fetch_data.py</code> - \u2705 <code>cases/traffic_phase/inputs/...</code> - Only use backslashes for the venv executables: <code>.\\.venv\\Scripts\\python</code></p>"},{"location":"cli_huf_reference/#discover-commands-dont-guess","title":"Discover commands (don\u2019t guess)","text":"<p>Canonical command lists come from <code>--help</code>:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n.\\.venv\\Scripts\\huf traffic --help\n.\\.venv\\Scripts\\huf traffic-anomaly --help\n</code></pre> <p>If a flag name differs between versions, trust <code>--help</code> over any doc page.</p>"},{"location":"cli_huf_reference/#planck-guide-windows","title":"Planck guide (Windows)","text":"<p>There is no <code>make</code> on Windows. Print the Planck download guide like this:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>Then run Planck after placing the FITS and installing <code>astropy</code> in the same venv:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n.\\.venv\\Scripts\\huf planck --fits \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\" --out out/planck70 --retained-target 0.97 --nside-out 64\n</code></pre>"},{"location":"cli_huf_reference/#output-artifacts-the-contract","title":"Output artifacts (the contract)","text":"<p>Every valid HUF run emits the \u201ccontract artifacts\u201d in the run output folder:</p> <ul> <li><code>artifact_1_coherence_map.csv</code> \u2014 \u201cWhere the budget went\u201d by regime (ranked)</li> <li><code>artifact_2_active_set.csv</code> \u2014 retained items with global + local shares</li> <li><code>artifact_3_trace_report.jsonl</code> \u2014 line-by-line trace records (provenance)</li> <li><code>artifact_4_error_budget.json</code> \u2014 explicit discarded budget + diagnostics</li> </ul> <p>If any of these are missing, treat the run as non-auditable.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome \u2014 even small things like typo fixes or \u201cthis step confused me\u201d issues help a lot.</p>"},{"location":"contributing/#the-easiest-ways-to-help","title":"The easiest ways to help","text":"<ol> <li>Open an Issue (best for feedback / questions)</li> <li>Describe what you tried, what happened, and what you expected.</li> <li> <p>If it\u2019s about a command, paste the exact command + the terminal output.</p> </li> <li> <p>Send a Pull Request</p> </li> <li>Fork the repo \u2192 create a branch \u2192 make changes \u2192 open a PR.</li> <li>Docs-only PRs are totally fine (they\u2019re often the most valuable).</li> </ol>"},{"location":"contributing/#suggested-contribution-ideas","title":"Suggested contribution ideas","text":"<ul> <li>Add a small new \u201cworked example\u201d page for a dataset you care about</li> <li>Improve Windows copy/paste reliability</li> <li>Add tiny helper scripts (inspect artifacts, sanity checks, etc.)</li> </ul>"},{"location":"contributing/#repo-settings-that-help-contributors","title":"Repo settings that help contributors","text":"<ul> <li>Issues: Enabled</li> <li>Pull requests from forks: Enabled</li> <li>Branch protection (optional): require CI checks on <code>main</code></li> </ul> <p>The canonical contributor guidance lives in the root CONTRIBUTING.md in the repo.</p>"},{"location":"data_sources/","title":"Data Sources &amp; Fetching","text":"<p>This repo ships small inputs for Markham and Toronto via <code>scripts/fetch_data.py</code>. Planck is guide-only because the file is large.</p>"},{"location":"data_sources/#fetch-markham-toronto-inputs","title":"Fetch Markham + Toronto inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>If you haven't created the venv yet:</p> <pre><code>python scripts/bootstrap.py\n</code></pre>"},{"location":"data_sources/#docs-preview","title":"Docs preview","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"get_started_readme/","title":"HUF Get Started Package","text":"<p>Open Start_Here.md or Start_Here.md.</p> <ul> <li>If you already have the HUF GitHub package, run the start scripts in the repo root:</li> <li>Windows: <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: <code>START_HERE_MAC.command</code></li> <li>Linux: <code>start_here_linux.sh</code></li> </ul> <p>This package does not include large input datasets. Data sources and instructions are in <code>docs/data_sources.md</code>.</p>"},{"location":"get_started_zero_github/","title":"Start Here (Zero GitHub Knowledge)","text":"<p>You can run HUF without learning command-line git. The goal is:</p> <ul> <li>you can run <code>.\\.venv\\Scripts\\huf --help</code></li> <li>you can produce <code>out/.../run_stamp.json</code></li> </ul>"},{"location":"get_started_zero_github/#option-1-easiest-recommended-the-one-click-starter","title":"Option 1 \u2014 easiest (recommended): the one-click starter","text":"<p>From the repo folder:</p> <ul> <li>Windows: double-click <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: right-click <code>START_HERE_MAC.command</code> \u2192 Open</li> <li>Linux: <code>./start_here_linux.sh</code></li> </ul> <p>This creates a local <code>.venv</code> and installs what you need.</p>"},{"location":"get_started_zero_github/#option-2-manual-windows-powershell","title":"Option 2 \u2014 manual (Windows PowerShell)","text":"<p>From the repo root:</p>"},{"location":"get_started_zero_github/#1-create-a-repo-virtual-environment","title":"1) Create a repo virtual environment","text":"<pre><code>python -m venv .venv\n.\\.venv\\Scripts\\python -m pip install --upgrade pip setuptools wheel\n.\\.venv\\Scripts\\python -m pip install -e \".[dev]\"\n</code></pre>"},{"location":"get_started_zero_github/#2-fetch-the-civic-inputs-markham-toronto","title":"2) Fetch the civic inputs (Markham + Toronto)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"get_started_zero_github/#3-run-the-demo-cases","title":"3) Run the demo cases","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"get_started_zero_github/#4-preview-the-docs-locally-optional","title":"4) Preview the docs locally (optional)","text":"<p>Always run MkDocs through the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"get_started_zero_github/#important-windows-note-slashes","title":"Important Windows note: slashes","text":"<ul> <li>Use forward slashes for file paths in docs and commands: <code>scripts/fetch_data.py</code>, <code>cases/...</code>, <code>out/...</code></li> <li>Use backslashes only for the venv executables: <code>.\\.venv\\Scripts\\python</code>, <code>.\\.venv\\Scripts\\huf</code></li> </ul>"},{"location":"github_for_beginners/","title":"GitHub for HUF (Beginner, GUI-first)","text":"<p>This is a plain-language guide to using HUF on GitHub with minimal jargon.</p>"},{"location":"github_for_beginners/#the-easiest-way-github-desktop-point-and-click","title":"The easiest way: GitHub Desktop (point-and-click)","text":"<ol> <li>Install GitHub Desktop</li> <li>Clone the repository</li> <li>Run the one-click starter scripts</li> </ol> <p>Then fetch data:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>Run a demo:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"gui_quickstart/","title":"GUI Quickstart (non\u2011GitHub\u2011native users)","text":"<p>This page is for people who prefer GUI workflows (e.g., GitHub Desktop, file explorers, Word/Excel) but still want to run HUF and keep record copies.</p>"},{"location":"gui_quickstart/#note","title":"Note","text":"<p>This docs-only package does not include the code/CLI. To run HUF, download the GitHub package release as well.</p>"},{"location":"gui_quickstart/#what-you-can-do-without-git","title":"What you can do without Git","text":"<p>If you don\u2019t want Git at all:</p> <ol> <li>Download the latest release ZIP from GitHub (look for Releases on the right side of the repo page).</li> <li>Unzip it to a folder like <code>Documents/HUF/</code>.</li> <li>Open the Markdown record copies in <code>docs/</code>:</li> <li><code>docs/handbook.md</code></li> <li><code>docs/reference_manual.md</code></li> <li><code>docs/data_sources.md</code></li> </ol> <p>You can still run the CLI from this unzipped folder (see below).</p>"},{"location":"gui_quickstart/#using-github-desktop-recommended-for-updates","title":"Using GitHub Desktop (recommended for updates)","text":"<p>If you want one-click updates:</p> <ol> <li>Install GitHub Desktop.</li> <li>In GitHub Desktop: File \u2192 Clone repository\u2026</li> <li>Pick a local folder (e.g., <code>Documents/GitHub/huf-core</code>).</li> <li>To update later: press Fetch origin then Pull origin.</li> </ol>"},{"location":"gui_quickstart/#one-time-setup-to-run-huf","title":"One-time setup to run HUF","text":"<p>You need Python 3.10+ installed.</p>"},{"location":"gui_quickstart/#step-1-open-a-terminal-in-the-repo-folder","title":"Step 1 \u2014 Open a terminal in the repo folder","text":"<ul> <li>Windows: open File Explorer \u2192 go to the repo folder \u2192 right\u2011click \u2192 Open in Terminal (or PowerShell).</li> <li>macOS: Finder \u2192 repo folder \u2192 right\u2011click \u2192 New Terminal at Folder (or open Terminal and <code>cd</code>).</li> <li>Linux: open Terminal and <code>cd</code> into the folder.</li> </ul>"},{"location":"gui_quickstart/#step-2-run-the-bootstrap-crossplatform","title":"Step 2 \u2014 Run the bootstrap (cross\u2011platform)","text":"<p>From the repo root:</p> <pre><code>python scripts/bootstrap.py\n</code></pre> <p>This creates <code>.venv/</code> and installs everything you need.</p> <p>If you\u2019re on macOS/Linux you can also use: <code>make bootstrap</code></p>"},{"location":"gui_quickstart/#download-the-real-input-data-no-big-inputs-are-bundled","title":"Download the real input data (no big inputs are bundled)","text":""},{"location":"gui_quickstart/#markham-toronto-automatic","title":"Markham + Toronto (automatic)","text":"<p>After bootstrap, run one of these:</p> <pre><code>make fetch-data\n# or:\npython scripts/fetch_data.py --markham --toronto\n</code></pre>"},{"location":"gui_quickstart/#toronto-non-interactive-yes","title":"Toronto non-interactive (<code>--yes</code>)","text":"<p>For scripted demos (no prompts):</p> <pre><code>make fetch-toronto-yes\n# or:\npython scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"gui_quickstart/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<p>Planck files are large, so HUF prints the steps instead of downloading by default:</p> <pre><code>make planck-guide\n# or:\npython scripts/fetch_data.py --planck-guide\n</code></pre>"},{"location":"gui_quickstart/#run-the-demos","title":"Run the demos","text":""},{"location":"gui_quickstart/#markham","title":"Markham","text":"<pre><code>huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018 --tau-global 0.005 --tau-local 0.02\n</code></pre>"},{"location":"gui_quickstart/#toronto-traffic","title":"Toronto traffic","text":"<pre><code>huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase --tau-local 0.05\n</code></pre>"},{"location":"gui_quickstart/#where-outputs-go","title":"Where outputs go","text":"<p>Each run writes a folder like <code>out/markham2018/</code> or <code>out/traffic_phase/</code> containing the mandatory artifacts:</p> <ul> <li><code>artifact_1_coherence_map.csv</code></li> <li><code>artifact_2_active_set.csv</code></li> <li><code>artifact_3_trace_report.jsonl</code></li> <li><code>artifact_4_error_budget.json</code></li> </ul> <p>You can open the CSVs in Excel and keep them with your meeting notes.</p>"},{"location":"handbook/","title":"Higgins Unity Framework (HUF) Handbook","text":"<p>Edition: v1.1.8 (docs refresh) Updated: 2026-02-17  </p> <p>This handbook is the conceptual and contractual description of HUF: what the Unity-Budgeted Hierarchy (UBH) is, how HUF emits auditable artifacts, and how to interpret stability sweeps.</p> <p>Real-data demos included in this repo: - Markham (2018 budget) \u2014 real Excel input fetched from the City of Markham open data site. - Toronto (traffic signals timing) \u2014 real CSV derived from the City of Toronto open data \u201cTraffic signals timing\u201d ZIP. - Planck (70 GHz all-sky map) \u2014 real FITS map not shipped in the repo (too large). You fetch it from PLA or IRSA (guided in <code>scripts/fetch_data.py --planck-guide</code>).</p> <p>Synthetic data: only small \u201ctoy\u201d examples (used for quick sanity checks) are synthetic. The headline demos above are real data.</p>"},{"location":"handbook/#origins-why-this-exists","title":"Origins (why this exists)","text":"<p>HUF grew out of a very practical question: how to solve diffraction and dispersion problems in loudspeakers well enough that the \u201cwhy\u201d became impossible to ignore. The working path was:</p> <ol> <li>solve the physical problem (dispersion / diffraction) empirically</li> <li>notice an \u201cenergy budget\u201d invariant when moving from 2\u03c0 to 4\u03c0 radiation equalization</li> <li>formalize the invariant as an isotropic budget / unity constraint</li> <li>generalize it into a contract for hierarchies \u2192 the Unity\u2011Budgeted Hierarchy (UBH)</li> <li>treat every run as a reproducible artifact emitter \u2192 HUF</li> </ol> <p>That\u2019s the reason the framework is written like a lab protocol: it is designed to let people verify \u201cis this real?\u201d before debating \u201cis this beautiful?\u201d.</p> <p>Higgins Unity Framework (HUF) Handbook</p> <p>A contract-first method for unity\u2011budgeted hierarchies, auditable reduction, and stable anomaly localization</p> <p>Handbook Edition \u2022 Version 1.0 February 2026</p> <p>Peter Higgins</p>"},{"location":"handbook/#front-matter","title":"Front matter","text":"<p>This handbook replaces the earlier \u2018meeting spec\u2019 lineage. It is written to be implementable, teachable, and hard to misread. The tone is intentionally contract\u2011driven: if you cannot verify finite elements, conserve a declared unity budget, emit the required artifacts, and pass stability checks, then you are not doing HUF \u2014 you are doing storytelling.</p> <p>The handbook contains two comprehensive, real-data case studies (Planck 70\u202fGHz and City of Markham public data) and a third operational case study (traffic signal telemetry) as an anomaly\u2011localization template.</p>"},{"location":"handbook/#how-to-use-this-handbook","title":"How to use this handbook","text":"<ul> <li> <p>If you need the method: read Part I and implement the contract (required artifacts + stability packet).</p> </li> <li> <p>If you need proof: read Part II and reproduce the reference runs (Planck and Markham).</p> </li> <li> <p>If you need to teach or deploy: read Part III (implementation patterns, templates, and training exercises).</p> </li> </ul>"},{"location":"handbook/#table-of-contents","title":"Table of contents","text":"<p>In Word: Right\u2011click the TOC \u2192 Update Field \u2192 Update entire table.</p>"},{"location":"handbook/#part-i-huf-core-normative","title":"Part I \u2014 HUF Core (Normative)","text":""},{"location":"handbook/#1-definition-in-one-page-the-core-stripped","title":"1. Definition in one page (the core, stripped)","text":"<p>HUF defines a system as a unity\u2011budgeted hierarchy with auditable finite elements.</p> <ol> <li> <p>Finite elements: verifiable units that contribute to a conserved budget.</p> </li> <li> <p>Regimes: named groupings of finite elements (nestable) used for interpretability.</p> </li> <li> <p>Unity budget: a declared conserved quantity (mass/weight or energy/power) with total sum exactly 1.0.</p> </li> <li> <p>Locked cycle: Normalize \u2192 Propagate \u2192 Aggregate \u2192 Exclude \u2192 Renormalize.</p> </li> <li> <p>Contract: a run is invalid unless it emits the required artifacts and passes declared stability checks.</p> </li> </ol>"},{"location":"handbook/#2-motivation-the-shortest-honest-version","title":"2. Motivation (the shortest honest version)","text":"<p>Every serious system ends up doing some form of reduction: compressing models, pruning portfolios, prioritizing interventions, or summarizing telemetry. The failure mode is consistent: reduction happens, but the justification is ad hoc. HUF exists to make reduction auditable.</p> <p>HUF does not promise \u2018truth.\u2019 It promises four things you can test: (1) unity conservation, (2) explicit retained set, (3) explicit discarded budget, and (4) backward trace to finite elements. That\u2019s the entire game.</p>"},{"location":"handbook/#3-primitives-and-invariants","title":"3. Primitives and invariants","text":"<p>3.1 Finite element</p> <p>A finite element is the smallest unit you agree to audit. It must have: a unique identifier, a repeatable method of computing its contribution, and stored provenance.</p> <p>Minimum finite-element record:</p> <ul> <li> <p>id: stable string key (do not recycle IDs across runs)</p> </li> <li> <p>inputs: pointers to measured data, logs, or upstream artifacts</p> </li> <li> <p>contribution: a non-negative scalar (or paired positive/negative extension) used by the unity budget</p> </li> <li> <p>provenance: hash or stamp sufficient to reproduce the number</p> </li> </ul> <p>3.2 Regime</p> <p>A regime is a partition (or nested partition) used to contextualize budget. A regime answers: \u2018where did the budget go?\u2019 Regimes must not double-count contributions. If an element belongs to multiple regimes, you must explicitly split its budget.</p> <p>3.3 Unity budget</p> <p>Unity is the only invariant HUF treats as sacred: after normalization, the sum of contributions equals 1.0 globally. Local unity (within a regime) may be enforced for a local view, but the global unity must always be satisfied.</p>"},{"location":"handbook/#4-budget-semantics-choose-once-dont-cheat","title":"4. Budget semantics (choose once; don\u2019t cheat)","text":"<p>HUF is ruthless about budget semantics. Declare one of the following and never mix them mid-run:</p> <ul> <li> <p>Mass/weight budget: \u03c1\u1d62 \u2265 0 and \u03a3\u03c1\u1d62 = 1. Examples: expenditure shares, portfolio weights, probability mass.</p> </li> <li> <p>Energy/power budget: \u03c1\u1d62 = e\u1d62 / \u03a3e with e\u1d62 = |x\u1d62|\u00b2 or another Parseval-consistent energy under a declared orthogonal basis.</p> </li> </ul> <p>If your domain has cancellation (signed contributions), do not fake it by allowing negative \u03c1. Use a paired-budget extension (track positive and negative magnitudes separately) or an explicitly signed framework with stability proofs.</p>"},{"location":"handbook/#5-the-locked-cycle-and-what-each-step-is-allowed-to-do","title":"5. The locked cycle and what each step is allowed to do","text":"<p>Figure 1. The locked HUF cycle. You may extend steps, but you may not reorder them without breaking audit expectations.</p> <p>Normalize</p> <p>Normalize converts raw contributions into a unity budget. For mass budgets: \u03c1\u1d62 = w\u1d62 / \u03a3w. For energy budgets: \u03c1\u1d62 = |x\u1d62|\u00b2 / \u03a3|x|\u00b2. Normalization must be deterministic and logged.</p> <p>Propagate</p> <p>Propagation moves budget between representations (e.g., from fine pixels to coarse blocks, from categories to wards, from events to root causes). Propagation is admissible only if it is conservative and traceable.</p> <ul> <li> <p>Conservation check: |\u03a3\u03c1_out \u2212 \u03a3\u03c1_in| \u2264 \u03b5 (declare \u03b5).</p> </li> <li> <p>Traceability check: every output element stores a map back to input elements with weights.</p> </li> <li> <p>No hidden state: propagation must be a pure function of inputs + declared parameters (seeded if stochastic).</p> </li> </ul> <p>Aggregate</p> <p>Aggregation merges elements to reduce complexity while preserving the budget. Examples: cluster similar items, sum within a regime, downsample by known hierarchical structure.</p> <p>Exclude</p> <p>Exclusion removes elements below a threshold \u03c4 or keeps the smallest set reaching a retained budget target. Exclusion must emit a discard ledger (what was removed and how much budget it carried).</p> <p>Renormalize and validate</p> <p>Renormalize after exclusion (and after any operation that may introduce floating-point drift). Then validate the contract: unity checks, trace completeness, artifact emission, and stability packet results.</p>"},{"location":"handbook/#6-the-contract-required-artifacts","title":"6. The contract (required artifacts)","text":"<p>Contract: a HUF run is invalid unless it emits all artifacts</p>"},{"location":"handbook/#7-artifact-schemas-minimum-workable-forms","title":"7. Artifact schemas (minimum workable forms)","text":"<p>HUF does not mandate file formats, but it does mandate fields. Minimal schemas:</p> <p>Schema A \u2014 Active set</p> <p>Schema B \u2014 Backward trace (per retained element)</p> <p>Schema C \u2014 Error/Budget report</p>"},{"location":"handbook/#8-stability-packet-required-anti-brittleness-tests","title":"8. Stability packet (required anti-brittleness tests)","text":"<p>Minimum stability packet</p>"},{"location":"handbook/#9-deployment-hazards-the-things-critics-correctly-attack","title":"9. Deployment hazards (the things critics correctly attack)","text":"<ul> <li> <p>Semantics drift: changing what unity means mid-run (e.g., mixing weight and energy).</p> </li> <li> <p>Black-box propagation: learned or heuristic mapping with no trace and no conservation validation.</p> </li> <li> <p>Double counting: elements belonging to overlapping regimes without explicit splitting.</p> </li> <li> <p>Unstable thresholds: large near-\u03c4 mass and low overlap across sweeps.</p> </li> <li> <p>Overfitting the narrative: tuning \u03c4 until your preferred story appears.</p> </li> </ul> <p>HUF\u2019s job is to make these failures visible. If your run fails, that is not \u2018HUF failing\u2019; that is the system refusing to be compressed honestly.</p>"},{"location":"handbook/#part-ii-comprehensive-reference-runs-real-data","title":"Part II \u2014 Comprehensive Reference Runs (Real Data)","text":""},{"location":"handbook/#10-case-study-a-planck-lfi-70-ghz-healpix-nside1024","title":"10. Case Study A \u2014 Planck LFI 70\u202fGHz (HEALPix, nside=1024)","text":"<p>This case demonstrates energy\u2011budget HUF on a large scientific dataset. Input file: LFI_SkyMap_070_1024_R3.00_full.fits. We use the Stokes I column (I_STOKES). The finite elements are pixels; the energy contribution is I\u00b2.</p>"},{"location":"handbook/#101-data-model","title":"10.1 Data model","text":"<ul> <li> <p>Raw finite elements: nside=1024 pixels (12\u00d71024\u00b2 = 12,582,912 elements).</p> </li> <li> <p>Aggregation: NESTED parent blocks at nside=64 (12\u00d764\u00b2 = 49,152 coarse elements), each covering 256 child pixels.</p> </li> <li> <p>Regimes: 12 HEALPix base faces (each face = 4,096 coarse blocks).</p> </li> <li> <p>Budget: energy share \u03c1\u1d62 = e\u1d62 / \u03a3e, with e\u1d62 = \u03a3child I\u00b2 (for coarse blocks).</p> </li> </ul>"},{"location":"handbook/#102-run-configuration","title":"10.2 Run configuration","text":"<p>Aggregation: nside 1024 \u2192 64 (ratio 16; 256 children per parent).</p> <p>Retain target: 0.97 of total energy.</p> <p>Outcome: K = 18,198 retained coarse blocks out of 49,152. Threshold \u03c4 = 1.66e-06.</p> <p>Energy retained = 0.9700; discarded = 0.0300.</p> <p>Pixel\u2011basis RMSE under keep\u2011or\u2011zero reconstruction = 7.6942e-05 (same units as I_STOKES).</p>"},{"location":"handbook/#103-coherence-map","title":"10.3 Coherence map","text":"<p>Figure 2. Planck 70\u202fGHz \u2014 global retained vs discarded energy share.</p> <p>Figure 3. Planck 70\u202fGHz \u2014 per\u2011face unity bars (faces as regimes).</p> <p>Figure 4. Planck 70\u202fGHz \u2014 active\u2011set growth curve (sorted by \u03c1).</p> <p>Table 10\u2011A. Per\u2011face energy shares (global \u03c1)</p> <p>Table 10\u2011B. Top retained coarse blocks (traceable sample)</p>"},{"location":"handbook/#104-traceability-how-to-audit-a-retained-block","title":"10.4 Traceability (how to audit a retained block)","text":"<p>Because the map uses HEALPix NESTED ordering, each nside=64 parent block corresponds to a contiguous range of 256 nside=1024 child pixels. For a retained parent with index p, the child range is [256p, 256p+255]. This makes backward traces compact and exact.</p> <p>Example: a compact backward trace for an aggregated HEALPix block</p>"},{"location":"handbook/#105-stability-packet-retaintarget-sweep","title":"10.5 Stability packet (retain\u2011target sweep)","text":"<p>Table 10\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 10\u2011D. Active\u2011set overlap (Jaccard) between sweep points</p> <p>Table 10\u2011E. Regime ranking stability (faces) across sweep points</p>"},{"location":"handbook/#106-what-this-run-teaches-and-what-it-does-not","title":"10.6 What this run teaches (and what it does not)","text":"<ul> <li> <p>HUF can reduce 49,152 coarse blocks to ~18k while retaining 97% pixel-basis energy, with exact accounting.</p> </li> <li> <p>Per-regime views (faces) remain stable across threshold sweeps: the \u2018where\u2019 of energy is robust.</p> </li> <li> <p>The discard fraction is a quantitative error bound under the declared reconstruction.</p> </li> <li> <p>This is not cosmological inference. HUF is an auditable reduction layer; domain science still happens above it.</p> </li> </ul>"},{"location":"handbook/#11-case-study-b-city-of-markham-2018-budget-civic-layers","title":"11. Case Study B \u2014 City of Markham (2018 budget + civic layers)","text":"<p>This case demonstrates mass/weight HUF on municipal public data. The conserved quantity is money. Primary budget workbook: 2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx (values in $000). We focus on expenditures (the allocation of outgoing funds), then show a propagation example onto wards using census population as a proxy.</p>"},{"location":"handbook/#111-data-inventory-what-we-used","title":"11.1 Data inventory (what we used)","text":"<ul> <li> <p>2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx \u2014 fund-level revenues/expenditures by category.</p> </li> <li> <p>2018-Operating-Budget-by-Account.xlsx \u2014 operating revenue/expense categories and year comparisons.</p> </li> <li> <p>2016-Tax-Rates.xlsx and 2018-Tax-Rates.xlsx \u2014 rate context (not used as budget, used for narrative checks).</p> </li> <li> <p>GIS layers: WARD.geojson, Parks.geojson, Fire_Stations.geojson, City_Facilities.geojson (used for a propagation demo).</p> </li> <li> <p>Census DA layer (Age/Sex) for Markham \u2014 used only to compute ward population shares (proxy).</p> </li> </ul>"},{"location":"handbook/#112-budget-declaration-and-finite-elements","title":"11.2 Budget declaration and finite elements","text":"<p>Global budget: total 2018 expenditures across all funds = 456,171 ($000). Unity budget is \u2018share of total expenditures\u2019.</p> <p>Finite element for the primary run: (Fund \u00d7 ExpenditureCategory). Regimes: Funds. This gives a clean \u2018where does the city spend money\u2019 decomposition.</p>"},{"location":"handbook/#113-primary-run-results-fundcategory","title":"11.3 Primary run results (Fund\u00d7Category)","text":"<p>Retain target: 0.97. Outcome: K = 23 retained elements out of 67. Threshold \u03c4 = 0.004. Retained = 0.9710; discarded = 0.0290.</p> <p>Figure 5. Markham 2018 expenditures \u2014 global retained vs discarded budget share.</p> <p>Figure 6. Markham 2018 expenditures \u2014 per-fund unity bars (funds as regimes).</p> <p>Figure 7. Markham 2018 expenditures \u2014 active-set growth curve (Fund\u00d7Category).</p> <p>Table 11\u2011A. Fund regimes: totals and global shares</p> <p>Table 11\u2011B. Largest spending contributors (Fund\u00d7Category)</p>"},{"location":"handbook/#114-stability-packet","title":"11.4 Stability packet","text":"<p>Table 11\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 11\u2011D. Active-set overlap (Jaccard) across sweep points</p>"},{"location":"handbook/#115-backward-trace-example-auditing-a-spending-line","title":"11.5 Backward trace example (auditing a spending line)","text":"<p>In this run, the backward trace is trivial but non\u2011negotiable: each retained element points back to a specific worksheet row/column (Fund, Category, cell location) plus workbook hash. If you can\u2019t point to the cell, you can\u2019t claim the number.</p> <p>Example: backward trace record for a budget line</p>"},{"location":"handbook/#116-propagation-demo-operating-fund-to-wards-proxy-allocation","title":"11.6 Propagation demo \u2014 Operating Fund to wards (proxy allocation)","text":"<p>This section demonstrates propagation constraints on civic geography. We do NOT claim this is the real ward budget \u2014 the city budget is not ward\u2011allocated in this dataset. We demonstrate a conservative, auditable proxy mapping.</p> <p>Propagation map: allocate Operating Fund expenditures to wards proportional to 2016 census population share. This is admissible as a mapping only if it is declared as a proxy, conservative (sums match), and traceable.</p> <p>Figure 8. Markham wards \u2014 population shares (proxy weights for propagation).</p> <p>Figure 9. Operating Fund propagated to wards \u2014 per-regime unity bars (retained vs discarded at target 0.97).</p> <p>Table 11\u2011E. Ward proxy table: population, facilities counts, and Operating Fund allocation ($M)</p> <p>Why include facilities counts? Not as causal claims \u2014 as audit context. They provide additional regimes for future propagation (e.g., allocate a parks-maintenance budget proportional to park count or area). Any such mapping must be declared and tested for stability.</p>"},{"location":"handbook/#117-what-dominates-and-what-to-do-next","title":"11.7 What dominates and what to do next","text":"<p>The Fund\u00d7Category decomposition typically reveals (a) how concentrated spending is, (b) whether one fund dominates the budget narrative, and (c) which categories are \u2018structural\u2019 versus \u2018tail.\u2019 This run is a starting point.</p> <ul> <li> <p>Next expansion: link operating categories to performance measures (if definitions match).</p> </li> <li> <p>Next expansion: add revenues as a parallel budget and compare structural mismatch (revenue concentration vs expenditure concentration).</p> </li> <li> <p>Next expansion: incorporate capital project lists and apply HUF to project portfolios (true finite elements with trace to project IDs).</p> </li> </ul>"},{"location":"handbook/#12-case-study-c-traffic-signal-telemetry-anomaly-localization-template","title":"12. Case Study C \u2014 Traffic signal telemetry (anomaly localization template)","text":"<p>This case shows how HUF behaves on operational event streams. The goal is not \u2018compress for beauty\u2019 \u2014 it is: what dominates anomalies, and where should you look first?</p>"},{"location":"handbook/#121-finite-element-and-budget-definition-recommended","title":"12.1 Finite element and budget definition (recommended)","text":"<p>Recommended finite element for anomaly work: Finite element = TCS \u00d7 PHASE \u00d7 PHASE_STATUS_TEXT (optionally \u00d7 PHASE_CALL_TEXT) Budget = event share or severity\u2011weighted share (declare weights) Output = which intersections/phases dominate drops/terminations/clearance with full trace to raw rows.</p> <p>In this run we define a simple severity budget: Dropped calls weight 3, Termination statuses weight 2, everything else weight 1, then restrict the anomaly view to rows with severity &gt; 1.</p>"},{"location":"handbook/#122-compressed-phase-activity-distribution-what-dominates-anomalies","title":"12.2 Compressed phase activity distribution (what dominates anomalies)","text":"<p>Figure 10. Traffic telemetry \u2014 anomaly severity budget by intersection (top contributors).</p> <p>Figure 11. Traffic telemetry \u2014 anomaly severity budget by phase.</p> <p>Figure 12. Traffic telemetry \u2014 anomaly severity budget by status.</p> <p>Table 12\u2011A. Top intersections by anomaly severity budget share</p> <p>Table 12\u2011B. Phases dominating the anomaly budget</p> <p>Table 12\u2011C. Status distribution within anomaly budget</p>"},{"location":"handbook/#123-traceability-and-actionability","title":"12.3 Traceability and actionability","text":"<p>A practical HUF anomaly run ends with a short, actionable list: top intersections, top phases, and the raw event rows supporting them. Backward traces should include timestamp ranges and source row IDs so an engineer can replay the evidence.</p> <ul> <li> <p>If one intersection dominates: inspect controller configuration and detector health first.</p> </li> <li> <p>If one phase dominates across many intersections: inspect phase timing policy or coordination logic.</p> </li> <li> <p>If one status dominates: inspect the semantic definition (what exactly triggers \u2018Termination\u2019 in your system).</p> </li> </ul>"},{"location":"handbook/#part-iii-implementation-extension-and-training","title":"Part III \u2014 Implementation, extension, and training","text":""},{"location":"handbook/#13-reference-implementation-patterns","title":"13. Reference implementation patterns","text":"<p>A handbook is useless if it can\u2019t be implemented. This section defines the minimal architecture that prevents HUF from collapsing back into prose.</p> <ul> <li> <p>Core data model: Element(id, rho, regime_path, trace).</p> </li> <li> <p>Adapters: domain-specific loaders and propagators that output the same element schema.</p> </li> <li> <p>I/O: artifact writers (CSV/JSON) that always include run stamps and file hashes.</p> </li> <li> <p>Tests: each reference run must have an automated test that checks unity, artifact emission, and stability packet generation.</p> </li> </ul> <p>Listing 13\u2011A. Reference core (excerpt, huf_core/core.py)</p> <p>(Full source is intended for the accompanying repository/package; this excerpt is included for handbook completeness.)</p>"},{"location":"handbook/#14-how-huf-prunes-itself-expansion-contraction-as-a-method","title":"14. How HUF prunes itself (expansion \u2192 contraction as a method)","text":"<p>The development history that produced this handbook is not a shameful detour \u2014 it is the method. You expand to explore, then you contract to ship. HUF applies to itself:</p> <ol> <li> <p>Expansion phase: explore candidate operations, artifacts, and narratives to discover what actually matters in practice.</p> </li> <li> <p>Contraction phase: declare the contract, delete optionality from the core, and move everything else into extensions.</p> </li> <li> <p>Stability phase: treat the framework definition as a system under HUF \u2014 track which sections survive pruning across reviewer critiques.</p> </li> </ol> <p>A useful internal exercise: assign a unity budget to sections of your draft (by reader time, by risk, or by implementation cost), then run HUF to see which sections dominate confusion or contribute little. That is \u2018HUF on HUF.\u2019</p>"},{"location":"handbook/#15-training-exercises-from-toy-to-real","title":"15. Training exercises (from toy to real)","text":"<p>Exercises are designed to build the habit of declaring budgets, regimes, and traces before you compute.</p> <ol> <li> <p>Take any spreadsheet with line items. Define finite elements and a mass budget. Produce the four artifacts.</p> </li> <li> <p>Repeat with two regime partitions (by department vs by fund). Compare regime stability across thresholds.</p> </li> <li> <p>Take an event log. Define anomaly budget weights. Produce a top\u2011N actionable list with backward traces to row IDs.</p> </li> <li> <p>Design a propagation map (e.g., cost \u2192 ward) and prove conservation + traceability in one paragraph.</p> </li> <li> <p>Perform a stability sweep and write the two-sentence interpretation of the stability packet.</p> </li> </ol>"},{"location":"handbook/#appendix-a-data-samples-print-friendly-excerpts","title":"Appendix A \u2014 Data samples (print-friendly excerpts)","text":"<p>A1. Planck sample (first 5 coarse blocks; energies are in I\u00b2 units)</p> <p>A2. Markham sample (top 10 Fund\u00d7Category elements)</p> <p>A3. Traffic sample (first 12 telemetry rows; severity weights shown)</p>"},{"location":"handbook/#appendix-b-artifact-checklists-what-a-reviewer-will-ask-for","title":"Appendix B \u2014 Artifact checklists (what a reviewer will ask for)","text":"<ul> <li> <p>Unity checks: global \u03a3\u03c1=1.0 after every normalization and renormalization step (log the tolerance).</p> </li> <li> <p>Discard ledger: list of excluded elements with their \u03c1; discarded sum must match 1\u2212retained.</p> </li> <li> <p>Trace completeness: every retained element has a backward trace to finite elements (no null traces).</p> </li> <li> <p>Stability packet: sweep points, overlap metrics, regime rank stability, near\u2011\u03c4 band.</p> </li> <li> <p>Repro stamp: file hashes, code version, run_id, parameters (\u03c4/target, seeds).</p> </li> </ul>"},{"location":"handbook/#appendix-c-glossary-minimal","title":"Appendix C \u2014 Glossary (minimal)","text":"<p>Glossary</p>"},{"location":"handbook/#appendix-d-reproducibility-stamps-recommended-minimum","title":"Appendix D \u2014 Reproducibility stamps (recommended minimum)","text":"<p>Run stamp</p>"},{"location":"huf_math_form_and_function/","title":"Mathematical form and function","text":"<p>\\</p>"},{"location":"huf_math_form_and_function/#higgins-unity-framework-mathematical-form-and-function","title":"Higgins Unity Framework: Mathematical form and function","text":"<p>This page is the \u201cmath spine\u201d that connects the HUF contract (artifacts + stability packet) to a minimal formal model.</p> <p>Not ML class imbalance: here \u201clong tail\u201d means mass distribution + exception reweighting (baseline vs filtered view).</p>"},{"location":"huf_math_form_and_function/#1-the-object-huf-normalizes","title":"1) The object HUF normalizes","text":"<p>HUF starts from a non\u2011negative contribution table and turns it into a unity budget.</p> <ul> <li>Finite elements: indices (i = 1..N)</li> <li>Raw contributions: (w_i \\ge 0)</li> <li>Unity\u2011budget weights (\u201cmass share\u201d or \u201cenergy share\u201d):</li> <li>Mass: (\\rho_i = \\frac{w_i}{\\sum_k w_k})</li> <li>Energy / Parseval: (\\rho_i = \\frac{|x_i|^2}{\\sum_k |x_k|^2})</li> </ul>"},{"location":"huf_math_form_and_function/#proof-sketch-unity-is-enforced","title":"Proof sketch: unity is enforced","text":"<p>Let (S = \\sum_k w_k). Then: - (\\rho_i \\ge 0) because (w_i \\ge 0) - (\\sum_i \\rho_i = \\sum_i \\frac{w_i}{S} = \\frac{1}{S}\\sum_i w_i = 1)</p> <p>This is the core invariant HUF treats as sacred: global unity.</p>"},{"location":"huf_math_form_and_function/#2-regimes-local-views-that-stay-auditable","title":"2) Regimes (local views that stay auditable)","text":"<p>A regime is a partition (or nested partition) of finite elements: - Regimes (R_1, \\dots, R_m) where (R_j \\subseteq {1..N}) - Regime mass:   [   \\rho(R_j) = \\sum_{i \\in R_j} \\rho_i   ]</p> <p>The coherence map artifact is exactly \u201c(\\rho(R_j)) for all regimes\u201d plus ranking, so you can answer:</p> <p>\u201cWhere did the budget go?\u201d</p>"},{"location":"huf_math_form_and_function/#3-exclusion-reduction-as-a-truncation-operator","title":"3) Exclusion / reduction as a truncation operator","text":"<p>Most practical HUF runs reduce the system to an auditable subset.</p>"},{"location":"huf_math_form_and_function/#31-threshold-form","title":"3.1 Threshold form (\u03c4)","text":"<p>Define a truncation operator: [ T_\\tau(\\rho)_i = \\rho_i \\cdot \\mathbf{1}[\\rho_i \\ge \\tau] ]</p> <p>Discarded budget (explicitly reported in <code>artifact_4_error_budget.json</code>): [ \\delta(\\tau) = 1 - \\sum_i T_\\tau(\\rho)_i ]</p> <p>Let (K(\\tau) = { i : \\rho_i \\ge \\tau }) be the retained set and (Z(\\tau)=\\sum_{k\\in K(\\tau)}\\rho_k = 1-\\delta(\\tau)).</p> <p>Renormalized retained distribution: [ \\hat\\rho_i(\\tau) = \\frac{\\rho_i}{Z(\\tau)} \\quad \\text{for } i \\in K(\\tau) ]</p> <p>Proof sketch (renormalized unity): [ \\sum_{i \\in K(\\tau)} \\hat\\rho_i(\\tau) = \\frac{\\sum_{i \\in K(\\tau)} \\rho_i}{Z(\\tau)} = 1 ]</p> <p>This is why HUF can be \u201ccompression + audit\u201d: you can discard mass, but you must (1) declare it, and (2) renormalize what remains.</p>"},{"location":"huf_math_form_and_function/#32-retainedtarget-form","title":"3.2 Retained\u2011target form (\u03b1)","text":"<p>Sometimes you don\u2019t choose (\\tau) directly. You choose a retained target (\\alpha) (e.g. 0.90), and HUF keeps the smallest set (K) such that: [ \\sum_{i \\in K} \\rho_i \\ge \\alpha ]</p> <p>Operationally: sort by (\\rho_i) descending; take the shortest prefix that reaches (\\alpha).</p> <p>This is exactly the \u201citems to cover 90%\u201d headline used in the long\u2011tail demo: - baseline run: items_to_cover_90pct = 37 - anomaly run: items_to_cover_90pct = 12 \u2192 concentration increased.</p>"},{"location":"huf_math_form_and_function/#4-fixed-points-why-the-cycle-is-stable","title":"4) Fixed points (why the cycle is stable)","text":""},{"location":"huf_math_form_and_function/#41-normalization-is-idempotent-on-the-simplex","title":"4.1 Normalization is idempotent on the simplex","text":"<p>Define normalization: [ N(w) = \\frac{w}{\\sum_k w_k} ]</p> <p>If (\\rho) already satisfies (\\sum \\rho = 1), then: [ N(\\rho) = \\rho ] So all unity\u2011budget distributions are fixed points of (N).</p>"},{"location":"huf_math_form_and_function/#42-a-lyapunov-view-stability-to-unity","title":"4.2 A Lyapunov view (stability to unity)","text":"<p>A simple \u201cdistance to unity\u201d function: [ V(\\rho) = 1 - \\sum_i \\rho_i ] After normalization, (V(\\rho)=0). Any drift away from unity is measurable, correctable, and auditable.</p> <p>In practice, HUF treats \u201cunity drift\u201d as a bug: either a numerical issue (float accumulation) or a forbidden operation (non\u2011conservative propagation).</p>"},{"location":"huf_math_form_and_function/#5-information-theory-optional-but-useful","title":"5) Information theory (optional, but useful)","text":"<p>Once (\\rho) is a probability\u2011like distribution, information tools become usable:</p>"},{"location":"huf_math_form_and_function/#51-entropy-as-concentration","title":"5.1 Entropy as \u201cconcentration\u201d","text":"<p>[ H(\\rho) = -\\sum_i \\rho_i \\log \\rho_i ]</p> <ul> <li>High entropy \u2192 diffuse mass (less concentrated)</li> <li>Low entropy \u2192 concentrated mass (few items dominate)</li> </ul> <p>A friendly scalar is the effective number of items: [ N_{\\mathrm{eff}} = \\exp(H(\\rho)) ] When your anomaly run concentrates, (H) tends to drop and (N_{\\mathrm{eff}}) shrinks.</p>"},{"location":"huf_math_form_and_function/#52-regime-shift-as-divergence","title":"5.2 Regime shift as divergence","text":"<p>Let (\\rho^{(base)}) be baseline (Traffic Phase) and (\\rho^{(anom)}) be exception view (Traffic Anomaly). A regime\u2011shift measure is KL divergence: [ D_{KL}(\\rho^{(anom)} \\Vert \\rho^{(base)}) = \\sum_i \\rho^{(anom)}_i \\log \\frac{\\rho^{(anom)}_i}{\\rho^{(base)}_i} ] You don\u2019t need this to run HUF \u2014 but it\u2019s a clean way to quantify \u201cthe mass moved\u201d.</p>"},{"location":"huf_math_form_and_function/#6-how-this-maps-to-the-three-artifact-first-pillars","title":"6) How this maps to the three \u201cartifact-first\u201d pillars","text":"<p>HUF\u2019s elevator pitch is not \u201cmath for math\u2019s sake.\u201d It\u2019s math that forces auditability:</p> <ul> <li>Coherence map \u2192 (\\rho(R_j)) (where the budget went, by regime)</li> <li>Active set \u2192 (K) (what you kept, explicitly)</li> <li>Trace report \u2192 provenance map (why each kept item is kept, and what it came from)</li> </ul> <p>If you can\u2019t show all three, you\u2019re not doing HUF \u2014 you\u2019re doing storytelling.</p>"},{"location":"huf_math_form_and_function/#math-appendix-artifact-columns-formulas","title":"Math appendix: artifact columns \u2194 formulas","text":"<p>This section lets you jump from an artifact column name to the math above.</p> <p>Important notes: - Column presence varies by adapter, but these names are common across HUF runs. - Suffix meanings are consistent:   - <code>*_pre</code> \u2192 computed on the original unity budget (\\rho)   - <code>*_post</code> \u2192 computed after exclusions + renormalization on the retained distribution (\\hat\\rho) - Let (K) be the retained set, (Z=\\sum_{k\\in K}\\rho_k=1-\\delta).</p>"},{"location":"huf_math_form_and_function/#a-element-level-columns-typical-in-artifact_2_active_setcsv","title":"A) Element-level columns (typical in <code>artifact_2_active_set.csv</code>)","text":"Column Formula Meaning <code>rho_global_pre</code> (\\rho_i) Element\u2019s share of the original unity budget <code>rho_global_post</code> (\\hat\\rho_i=\\rho_i/Z) for (i\\in K) Element\u2019s share after exclusion + renormalization <code>rho_local_pre</code> (\\rho_i / \\rho(R)) where (i\\in R) Element\u2019s share within its regime (pre) <code>rho_local_post</code> (\\hat\\rho_i / \\hat\\rho(R)) Element\u2019s share within its regime (post) <p>Where: - (\\rho(R)=\\sum_{j\\in R}\\rho_j) - (\\hat\\rho(R)=\\sum_{j\\in R\\cap K}\\hat\\rho_j = \\frac{\\sum_{j\\in R\\cap K}\\rho_j}{Z})</p> <p>A useful simplification: [ \\rho_local_post(i\\in R) = \\frac{\\rho_i}{\\sum_{j\\in R\\cap K}\\rho_j} ] (renormalization cancels (Z) inside the regime).</p> <p>Practical reading: <code>rho_global_post</code> answers \u201chow important is this element overall (after pruning)?\u201d <code>rho_local_post</code> answers \u201chow dominant is this element inside its regime?\u201d</p>"},{"location":"huf_math_form_and_function/#b-regime-level-columns-typical-in-artifact_1_coherence_mapcsv","title":"B) Regime-level columns (typical in <code>artifact_1_coherence_map.csv</code>)","text":"Column Formula Meaning <code>rho_global_pre</code> (\\rho(R)=\\sum_{i\\in R}\\rho_i) Regime share in the original distribution <code>rho_global_post</code> (\\hat\\rho(R)=\\sum_{i\\in R\\cap K}\\rho_i/Z) Regime share after exclusion + renormalization <code>rho_discarded_pre</code> (\\sum_{i\\in R\\setminus K}\\rho_i) Amount of original mass discarded inside the regime <p>So the coherence map can be read as: - who dominates now (<code>rho_global_post</code>) - how much tail was cut away (<code>rho_discarded_pre</code>)</p>"},{"location":"huf_math_form_and_function/#c-error-budget-artifact_4_error_budgetjson","title":"C) Error budget (<code>artifact_4_error_budget.json</code>)","text":"<p>Common keys and their math:</p> Key Formula Meaning <code>discarded_budget_global</code> (or similar) (\\delta = 1 - \\sum_{i\\in K}\\rho_i) Total mass discarded globally <code>retained_budget_global</code> (if present) (Z = \\sum_{i\\in K}\\rho_i = 1-\\delta) Total mass retained before renormalization"},{"location":"huf_math_form_and_function/#d-the-items-to-cover-90-headline-used-in-demos","title":"D) The \u201citems to cover 90%\u201d headline (used in demos)","text":"<p>Given active set rows sorted by <code>rho_global_post</code> descending, define: [ k_{0.90} = \\min \\left{k : \\sum_{i=1}^k \\rho^{post}_{(i)} \\ge 0.90 \\right} ]</p> <p>This is what the demo prints as:</p> <ul> <li><code>items_to_cover_90pct baseline -&gt; exception</code></li> </ul> <p>If (k_{0.90}) shrinks in the exception view, you can legitimately say:</p> <p>\u201cConcentration increased.\u201d</p>"},{"location":"huf_math_form_and_function/#e-trace-report-artifact_3_trace_reportjsonl","title":"E) Trace report (<code>artifact_3_trace_report.jsonl</code>)","text":"<p>The trace report isn\u2019t one formula; it\u2019s the provenance map for each retained item: - which input rows/cells formed the finite element, - what regime labels were assigned, - what exclusions applied, - what post-normalized shares were computed.</p> <p>Think of it as a serialized proof object that supports the numbers above.</p>"},{"location":"huf_math_form_and_function/#next","title":"Next","text":"<ul> <li>For the accounting\u2011facing explanation and the baseline\u2192exception\u2192variance flow, see:</li> <li>Long tail (accounting lens) (<code>docs/long_tail_accounting_lens.md</code>)</li> <li>For command discovery and artifact labels, see:</li> <li>CLI command lists + terminology (<code>docs/cli_huf_reference.md</code>)</li> </ul>"},{"location":"jupyter_demos/","title":"Jupyter demos (optional)","text":"<p>Jupyter is optional. It\u2019s useful when you want to read and summarize artifacts interactively.</p>"},{"location":"jupyter_demos/#install-launch-windows-powershell","title":"Install + launch (Windows PowerShell)","text":"<pre><code>.\\.venv\\Scripts\\python -m pip install notebook pandas\n.\\.venv\\Scripts\\python -m notebook\n</code></pre> <p>A browser window opens. Create a new notebook (Python).</p>"},{"location":"jupyter_demos/#important-powershell-is-not-python","title":"Important: PowerShell is not Python","text":"<p>If you type <code>import pandas as pd</code> at a PowerShell prompt, it will fail.</p> <p>Run Python code: - in a notebook cell, or - inside <code>python</code> interactive (<code>.\\.venv\\Scripts\\python</code>), or - from a script file.</p>"},{"location":"jupyter_demos/#suggested-notebook-pattern","title":"Suggested notebook pattern","text":""},{"location":"jupyter_demos/#cell-1-run-a-case-cli","title":"Cell 1 \u2014 run a case (CLI)","text":"<pre><code>import subprocess, sys\nsubprocess.check_call([sys.executable, \"-m\", \"huf_core.cli\", \"--help\"])\n</code></pre> <p>(Or just run the case in PowerShell first, then open artifacts in the next cells.)</p>"},{"location":"jupyter_demos/#cell-2-open-artifacts-markham","title":"Cell 2 \u2014 open artifacts (Markham)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/markham2018/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/markham2018/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(10)\n</code></pre>"},{"location":"jupyter_demos/#cell-3-how-many-items-cover-90","title":"Cell 3 \u2014 \u201chow many items cover 90%?\u201d","text":"<pre><code>active[\"cum\"] = active[\"rho_global_post\"].cumsum()\nactive.loc[active[\"cum\"] &gt;= 0.90, [\"rank\",\"item_id\",\"cum\"]].head(1)\n</code></pre>"},{"location":"jupyter_demos/#cell-4-open-artifacts-traffic-phase","title":"Cell 4 \u2014 open artifacts (Traffic Phase)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/traffic_phase/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/traffic_phase/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(15)\n</code></pre>"},{"location":"jupyter_demos/#export","title":"Export","text":"<p>You can export notebooks to HTML/PDF from the Jupyter UI (File \u2192 Download).</p>"},{"location":"learning_path/","title":"Learning path","text":"<p>HUF is easiest to learn by running a case, then reading the artifacts it produces. This path is designed so the left sidebar is a \u201cdo-this-next\u201d guide.</p> <p>Windows / Conda rule</p> <p>After the repo venv exists, always run tools via the repo executables:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"learning_path/#step-1-install-first-run","title":"Step 1 \u2014 Install + first run","text":"<p>Choose one:</p> <ul> <li>Start here (developer): Start Here \u2192 Developer</li> <li>Start here (beginner): Start Here \u2192 Zero GitHub knowledge</li> </ul> <p>Goal: you can run <code>.\\.venv\\Scripts\\huf --help</code> and produce an <code>out/.../run_stamp.json</code>.</p>"},{"location":"learning_path/#step-2-run-the-two-core-cases","title":"Step 2 \u2014 Run the \u201ctwo core\u201d cases","text":"<p>1) Markham (budget allocation) \u2192 then read: - Worked examples \u2192 Markham</p> <p>2) Traffic Phase (signal phases) \u2192 then read: - Worked examples \u2192 Traffic phase</p>"},{"location":"learning_path/#step-3-understand-the-long-tail-story-accounting-lens","title":"Step 3 \u2014 Understand the \u201clong tail\u201d story (accounting lens)","text":"<ul> <li>Long tail (accounting lens)</li> </ul> <p>Then run the 2\u2011minute demo:</p> <pre><code>.\\.venv\\Scripts\\python scripts/run_long_tail_demo.py --status \"Green Termination\"\n</code></pre>"},{"location":"learning_path/#step-4-try-an-adapter-style-use-case","title":"Step 4 \u2014 Try an adapter-style use case","text":"<ul> <li>Adapters \u2192 Vector DB coherence</li> </ul>"},{"location":"learning_path/#step-5-optional-notebooks","title":"Step 5 \u2014 Optional: notebooks","text":"<ul> <li>Jupyter demos (optional)</li> </ul>"},{"location":"long_tail_accounting_lens/","title":"Long tail (accounting lens)","text":"<p>Two-line disambiguation (for skimmers):</p> <ul> <li>Not ML class imbalance. Here \u201clong tail\u201d means mass distribution + exception reweighting (baseline vs filtered view).  </li> <li>In practice: baseline ledger \u2192 exception-only sub-ledger \u2192 ranked variance review.</li> </ul> <p>HUF makes that workflow reproducible by writing artifacts (CSVs/JSON) that answer:</p> <ul> <li>Where is the mass? (coherence map)</li> <li>What do we keep for review? (active set)</li> <li>What did we discard, explicitly? (error budget)</li> <li>Why did this row/item survive? (trace)</li> </ul>"},{"location":"long_tail_accounting_lens/#why-the-tail-becomes-the-story","title":"Why the \u201ctail\u201d becomes the story","text":""},{"location":"long_tail_accounting_lens/#1-long-tail-reweighting","title":"1) Long-tail reweighting","text":"<p>In a baseline ledger, most categories look \u201csmall\u201d and ignorable.</p> <p>But the moment you filter to a rare event type (exceptions), the distribution reweights:</p> <ul> <li>a small set of rows can dominate the review list</li> <li>regimes you barely noticed can become the story</li> </ul> <p>This is the accounting intuition behind \u201cthe long tail\u201d: exceptions make the tail visible.</p>"},{"location":"long_tail_accounting_lens/#2-non-linear-concentration","title":"2) Non-linear concentration","text":"<p>Filtering is non-linear.</p> <p>When you discard rows (tighten the review boundary), probability mass doesn\u2019t shrink uniformly \u2014 it concentrates.</p> <p>HUF exposes this concentration with one repeatable headline:</p> <p><code>items_to_cover_90pct = k</code> The top k retained items explain 90% of post-normalized mass.</p> <p>Smaller <code>k</code> \u21d2 more concentrated \u21d2 a tiny set dominates.</p>"},{"location":"long_tail_accounting_lens/#3-auditability","title":"3) Auditability","text":"<p>Exception review is only useful if you can defend it.</p> <p>HUF provides:</p> <ul> <li>a regime ranking (who dominates)</li> <li>a ranked review list (what to look at first)</li> <li>a discard ledger (what was dropped, and how much \u201cbudget\u201d that represents)</li> <li>a trace report (why retained)</li> </ul>"},{"location":"long_tail_accounting_lens/#traffic-phase-vs-traffic-anomaly","title":"Traffic Phase vs Traffic Anomaly","text":"<p>This is the simplest \u201caccounting-style\u201d teaching example in the repo.</p>"},{"location":"long_tail_accounting_lens/#baseline-view-traffic-phase","title":"Baseline view (Traffic Phase)","text":"<p>Traffic Phase is like baseline P&amp;L:</p> <ul> <li>you observe routine operations</li> <li>mass is spread across many rows</li> <li>the \u201ctail\u201d looks harmless</li> </ul>"},{"location":"long_tail_accounting_lens/#exception-view-traffic-anomaly","title":"Exception view (Traffic Anomaly)","text":"<p>Traffic Anomaly is like exception-only P&amp;L:</p> <ul> <li>you filter to a rare/important condition (an anomaly)</li> <li>the distribution reweights</li> <li>mass concentrates into fewer regimes/items</li> </ul>"},{"location":"long_tail_accounting_lens/#ranked-variance-review","title":"Ranked variance review","text":"<p>Once you have baseline and exception views, the operational question is:</p> <p>What changed the most, and where should we look first?</p> <p>HUF\u2019s artifacts answer that with ranking + a proof line.</p>"},{"location":"long_tail_accounting_lens/#two-minute-demo-script-first-windows-safe","title":"Two-minute demo (script-first, Windows-safe)","text":"<p>Run in PowerShell (not inside Python)</p> <p>If your prompt shows <code>&gt;&gt;&gt;</code>, exit Python with <code>exit()</code>.</p> <pre><code>.\\.venv\\Scripts\\python scripts/run_long_tail_demo.py --status \"Green Termination\"\n</code></pre> <p>What the demo does:</p> <p>1) Runs Traffic Phase (baseline) 2) Runs Traffic Anomaly (exception) 3) Prints a repeatable summary you can paste into an email/issue</p> <p>Look for these lines:</p> <ul> <li><code>Top regimes changed: ...</code> </li> <li><code>PROOF: Concentration increased: items_to_cover_90pct X -&gt; Y</code></li> </ul> <p>Interpretation:</p> <ul> <li>Top regimes changed: your exception filter changed \u201cwho dominates\u201d</li> <li>Concentration increased (Y smaller): the exception view is dominated by fewer items \u2192 higher operational risk if those items are wrong/stale</li> </ul>"},{"location":"long_tail_accounting_lens/#accounting-example-same-pattern-different-nouns","title":"Accounting example (same pattern, different nouns)","text":"<p>Imagine an accounts payable ledger.</p>"},{"location":"long_tail_accounting_lens/#baseline-ledger-monthly-close","title":"Baseline ledger (monthly close)","text":"<p>Rows: all invoices. Regimes: cost center, vendor, GL account.</p> <p>You expect dispersion: many vendors, many cost centers.</p>"},{"location":"long_tail_accounting_lens/#exception-only-sub-ledger-audit-filter","title":"Exception-only sub-ledger (audit filter)","text":"<p>Filter rows to:</p> <ul> <li>invoices above a threshold</li> <li>invoices with a policy exception code</li> <li>invoices paid outside terms</li> </ul> <p>Now the tail becomes visible:</p> <ul> <li>a \u201csmall\u201d vendor becomes dominant</li> <li>one cost center suddenly explains most of the exception mass</li> </ul>"},{"location":"long_tail_accounting_lens/#ranked-variance-review-what-to-inspect-first","title":"Ranked variance review (what to inspect first)","text":"<p>You don\u2019t want a spreadsheet you scroll.</p> <p>You want:</p> <ul> <li>regime ranking (who dominates exceptions)</li> <li>active set (which invoices dominate)</li> <li>discard ledger (what got dropped, explicitly)</li> </ul> <p>That\u2019s exactly what HUF writes.</p>"},{"location":"long_tail_accounting_lens/#what-to-look-for-in-the-artifacts","title":"What to look for in the artifacts","text":"<p>This is the \u201copen in Excel and circle the row\u201d guide.</p>"},{"location":"long_tail_accounting_lens/#artifact_1_coherence_mapcsv-regime-ranking","title":"artifact_1_coherence_map.csv (regime ranking)","text":"<p>Sort by <code>rho_global_post</code> descending.</p> <p>Watch for:</p> <ul> <li>top regime &gt; 0.50 (dominance)</li> <li>top 2\u20133 regimes cover most of mass (concentration by group)</li> </ul>"},{"location":"long_tail_accounting_lens/#artifact_2_active_setcsv-ranked-review-list","title":"artifact_2_active_set.csv (ranked review list)","text":"<p>Sort by <code>rho_global_post</code> descending.</p> <p>This is your global review list.</p> <p>Then filter by <code>regime_id</code> and sort by <code>rho_local_post</code> for \u201ctop inside regime.\u201d</p>"},{"location":"long_tail_accounting_lens/#artifact_4_error_budgetjson-declared-discards","title":"artifact_4_error_budget.json (declared discards)","text":"<p>Find:</p> <ul> <li><code>discarded_budget_global</code> (or similarly named key)</li> </ul> <p>This is the explicit \u201cwhat we dropped\u201d ledger.</p> <p>If discarded budget is large, your threshold is aggressively pruning.</p>"},{"location":"long_tail_accounting_lens/#make-it-future-proof-how-teams-extend-this","title":"Make it future-proof (how teams extend this)","text":"<p>Once a team \u201cgets\u201d this page, they usually want:</p> <p>1) Multi-run drift    - run daily/weekly on the same queries    - track top regimes and <code>items_to_cover_90pct</code> over time</p> <p>2) Two-tau sensitivity    - run tau A vs tau B    - print \u201cconcentration increased\u201d as a regression guardrail</p> <p>3) Compliance / isolation checks    - treat tenant/namespace as regimes    - detect dominance bleed across boundaries</p> <p>If you\u2019re already using the Vector DB coherence adapter, this is the same mental model \u2014 only the nouns change.</p> <p>See also:</p> <ul> <li><code>vector_db_coherence.md</code> (regimes, artifacts, and the same \u201cproof line\u201d)</li> <li><code>math_form_and_function.md</code> (equations + column mapping)</li> </ul>"},{"location":"markham_worked_example/","title":"Markham worked example (2018 budget)","text":"<p>Run:</p> <pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre> <p>Then open:</p> <ul> <li><code>out/markham2018/artifact_1_coherence_map.csv</code></li> <li><code>out/markham2018/artifact_2_active_set.csv</code></li> <li><code>out/markham2018/artifact_3_trace_report.jsonl</code></li> </ul>"},{"location":"planck/","title":"Planck 70 GHz worked example","text":"<p>This example runs HUF on a real scientific dataset (a Planck 70 GHz sky map in FITS format).</p>"},{"location":"planck/#why-run-this","title":"Why run this","text":"<ul> <li>Demonstrates the pipeline on non\u2011toy data.</li> <li>Produces artifacts you can inspect (and plot) to confirm you\u2019re looking at real structure rather than a \u201cdemo UI\u201d.</li> </ul>"},{"location":"planck/#what-you-need","title":"What you need","text":"<ul> <li>A working virtual environment (<code>.venv</code>) with HUF installed.</li> <li> <p>The FITS input file:</p> </li> <li> <p><code>cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits</code></p> </li> <li> <p><code>astropy</code> (for FITS I/O):</p> </li> </ul> WindowsmacOS / Linux <pre><code>&amp; .\\.venv\\Scripts\\python.exe -m pip install astropy\n</code></pre> <pre><code>./.venv/bin/python -m pip install astropy\n</code></pre>"},{"location":"planck/#run","title":"Run","text":"Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>.\\.venv\\Scripts\\huf.exe planck `\n  --fits \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\" `\n  --out \"out/planck70\" `\n  --retained-target 0.97 `\n  --nside-out 64\n</code></pre> <pre><code>./.venv/bin/huf planck \\\n  --fits \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\" \\\n  --out \"out/planck70\" \\\n  --retained-target 0.97 \\\n  --nside-out 64\n</code></pre>"},{"location":"planck/#what-you-should-see","title":"What you should see","text":"<p>A successful run prints a short summary like:</p> <pre><code>[done] planck -&gt; out\\planck70 | active_set=18198 coherence_rows=12 discarded_global=0.0299995\n       dataset_id: 1494a5d87d37b5b3\n       tau: 1.6627253164644175e-06\n       retained_target: 0.97\n       nside_out: 64\n</code></pre>"},{"location":"planck/#inspect-the-artifacts","title":"Inspect the artifacts","text":"<p>Important: don\u2019t paste raw Python (<code>import ...</code>, <code>print(...)</code>) directly into PowerShell.</p> <ul> <li>In PowerShell you\u2019re still in the shell, not Python.</li> <li>Use the inspection script instead.</li> </ul> Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>$py = \".\\\\.venv\\\\Scripts\\\\python.exe\"\n&amp; $py scripts/inspect_huf_artifacts.py --out out/planck70\n</code></pre> <pre><code>./.venv/bin/python scripts/inspect_huf_artifacts.py --out out/planck70\n</code></pre> <p>What you should see:</p> <ul> <li>The output folder path</li> <li>A small \u201ctail\u201d headline (e.g., <code>items_to_cover_90pct=...</code>)</li> <li>A ranked list of regimes by <code>rho_global_post</code></li> </ul>"},{"location":"planck/#optional-plots","title":"Optional plots","text":"<p>If you want charts, install matplotlib and generate plots from the artifact CSVs:</p> WindowsmacOS / Linux <pre><code>&amp; .\\.venv\\Scripts\\python.exe -m pip install matplotlib\n&amp; .\\.venv\\Scripts\\python.exe scripts/plot_huf_artifacts.py --out out/planck70\n</code></pre> <pre><code>./.venv/bin/python -m pip install matplotlib\n./.venv/bin/python scripts/plot_huf_artifacts.py --out out/planck70\n</code></pre> <p>This writes images under:</p> <ul> <li><code>out/planck70/plots/</code></li> </ul>"},{"location":"quick_run/","title":"Quick Run (copy/paste)","text":"<p>Goal: create a local <code>.venv</code>, fetch inputs, and run the included demos.</p> <p>Run these commands from the repo root (the folder that contains <code>pyproject.toml</code>).</p>"},{"location":"quick_run/#windows-powershell","title":"Windows (PowerShell)","text":""},{"location":"quick_run/#1-bootstrap-install","title":"1) Bootstrap + install","text":"<pre><code>python scripts/bootstrap.py\n.\\.venv\\Scripts\\python -m pip install -e .\n</code></pre>"},{"location":"quick_run/#2-fetch-markham-toronto-inputs","title":"2) Fetch Markham + Toronto inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"quick_run/#3-run-the-demos","title":"3) Run the demos","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"quick_run/#4-two-minute-long-tail-demo-recommended","title":"4) Two-minute long-tail demo (recommended)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/run_long_tail_demo.py --status \"Green Termination\"\n</code></pre>"},{"location":"quick_run/#5-docs-site-local","title":"5) Docs site (local)","text":"<p>Always:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Strict check:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs build --strict\n</code></pre>"},{"location":"quick_run/#macos-linux-bashzsh","title":"macOS / Linux (bash/zsh)","text":"<pre><code>python3 scripts/bootstrap.py\n./.venv/bin/python -m pip install -e .\n./.venv/bin/python scripts/fetch_data.py --markham --toronto --yes\n\n./.venv/bin/huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n./.venv/bin/huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n./.venv/bin/huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"reference_manual/","title":"HUF Reference Manual","text":"<p>Updated: 2026-02-17</p> <p>This manual is the \u201chow to run it\u201d companion to the handbook. It\u2019s written for:</p> <ul> <li>GUI-only users (download a ZIP, double-click a Windows starter),</li> <li>researchers who live in Excel + theory,</li> <li>anyone who wants reproducible artifacts without learning Git on day one.</li> </ul>"},{"location":"reference_manual/#1-quick-start-windows-no-git-required","title":"1) Quick Start (Windows, no Git required)","text":""},{"location":"reference_manual/#option-a-easiest-github-release-zip","title":"Option A \u2014 easiest: GitHub Release ZIP","text":"<ol> <li>Download the ZIP from the project\u2019s GitHub Releases page.</li> <li>Unzip it somewhere simple (Desktop is fine).</li> <li>Double-click: <code>START_HERE_WINDOWS.bat</code></li> </ol> <p>What it does:</p> <ul> <li>creates a local virtual environment in <code>.venv</code></li> <li>installs HUF in editable mode (local)</li> <li>fetches Markham + Toronto inputs (unless you skip)</li> <li>prints the exact commands to run the demos</li> </ul> <p>Tip: If Windows shows a security warning the first time, click \u201cMore info\u201d \u2192 \u201cRun anyway\u201d.</p>"},{"location":"reference_manual/#option-b-github-desktop-recommended-once-youre-comfortable","title":"Option B \u2014 GitHub Desktop (recommended once you\u2019re comfortable)","text":"<p>Use GitHub Desktop to keep your folder synced with GitHub.</p> <p>Day-to-day:</p> <ul> <li>Fetch checks for updates.</li> <li>Pull downloads updates.</li> <li>Commit records your changes.</li> <li>Push/Sync uploads your changes.</li> </ul>"},{"location":"reference_manual/#2-fetching-input-data-real-public-sources","title":"2) Fetching input data (real public sources)","text":"<p>Run these from the repo root (the folder that contains <code>pyproject.toml</code>).</p>"},{"location":"reference_manual/#markham-2018-budget-allocation-xlsx","title":"Markham (2018 Budget Allocation XLSX)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham\n</code></pre> <p>Expected file:</p> <ul> <li><code>cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></li> </ul>"},{"location":"reference_manual/#toronto-traffic-signals-timing-csv","title":"Toronto (Traffic signals timing \u2192 CSV)","text":"<p>Non-interactive default selection:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre> <p>Expected files:</p> <ul> <li><code>cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv</code></li> <li><code>cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv</code></li> </ul> <p>Toronto schema expected by HUF traffic adapters:</p> <ul> <li>required: <code>TCS</code>, <code>PHASE</code></li> <li>optional: <code>PHASE_STATUS_TEXT</code>, <code>PHASE_CALL_TEXT</code></li> </ul>"},{"location":"reference_manual/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>You\u2019ll end up with a FITS file such as:</p> <ul> <li><code>cases/planck70/inputs/...70...fits</code></li> </ul>"},{"location":"reference_manual/#3-running-the-included-cases-windows-powershell","title":"3) Running the included cases (Windows PowerShell)","text":""},{"location":"reference_manual/#a-markham-2018-fund-weighted-expenditures","title":"A) Markham 2018 (fund-weighted expenditures)","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre>"},{"location":"reference_manual/#b-toronto-traffic-phase-band-extraction","title":"B) Toronto traffic phase (band extraction)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre>"},{"location":"reference_manual/#c-toronto-traffic-anomaly-share-hotspots","title":"C) Toronto traffic anomaly (share + hotspots)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"reference_manual/#d-planck-70-ghz-map-coherence-stability","title":"D) Planck 70 GHz (map \u2192 coherence \u2192 stability)","text":"<pre><code>.\\.venv\\Scripts\\huf planck --fits cases/planck70/inputs/YOUR_70GHZ_MAP.fits --out out/planck70\n</code></pre>"},{"location":"reference_manual/#4-understanding-run_stampjson-your-reproducibility-receipt","title":"4) Understanding <code>run_stamp.json</code> (your reproducibility receipt)","text":"<p>HUF writes a stamp like:</p> <pre><code>{\n  \"dataset_id\": \"...\",\n  \"code_hash\": \"...\",\n  \"param_hash\": \"...\",\n  \"created_utc\": \"...\",\n  \"run_id\": \"...\"\n}\n</code></pre> <p>Interpretation:</p> <ul> <li><code>dataset_id</code> \u2014 identifier derived from the input file(s)</li> <li><code>code_hash</code> \u2014 identifier for the code state that produced artifacts</li> <li><code>param_hash</code> \u2014 identifier for your parameterization (\u03c4 grid, budgets, etc.)</li> <li><code>run_id</code> \u2014 unique run identifier</li> </ul> <p>If two runs have the same <code>dataset_id + code_hash + param_hash</code>, their artifacts should match (modulo timestamps).</p>"},{"location":"reference_manual/#5-troubleshooting-windows-focused","title":"5) Troubleshooting (Windows-focused)","text":""},{"location":"reference_manual/#ssl-certificate_verify_failed","title":"\u201cSSL: CERTIFICATE_VERIFY_FAILED\u201d","text":"<p>Try:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\python -m pip install certifi\n.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"reference_manual/#http-error-404-during-toronto-fetch","title":"\u201cHTTP Error 404\u201d during Toronto fetch","text":"<p>Default:</p> <ul> <li><code>https://open.toronto.ca/api/3/action</code></li> </ul> <p>Override explicitly:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes --toronto-ckan https://open.toronto.ca/api/3/action\n</code></pre>"},{"location":"reference_manual/#file-not-found-casesinputs","title":"\u201cFile not found \u2026 cases/.../inputs/...\u201d","text":"<p>Run fetch first:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"reference_manual/#6-build-preview-the-docs-site","title":"6) Build / preview the docs site","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Strict build check:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs build --strict\n</code></pre>"},{"location":"running_examples/","title":"Running examples on Windows, macOS, and Linux","text":"<p>This project is cross\u2011platform, but the shell syntax is not. Most \u201cit broke when I pasted it\u201d problems come from mixing:</p> <ul> <li>PowerShell commands (Windows) vs bash/zsh commands (macOS/Linux)</li> <li>Shell commands vs the Python REPL (<code>&gt;&gt;&gt;</code> prompt)</li> </ul> <p>This page gives copy/paste\u2011safe patterns and explains why each one exists.</p>"},{"location":"running_examples/#which-terminal-should-i-use","title":"Which terminal should I use?","text":"WindowsmacOS / Linux <p>Recommended:</p> <ul> <li>Windows Terminal + PowerShell 7+ (best copy/paste behavior)</li> <li>PowerShell 5.1 also works, but line continuations and paste handling are fussier.</li> </ul> <p>If pasting turns <code>.</code> into <code>[</code> or auto\u2011enters mid\u2011paste, update PSReadLine (this fixes most \u201cweird paste\u201d bugs):</p> <pre><code>Install-Module PSReadLine -Scope CurrentUser -Force -AllowClobber\n# close the terminal completely, then open a NEW PowerShell session\n</code></pre> <p>Use your default terminal with bash or zsh.</p> <ul> <li>Most docs and one\u2011liners online assume bash/zsh.</li> <li><code>python - &lt;&lt;'PY' ... PY</code> (heredoc) works here, not in PowerShell.</li> </ul>"},{"location":"running_examples/#shell-vs-python-how-to-tell-what-youre-typing-into","title":"Shell vs Python: how to tell what you\u2019re typing into","text":"<ul> <li> <p>If your prompt looks like:</p> </li> <li> <p><code>PS C:\\...&gt;</code> \u2192 you are in PowerShell</p> </li> <li><code>$</code> \u2192 you are in bash/zsh</li> <li><code>&gt;&gt;&gt;</code> \u2192 you are in Python (the REPL)</li> </ul> <p>Rule:</p> <ul> <li>Run <code>huf ...</code> and <code>python some_script.py ...</code> in the shell.</li> <li>Run <code>import ...</code> and <code>print(...)</code> inside Python, or via <code>python -c</code> / a script.</li> </ul> <p>Why this matters:</p> <ul> <li>In PowerShell, <code>print</code> is not Python \u2014 it\u2019s a shell command/alias that tries to print to a printer (the \u201cPRN\u201d device), which is why you saw:</li> </ul> <pre><code>Unable to initialize device PRN\n</code></pre>"},{"location":"running_examples/#recommended-pattern-run-the-provided-scripts-not-pasted-python","title":"Recommended pattern: run the provided scripts (not pasted Python)","text":"<p>The repo includes helper scripts like:</p> <ul> <li><code>scripts/inspect_huf_artifacts.py</code> (quick dashboard)</li> <li><code>scripts/run_vector_db_concentration_delta.py</code> (compare tau settings)</li> </ul> <p>These are intentionally paste\u2011friendly and avoid REPL confusion.</p>"},{"location":"running_examples/#multiline-python-snippets-when-you-really-need-them","title":"Multi\u2011line Python snippets (when you really need them)","text":""},{"location":"running_examples/#option-a-recommended-save-a-py-file","title":"Option A (recommended): save a <code>.py</code> file","text":"<p>This is the most reliable approach for beginners and teams.</p>"},{"location":"running_examples/#option-b-pipe-a-herestring-heredoc-into-python-","title":"Option B: pipe a here\u2011string / heredoc into <code>python -</code>","text":"Windows (PowerShell)macOS / Linux (bash/zsh) <p>PowerShell does not support bash heredocs (<code>&lt;&lt;'PY'</code>). Use a here\u2011string piped into Python:</p> <pre><code>$py = \".\\\\.venv\\\\Scripts\\\\python.exe\"\n\n@'\nimport sys\nprint(\"Hello from stdin\", sys.version)\n'@ | &amp; $py -\n</code></pre> <pre><code>./.venv/bin/python - &lt;&lt;'PY'\nimport sys\nprint(\"Hello from stdin\", sys.version)\nPY\n</code></pre> <p>What to expect:</p> <ul> <li><code>python -</code> means \u201cread the program from stdin\u201d.</li> <li>If you see syntax errors before Python starts, it\u2019s a shell syntax mismatch.</li> </ul>"},{"location":"running_examples/#worked-examples","title":"Worked examples","text":"<p>Below are the three examples most people start with. Each one has:</p> <ul> <li>Why run it (what question it answers)</li> <li>How to run it (Windows + macOS/Linux)</li> <li>What you should see (expected outputs)</li> <li>How to inspect/plot results</li> </ul>"},{"location":"running_examples/#example-1-vector-db-coherence-retrieval-audit","title":"Example 1 \u2014 Vector DB coherence (retrieval audit)","text":"<p>Why run it:</p> <ul> <li>Check whether a retrieval result set is dominated by one namespace/source/tenant.</li> <li>Quantify concentration (\u201chow many items explain 90% of the mass?\u201d).</li> </ul> <p>See the full walkthrough: Vector DB coherence.</p>"},{"location":"running_examples/#example-2-concentration-delta-tau-sensitivity","title":"Example 2 \u2014 Concentration delta (tau sensitivity)","text":"<p>Why run it:</p> <ul> <li>Compare two <code>tau</code> settings to see if concentration is stable or sensitive.</li> </ul> <p>What you should expect:</p> <ul> <li>It runs two sub\u2011runs (A and B) and reports whether the \u201citems_to_cover_90pct\u201d headline changes.</li> </ul>"},{"location":"running_examples/#example-3-planck-70-ghz-fits-huf","title":"Example 3 \u2014 Planck 70 GHz (FITS \u2192 HUF)","text":"<p>Why run it:</p> <ul> <li>A \u201creal physics\u201d example that produces a non\u2011toy output and demonstrates the pipeline on scientific data.</li> </ul> <p>See the worked page: Planck 70 GHz worked example.</p>"},{"location":"running_examples/#plots-and-visual-sanity-checks","title":"Plots and visual sanity checks","text":"<p>If you want charts (recommended when presenting results), install matplotlib:</p> WindowsmacOS / Linux <pre><code>&amp; .\\.venv\\Scripts\\python.exe -m pip install matplotlib\n</code></pre> <pre><code>./.venv/bin/python -m pip install matplotlib\n</code></pre> <p>Then generate plots from any output folder:</p> <pre><code>python scripts/plot_huf_artifacts.py --out out/vector_db_demo\n</code></pre> <p>Outputs (saved under <code>&lt;out&gt;/plots/</code>):</p> <ul> <li><code>coherence_by_regime.png</code> \u2014 bar chart of <code>rho_global_post</code> by regime</li> <li><code>concentration_curve.png</code> \u2014 cumulative coverage curve + the 90% cutoff</li> </ul>"},{"location":"start_here/","title":"Start Here (Developer)","text":"<p>This page assumes you already have the repo locally (git clone or GitHub Desktop).</p> <p>Goal: get a working <code>.venv</code>, fetch inputs, run demos.</p> <p>Run commands from the repo root (folder containing <code>pyproject.toml</code>).</p>"},{"location":"start_here/#windows-powershell","title":"Windows (PowerShell)","text":""},{"location":"start_here/#create-venv-install-dev-docs-deps","title":"Create venv + install (dev + docs deps)","text":"<p><code>bootstrap.py</code> creates <code>.venv</code> and installs the pinned docs stack (MkDocs + Material):</p> <pre><code>python scripts/bootstrap.py\n</code></pre>"},{"location":"start_here/#ensure-the-repo-venv-huf-wins-over-conda","title":"Ensure the repo venv <code>huf</code> wins over conda","text":"<p>Prefer calling the repo executables explicitly:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"start_here/#fetch-inputs","title":"Fetch inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"start_here/#run-demos","title":"Run demos","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"start_here/#planck-optional","title":"Planck (optional)","text":"<pre><code>.\\.venv\\Scripts\\python -m pip install \"astropy&gt;=6.0\"\n.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n# (place the FITS at cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits)\n.\\.venv\\Scripts\\huf planck --fits cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits --out out/planck70 --retained-target 0.97 --nside-out 64\n</code></pre>"},{"location":"start_here/#docs-local","title":"Docs (local)","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"start_here/#macos-linux-bashzsh","title":"macOS / Linux (bash/zsh)","text":"<pre><code>python3 scripts/bootstrap.py\n./.venv/bin/python scripts/fetch_data.py --markham --toronto --yes\n./.venv/bin/huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n./.venv/bin/huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n./.venv/bin/huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n./.venv/bin/python -m mkdocs serve\n</code></pre>"},{"location":"theory_notes/","title":"Theory Notes (HUF / UBH)","text":"<p>Updated: 2026-02-17</p> <p>This repo is deliberately artifact-first: you can run real datasets and inspect outputs without accepting any theory claims.</p> <p>If you do want the formal structure (definitions, taxonomy, and expanded proofs), see:</p> <ul> <li><code>docs/The_Higgins_Unity_Framework.md</code> (full theoretical handbook)</li> <li>Handbook (conceptual + case-study narrative)</li> </ul>"},{"location":"theory_notes/#what-huf-is-in-one-paragraph","title":"What HUF is (in one paragraph)","text":"<p>HUF is a reproducibility wrapper around a single contract: a Unity\u2011Budgeted Hierarchy (UBH). A UBH is a hierarchy where each node\u2019s outgoing weights form a budgeted, normalized distribution (a \u201cunity\u201d constraint). HUF turns inputs into UBH elements, then emits auditable artifacts (tables, maps, images) plus a stability sweep that shows what structure survives across \u03c4.</p>"},{"location":"theory_notes/#why-unity-budget-matters","title":"Why \u201cunity budget\u201d matters","text":"<p>In practice, a unity budget behaves like a conserved quantity: - it forces competing explanations to share the same budget, - it makes comparisons across scales meaningful (local vs global), - it makes stability sweeps interpretable (what stays when \u03c4 tightens?).</p> <p>This was originally motivated by loudspeaker dispersion/diffraction work, but the same contract applies anywhere \u201cparts must sum to a whole\u201d.</p>"},{"location":"theory_notes/#proof-burden-and-how-huf-helps","title":"Proof burden and how HUF helps","text":"<p>HUF does not ask you to \u201cbelieve the proof.\u201d It asks you to: 1) run the same public dataset, 2) confirm you get the same artifacts, 3) inspect the stability packet, 4) only then argue about interpretation.</p> <p>That\u2019s why every run writes a <code>run_stamp.json</code>.</p>"},{"location":"traffic_phase_worked_example/","title":"Traffic Phase worked example (Toronto signals)","text":"<p>Run baseline:</p> <pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre> <p>Run exception-only:</p> <pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre> <p>See: - Long tail (accounting lens)</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This page collects common \u201cWindows reality\u201d problems people hit when they\u2019re new to Python tooling.</p>"},{"location":"troubleshooting/#i-typed-huf-and-got-syntaxerror","title":"\u201cI typed <code>huf ...</code> and got <code>SyntaxError</code>\u201d","text":"<p>If you see this:</p> <ul> <li><code>&gt;&gt;&gt; huf traffic ...</code></li> <li><code>SyntaxError: invalid syntax</code></li> </ul> <p>\u2026you typed a shell command inside Python.</p> <p>Fix:</p> <p>1) exit Python: type <code>exit()</code> (or Ctrl+Z then Enter) 2) run the command in PowerShell:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"troubleshooting/#make-is-not-recognized","title":"\u201c<code>make</code> is not recognized\u201d","text":"<p>Windows does not ship <code>make</code>.</p> <p>For the Planck download guide, use:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre>"},{"location":"troubleshooting/#venv-exists-but-commands-run-the-wrong-python","title":"\u201c.venv exists but commands run the wrong Python\u201d","text":"<p>If you see paths like <code>miniconda3\\Scripts\\huf.exe</code>, you\u2019re running a global install, not the repo venv.</p> <p>Use the venv explicitly:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"troubleshooting/#mkdocs-warning-about-mkdocs-20","title":"MkDocs warning about \u201cMkDocs 2.0\u201d","text":"<p>Material for MkDocs currently expects a pinned MkDocs 1.x stack.</p> <p>This repo pins:</p> <ul> <li><code>mkdocs==1.6.1</code></li> <li><code>mkdocs-material==9.7.2</code></li> </ul> <p>Fix:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install \"mkdocs==1.6.1\" \"mkdocs-material==9.7.2\"\n</code></pre> <p>Then always run:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"troubleshooting/#ssl-certificate-errors-certificate_verify_failed","title":"SSL certificate errors (CERTIFICATE_VERIFY_FAILED)","text":"<p>Fix:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install certifi\n.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"vector_db_coherence/","title":"Vector DB coherence (from retrieval results)","text":"<p>This adapter analyzes a set of retrieval hits (e.g., from a vector database) and answers:</p> <ul> <li>Which regimes dominate the retrieved set? (e.g., <code>namespace</code>, <code>tenant</code>, <code>source</code>, \u2026)</li> <li>How concentrated is the set? (e.g., \u201chow many items explain 90% of the mass?\u201d)</li> </ul> <p>If you\u2019re coming from outside \u201cadvanced computation\u201d: think of this as a retrieval audit that turns a pile of ranked results into a small, explainable report.</p> <p>If you ever see PowerShell \u201cdoing weird things\u201d when you paste commands, start with Running examples on Windows/macOS/Linux.</p>"},{"location":"vector_db_coherence/#why-run-this","title":"Why run this","text":"<p>Run this when you want to validate that:</p> <ul> <li>Your retrieval isn\u2019t silently dominated by one bucket (a single namespace/tenant/source)</li> <li>Small parameter changes (like <code>tau</code>) don\u2019t create unstable, misleading concentration</li> </ul>"},{"location":"vector_db_coherence/#input-retrieval-export-jsonl","title":"Input: retrieval export (<code>.jsonl</code>)","text":"<p>The demo input is a JSON Lines file (one JSON object per line) containing:</p> <ul> <li><code>id</code> (string)</li> <li><code>score</code> (float)</li> <li>a regime field such as <code>namespace</code></li> </ul> <p>Example line:</p> <pre><code>{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n</code></pre>"},{"location":"vector_db_coherence/#run-the-demo","title":"Run the demo","text":""},{"location":"vector_db_coherence/#1-set-paths","title":"1) Set paths","text":"Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>$py  = \".\\\\.venv\\\\Scripts\\\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_demo\"\n</code></pre> <pre><code>py=\"./.venv/bin/python\"\nin=\"cases/vector_db/inputs/retrieval.jsonl\"\nout=\"out/vector_db_demo\"\n</code></pre>"},{"location":"vector_db_coherence/#2-create-a-tiny-demo-input-optional","title":"2) Create a tiny demo input (optional)","text":"<p>If you already have a retrieval export, skip this.</p> Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>New-Item -ItemType Directory -Force (Split-Path $in) | Out-Null\n\n@'\n{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_002\",\"score\":0.63,\"namespace\":\"kb\",\"source\":\"manual\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n{\"id\":\"doc_102\",\"score\":0.12,\"namespace\":\"tickets\",\"source\":\"ops\"}\n'@ | Set-Content -Encoding utf8 $in\n</code></pre> <pre><code>mkdir -p \"$(dirname \"$in\")\"\ncat &gt; \"$in\" &lt;&lt;'JSONL'\n{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_002\",\"score\":0.63,\"namespace\":\"kb\",\"source\":\"manual\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n{\"id\":\"doc_102\",\"score\":0.12,\"namespace\":\"tickets\",\"source\":\"ops\"}\nJSONL\n</code></pre>"},{"location":"vector_db_coherence/#3-run-the-example","title":"3) Run the example","text":"Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>New-Item -ItemType Directory -Force $out | Out-Null\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n</code></pre> <pre><code>mkdir -p \"$out\"\n\n\"$py\" examples/run_vector_db_demo.py \\\n  --in \"$in\" \\\n  --out \"$out\" \\\n  --tau-global 0.02 \\\n  --regime-field namespace\n</code></pre>"},{"location":"vector_db_coherence/#what-you-should-see","title":"What you should see","text":"<pre><code>[OK] Wrote artifacts to: out\\vector_db_demo\n</code></pre> <p>Artifacts are written to:</p> <ul> <li><code>out/vector_db_demo/</code></li> </ul>"},{"location":"vector_db_coherence/#inspect-the-artifacts-recommended","title":"Inspect the artifacts (recommended)","text":"<p>Why: this is the fastest way to verify the run produced real numbers and to find the CSV files you can open in Excel / pandas.</p> Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>&amp; $py scripts/inspect_huf_artifacts.py --out $out\n</code></pre> <pre><code>\"$py\" scripts/inspect_huf_artifacts.py --out \"$out\"\n</code></pre>"},{"location":"vector_db_coherence/#expected-output-example","title":"Expected output (example)","text":"<pre><code>[out] ...\\out\\vector_db_demo\n[tail] items_to_cover_90pct=3\n\nTop regimes by rho_global_post:\n  1. kb       rho_post=0.619658\n  2. tickets  rho_post=0.380342\n</code></pre>"},{"location":"vector_db_coherence/#compare-two-tau-values-concentration-delta","title":"Compare two tau values (concentration delta)","text":"<p>Why: check whether your concentration headline is stable.</p> Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>$out = \"out/vector_db_delta\"\n\n&amp; $py scripts/run_vector_db_concentration_delta.py `\n  --in $in `\n  --out $out `\n  --tau-a 0.005 `\n  --tau-b 0.02 `\n  --regime-field namespace\n</code></pre> <pre><code>out=\"out/vector_db_delta\"\n\n\"$py\" scripts/run_vector_db_concentration_delta.py \\\n  --in \"$in\" \\\n  --out \"$out\" \\\n  --tau-a 0.005 \\\n  --tau-b 0.02 \\\n  --regime-field namespace\n</code></pre> <p>What you should see:</p> <ul> <li>Two sub\u2011runs under <code>out/vector_db_delta/</code> (one per tau)</li> <li>A headline like:</li> </ul> <pre><code>Concentration unchanged: items_to_cover_90pct 3 -&gt; 3\n</code></pre>"},{"location":"vector_db_coherence/#plots-optional-but-great-for-presentations","title":"Plots (optional, but great for presentations)","text":"<p>If you want charts, install matplotlib:</p> WindowsmacOS / Linux <pre><code>&amp; .\\.venv\\Scripts\\python.exe -m pip install matplotlib\n</code></pre> <pre><code>./.venv/bin/python -m pip install matplotlib\n</code></pre> <p>Then generate plots for any output folder:</p> <pre><code>python scripts/plot_huf_artifacts.py --out out/vector_db_demo\n</code></pre> <p>This writes images under <code>&lt;out&gt;/plots/</code>.</p> <p>Example charts (from the tiny demo input):</p> <p></p> <p></p>"},{"location":"vector_db_coherence/#common-pitfalls","title":"Common pitfalls","text":"<ul> <li>PowerShell is not Python. If you type <code>import pandas as pd</code> at <code>PS C:\\...&gt;</code> it will fail.</li> <li><code>python - &lt;&lt;'PY'</code> is bash\u2011only. On Windows PowerShell, use the here\u2011string pattern from <code>running_examples.md</code>.</li> <li>If you see <code>Unable to initialize device PRN</code>, you likely ran <code>print(...)</code> in PowerShell instead of Python.</li> </ul>"},{"location":"vector_db_coherence_one_pager/","title":"Vector DB coherence (one\u2011pager)","text":"<p>This is the quickest way to run the \u201cretrieval audit\u201d demo and confirm the output is real.</p> <p>If you want the deeper explanation, plots, and tau\u2011sensitivity checks, go to Vector DB coherence.</p>"},{"location":"vector_db_coherence_one_pager/#run","title":"Run","text":"Windows (PowerShell)macOS / Linux (bash/zsh) <pre><code>$py  = \".\\\\.venv\\\\Scripts\\\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_demo\"\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out $out\n</code></pre> <pre><code>py=\"./.venv/bin/python\"\nin=\"cases/vector_db/inputs/retrieval.jsonl\"\nout=\"out/vector_db_demo\"\n\n\"$py\" examples/run_vector_db_demo.py \\\n  --in \"$in\" \\\n  --out \"$out\" \\\n  --tau-global 0.02 \\\n  --regime-field namespace\n\n\"$py\" scripts/inspect_huf_artifacts.py --out \"$out\"\n</code></pre>"},{"location":"vector_db_coherence_one_pager/#what-you-should-see","title":"What you should see","text":"<ul> <li><code>[OK] Wrote artifacts to: out\\vector_db_demo</code></li> <li> <p>A short dashboard including:</p> </li> <li> <p><code>items_to_cover_90pct=...</code></p> </li> <li>\u201cTop regimes by rho_global_post\u201d</li> </ul>"},{"location":"vector_db_coherence_one_pager/#if-paste-behaves-strangely-windows","title":"If paste behaves strangely (Windows)","text":"<p>See Running examples on Windows/macOS/Linux for the PSReadLine fix and safe multi\u2011line patterns.</p>"},{"location":"windows_powershell_vs_python/","title":"PowerShell vs Python (Windows-safe)","text":""},{"location":"windows_powershell_vs_python/#windows-note-powershell-does-not-support-py-heredocs","title":"Windows note: PowerShell does not support <code>&lt;&lt;'PY'</code> heredocs","text":"<p>If you see examples like this on the internet:</p> <pre><code>python - &lt;&lt;'PY'\nprint(\"hello\")\nPY\n</code></pre> <p>That is bash syntax, not PowerShell.</p>"},{"location":"windows_powershell_vs_python/#do-this-instead-powershell-repo-venv","title":"Do this instead (PowerShell + repo venv)","text":"<p>Option A \u2014 run a helper script (recommended):</p> <pre><code>.\\.venv\\Scripts\\python scripts/inspect_artifact_tables.py --out out/planck70 --top 10\n</code></pre> <p>Option B \u2014 start Python explicitly, then type Python:</p> <pre><code>$py = \".\\.venv\\Scripts\\python.exe\"\n&amp; $py\n</code></pre> <p>Now your prompt changes to <code>&gt;&gt;&gt;</code> and you can run:</p> <pre><code>import sys\nprint(sys.executable)\n</code></pre> <p>Why you saw <code>Unable to initialize device PRN</code></p> <p>In PowerShell, <code>print</code> is a Windows command (printer), not Python. If you run <code>print(...)</code> in PowerShell, it tries to print to <code>PRN</code>.</p>"},{"location":"partnerships/","title":"Partnerships","text":"<p>This section is the \u201cgo-to-market\u201d sibling of the technical docs.</p> <p>HUF is easiest to understand when you can run it in 60 seconds, then show a colleague:</p> <ul> <li>Where the mass is (coherence map)</li> <li>What to review first (active set)</li> <li>What was dropped, explicitly (error budget)</li> <li>Why something survived (trace)</li> </ul> <p>Partnership pages package that into \u201cPR + proof + two commands\u201d.</p>"},{"location":"partnerships/#current-packages","title":"Current packages","text":""},{"location":"partnerships/#weaviate","title":"Weaviate","text":"<ul> <li>Weaviate outreach package: <code>partnerships/weaviate_outreach.md</code></li> </ul> <p>This includes: - PR title + description (ready to paste) - a short follow\u2011up email template (send after PR link exists) - Windows-safe commands and expected output shape</p>"},{"location":"partnerships/#next-targets","title":"Next targets","text":"<p>These are \u201cstubs\u201d for now \u2014 add packages as you build them:</p> <ul> <li>Qdrant (collection / payload coherence)</li> <li>Pinecone (namespace dominance / multi\u2011tenant audit)</li> <li>LangChain / LlamaIndex (retrieval callback \u2192 coherence report)</li> </ul>"},{"location":"partnerships/#ground-rule","title":"Ground rule","text":"<p>PR first, email second. A reviewable PR is the best proof artifact: it reduces meeting overhead and makes the ask concrete.</p>"},{"location":"partnerships/dissemination/","title":"Dissemination checklist","text":"<p>This is the repeatable \u201cno meeting required\u201d distribution strategy.</p> <p>1) Publish the partner package in docs (stable link) 2) Open a PR in the partner\u2019s examples repo (proof artifact) 3) Post PR link in a community channel (Slack/Discord/GitHub Discussion) 4) Email partner manager with PR link in the first paragraph 5) Follow up once after 5\u20137 business days 6) Offer one co-authored asset: short blog outline + screenshot/plots</p> <p>Metrics to track: - PR merged - integration directory listing - partner blog post published - inbound GitHub stars / clones from partner referral - repeatable proof line shared by others</p> <p>Tip: keep every demo \u201ctwo commands\u201d and Windows-safe.</p>"},{"location":"partnerships/partner_playbook/","title":"Partner playbook","text":"<p>This is the repeatable process to \u201cdisseminate HUF\u201d in partner ecosystems without relying on meetings.</p>"},{"location":"partnerships/partner_playbook/#1-pick-the-regime-field","title":"1) Pick the regime field","text":"<p>Your partner will already have a natural grouping field:</p> <ul> <li><code>namespace</code> (multi-tenant VDB)</li> <li><code>collection</code> (collection-based VDB)</li> <li><code>tenant</code> (explicit tenant isolation)</li> <li><code>source</code> / <code>connector</code> (enterprise search)</li> </ul> <p>HUF uses this as <code>--regime-field</code>.</p>"},{"location":"partnerships/partner_playbook/#2-export-retrieval-or-events-to-jsonl","title":"2) Export retrieval (or events) to JSONL","text":"<p>HUF input is JSONL:</p> <ul> <li>one JSON object per line</li> <li>required: <code>id</code>, <code>score</code> (higher = better)</li> <li>optional: <code>namespace</code>/<code>collection</code>/<code>tenant</code>/<code>source</code> + any metadata you want in the trace</li> </ul> <p>Distance metrics? Convert once:</p> <p><code>score = 1 / (1 + distance)</code></p>"},{"location":"partnerships/partner_playbook/#3-run-in-two-commands-windows-safe","title":"3) Run in two commands (Windows-safe)","text":"<pre><code>$py  = \".\\.venv\\Scripts\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/partner_demo\"\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out $out\n</code></pre> <p>Expected shape:</p> <pre><code>[tail] items_to_cover_90pct=3\n\nTop regimes by rho_global_post:\n  1. kb       rho_post=0.619658\n  2. tickets  rho_post=0.380342\n</code></pre>"},{"location":"partnerships/partner_playbook/#4-produce-the-proof-line","title":"4) Produce the \u201cproof line\u201d","text":"<p>People repeat a single number.</p> <p>Run two tau settings and print:</p> <p><code>Concentration increased: items_to_cover_90pct X -&gt; Y</code></p> <pre><code>$py  = \".\\.venv\\Scripts\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_delta\"\n\n&amp; $py scripts/run_vector_db_concentration_delta.py `\n  --in $in `\n  --out $out `\n  --tau-a 0.005 `\n  --tau-b 0.02 `\n  --regime-field namespace\n</code></pre>"},{"location":"partnerships/partner_playbook/#5-publish-the-case-study","title":"5) Publish the case study","text":"<p>A partner-ready page should always contain:</p> <ul> <li>the problem (dominance + concentration + discards)</li> <li>the two commands</li> <li>the four artifacts and how to interpret them</li> <li>what changed after adjusting tau (proof line)</li> <li>links to the repo + docs</li> </ul>"},{"location":"partnerships/partner_playbook/#6-outreach-sequence","title":"6) Outreach sequence","text":"<p>1) Open PR 2) Post PR link to partner community channel 3) Send short email (PR link first paragraph) 4) Follow up once after 5\u20137 business days</p> <p>Keep everything \u201cartifact-first\u201d.</p>"},{"location":"partnerships/partner_program/","title":"HUF partner program","text":"<p>HUF is an artifact-first audit layer for long-tail distributions in hierarchical systems (budgets, logs, exceptions, retrieval outputs).</p> <p>This partner program exists to make integrations predictable and repeatable:</p> <ul> <li>PR-first (a proof artifact)</li> <li>two commands (Windows/Conda friendly)</li> <li>four contract artifacts (coherence map, active set, trace, error budget)</li> <li>one proof line (e.g., <code>items_to_cover_90pct 37 -&gt; 12</code>)</li> </ul>"},{"location":"partnerships/partner_program/#what-partners-get","title":"What partners get","text":""},{"location":"partnerships/partner_program/#technical-deliverables","title":"Technical deliverables","text":"<ul> <li>A minimal integration that converts a partner\u2019s output into HUF JSONL (<code>id</code>, <code>score</code>, plus a regime field like <code>namespace</code>/<code>collection</code>/<code>tenant</code>)</li> <li>A runnable example (no notebooks required)</li> <li>A dashboard command (<code>inspect_huf_artifacts.py</code>) that prints:</li> <li>top regimes by <code>rho_global_post</code></li> <li><code>items_to_cover_90pct</code></li> <li>discarded budget from <code>artifact_4_error_budget.json</code></li> </ul>"},{"location":"partnerships/partner_program/#content-deliverables","title":"Content deliverables","text":"<ul> <li>A one-pager or \u201cfull picture\u201d explainer (for a PR + email link)</li> <li>A case study page (problem \u2192 run \u2192 artifacts \u2192 interpretation)</li> <li>Optional: plots (coherence bars + concentration curve)</li> </ul>"},{"location":"partnerships/partner_program/#program-tiers","title":"Program tiers","text":""},{"location":"partnerships/partner_program/#tier-0-community-example","title":"Tier 0 \u2014 Community example","text":"<p>Goal: get merged into the partner\u2019s examples repo.</p> <p>Deliverables: - README + sample JSONL + 1\u20132 commands - expected output section (copy/paste safe) - license-compatible sample data</p>"},{"location":"partnerships/partner_program/#tier-1-integration-listing","title":"Tier 1 \u2014 Integration listing","text":"<p>Goal: partner lists HUF in an integrations directory.</p> <p>Deliverables: - stable folder path + docs link - \u201chow it works\u201d explainer - screenshot-style artifact interpretation</p>"},{"location":"partnerships/partner_program/#tier-2-co-authored-post","title":"Tier 2 \u2014 Co-authored post","text":"<p>Goal: joint blog post explaining why (observability + governance), with a runnable demo.</p> <p>Deliverables: - blog outline + diagrams - repeatable proof line (<code>items_to_cover_90pct X -&gt; Y</code>) - repo link + docs link</p>"},{"location":"partnerships/partner_program/#tier-3-strategic-enterprise-public-sector","title":"Tier 3 \u2014 Strategic (enterprise / public sector)","text":"<p>Goal: pilot with real customer data and governance needs.</p> <p>Deliverables: - runbook (audit controls, trace retention, reporting) - \u201cgovernance pack\u201d (trace report + discard ledger) - optional: SOC2 / ISO-aligned mapping</p>"},{"location":"partnerships/partner_program/#partner-targets","title":"Partner targets","text":""},{"location":"partnerships/partner_program/#vector-dbs","title":"Vector DBs","text":"<ul> <li>Weaviate</li> <li>Qdrant</li> <li>Pinecone</li> <li>Milvus / Zilliz</li> </ul>"},{"location":"partnerships/partner_program/#rag-orchestration","title":"RAG orchestration","text":"<ul> <li>LangChain</li> <li>LlamaIndex</li> </ul>"},{"location":"partnerships/partner_program/#evaluation-observability","title":"Evaluation / observability","text":"<ul> <li>Arize Phoenix</li> <li>Weights &amp; Biases</li> <li>Ragas</li> </ul>"},{"location":"partnerships/partner_program/#enterprise-rag-platforms","title":"Enterprise RAG platforms","text":"<ul> <li>Glean</li> <li>Vectara</li> </ul>"},{"location":"partnerships/partner_program/#public-sector-science","title":"Public sector + science","text":"<ul> <li>Municipal budgets and logs (Markham / Toronto)</li> <li>Scientific computing validation (Planck 70 GHz)</li> </ul>"},{"location":"partnerships/partner_program/#operating-rule","title":"Operating rule","text":"<p>PR first, email second. A reviewable PR is the highest-leverage artifact: it reduces meetings and makes the ask concrete.</p>"},{"location":"partnerships/templates/","title":"Outreach templates","text":"<p>These are intentionally short. The PR is the proof artifact; the message just points to it.</p>"},{"location":"partnerships/templates/#pr-title","title":"PR title","text":"<p><code>feat: HUF coherence adapter \u2014 retrieval audit for &lt;Partner&gt; exports (dominance + concentration + declared discards)</code></p>"},{"location":"partnerships/templates/#pr-description","title":"PR description","text":"<ul> <li>Adds a minimal example showing how to run a HUF coherence audit on exports  </li> <li>Answers: dominant regimes, concentration (<code>items_to_cover_90pct</code>), declared discards (error budget) </li> <li>No live connection required \u2014 JSONL in, HUF artifacts out  </li> </ul> <p>Two-command demo (Windows-safe):</p> <pre><code>$py = \".\\.venv\\Scripts\\python.exe\"\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in cases/vector_db/inputs/retrieval.jsonl `\n  --out out/vector_db_demo `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out out/vector_db_demo\n</code></pre> <p>Expected output shape:</p> <pre><code>[tail] items_to_cover_90pct=3\nTop regimes by rho_global_post:\n  1. kb       rho_post=0.619658\n  2. tickets  rho_post=0.380342\n</code></pre>"},{"location":"partnerships/templates/#email-send-after-pr-exists","title":"Email (send after PR exists)","text":"<p>Subject: <code>HUF coherence audit for &lt;Partner&gt; exports \u2014 PR open</code></p> <p>Body:</p> <pre><code>Hi &lt;Name&gt;,\n\nI'm Peter Higgins, author of HUF Core \u2014 an artifact-first audit tool for long-tail distributions in retrieval outputs.\n\nI opened a PR that adds a HUF coherence audit example for &lt;Partner&gt; exports: &lt;PR link&gt;.\n\nIt runs in two commands and outputs:\n- a regime ranking (rho_global_post)\n- a concentration number (items_to_cover_90pct)\n- an explicit discard ledger (error budget) + trace report\n\nThis surfaces silent regime dominance that retrieval metrics can miss.\n\nDocs: &lt;docs link&gt;\n\nPeter Higgins\n</code></pre>"},{"location":"partnerships/templates/#community-post-slack-discord-github-discussion","title":"Community post (Slack / Discord / GitHub Discussion)","text":"<p>One-liner:</p> <p><code>Opened a PR adding a HUF coherence audit example for &lt;Partner&gt; exports \u2014 dominance + concentration + declared discards. Feedback welcome: &lt;PR link&gt;</code></p>"},{"location":"partnerships/weaviate_full_picture/","title":"Weaviate \u00d7 HUF \u2014 the full picture","text":"<p>This is a technical explainer you can link in an email alongside the PR. It answers four questions in order:</p> <p>1) What Weaviate is (what a vector database actually does) 2) The gap (what retrieval metrics miss in multi\u2011source deployments) 3) Why HUF (audit layer: dominance + concentration + declared discards) 4) The export (what to export, the one transform, and what artifacts mean)</p>"},{"location":"partnerships/weaviate_full_picture/#read-the-visual-onepager-html","title":"Read the visual one\u2011pager (HTML)","text":"<p>If you want the \u201cdiagram + bars + story\u201d version:</p> <ul> <li><code>partnerships/weaviate_full_picture.html</code></li> </ul> <p>(That file is included in the repo and served by MkDocs as a static asset.)</p>"},{"location":"partnerships/weaviate_full_picture/#part-1-what-weaviate-actually-is","title":"Part 1 \u2014 What Weaviate actually is","text":"<p>Vector DBs store objects and vectors together and retrieve by semantic similarity. In RAG, the top\u2011k retrieved chunks become the LLM context window.</p> <p>In real deployments, retrieval often spans multiple sources (collections, namespaces, tenants, \u201cindexes\u201d, etc.). That\u2019s where audits matter.</p>"},{"location":"partnerships/weaviate_full_picture/#part-2-the-gap-silent-dominance","title":"Part 2 \u2014 The gap (silent dominance)","text":"<p>Weaviate (and most vector DBs) return item scores, and you can track latency and ranking metrics.</p> <p>But they don\u2019t natively answer:</p> <ul> <li>Which source dominated after retrieval ran?</li> <li>How concentrated is the result mass (one number)?</li> <li>What got dropped below a boundary \u2014 explicitly, as a ledger?</li> </ul> <p>It\u2019s possible for headline metrics to look \u201cgreen\u201d while one namespace supplies most results.</p>"},{"location":"partnerships/weaviate_full_picture/#part-3-why-huf-audit-layer","title":"Part 3 \u2014 Why HUF (audit layer)","text":"<p>HUF is not a replacement for Weaviate.</p> <p>HUF takes an offline export of retrieval output and writes contract artifacts:</p> <ul> <li>artifact_1_coherence_map.csv \u2014 regime ranking (<code>rho_global_post</code>)</li> <li>artifact_2_active_set.csv \u2014 ranked review list (global + within\u2011regime)</li> <li>artifact_3_trace_report.jsonl \u2014 \u201cworkpapers\u201d / provenance trace</li> <li>artifact_4_error_budget.json \u2014 explicit discard ledger</li> </ul> <p>One headline users remember:</p> <p><code>items_to_cover_90pct = k</code> The top k retained items explain 90% of post\u2011normalized mass.</p>"},{"location":"partnerships/weaviate_full_picture/#part-4-the-export-what-huf-needs","title":"Part 4 \u2014 The export (what HUF needs)","text":"<p>HUF input is JSONL:</p> <ul> <li>One JSON object per line</li> <li>Required fields: <code>id</code>, <code>score</code> (higher = better)</li> <li>Optional: grouping fields like <code>namespace</code>, <code>collection</code>, <code>tenant</code>, <code>source</code></li> </ul> <p>Distance metrics? Convert once:</p> <ul> <li><code>score = 1 / (1 + distance)</code></li> </ul>"},{"location":"partnerships/weaviate_full_picture/#twocommand-demo-windows-powershell","title":"Two\u2011command demo (Windows / PowerShell)","text":"<pre><code>$py = \".\\.venv\\Scripts\\python.exe\"\n$in = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_demo\"\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out $out\n</code></pre> <p>Expected shape:</p> <pre><code>[tail] items_to_cover_90pct=3\n\nTop regimes by rho_global_post:\n  1. kb       rho_post=0.619658\n  2. tickets  rho_post=0.380342\n</code></pre>"},{"location":"partnerships/weaviate_full_picture/#optional-plots-if-you-want-visuals","title":"Optional: plots (if you want visuals)","text":"<p>If you installed the plotting helper, you can generate:</p> <ul> <li>coherence bar chart by regime</li> <li>concentration curve</li> </ul> <pre><code>&amp; $py -m pip install matplotlib\n&amp; $py scripts/plot_huf_artifacts.py --out $out\n</code></pre> <p>Outputs land under:</p> <ul> <li><code>out/vector_db_demo/plots/</code></li> </ul>"},{"location":"partnerships/weaviate_outreach/","title":"Weaviate outreach package","text":"<p>This page packages two \u201cready-to-send\u201d assets:</p> <p>1) GitHub PR text (for Weaviate\u2019s <code>partner-integration-examples</code> repo) 2) A short email to the partner manager \u2014 sent after the PR exists, so the email includes proof (a link)</p> <p>Why this exists: integrations land faster when there is something reviewable (a PR) before anyone has to take a meeting.</p> <p>Time sensitivity</p> <p>Partner roles and names can change. Verify the current partner contact first. Keep the message the same; just address the right person.</p>"},{"location":"partnerships/weaviate_outreach/#use-this-if-you-want-to-do-outreach","title":"Use this if you want to do outreach","text":""},{"location":"partnerships/weaviate_outreach/#step-1-open-the-pr-first","title":"Step 1 \u2014 Open the PR first","text":"<p>The PR is the \u201cproof artifact\u201d. It makes the follow\u2011up email feel like: \u201cHere is something real you can review\u201d instead of \u201cHere is an idea\u201d.</p>"},{"location":"partnerships/weaviate_outreach/#step-2-send-the-email-after-the-pr-link-exists","title":"Step 2 \u2014 Send the email after the PR link exists","text":"<p>Put the PR link in the first paragraph.</p>"},{"location":"partnerships/weaviate_outreach/#plain-text-fallback-copypaste","title":"Plain-text fallback (copy/paste)","text":""},{"location":"partnerships/weaviate_outreach/#pr-title","title":"PR title","text":"<p><code>feat: HUF coherence adapter \u2014 retrieval audit for Weaviate exports (namespace dominance + long-tail concentration)</code></p>"},{"location":"partnerships/weaviate_outreach/#pr-description-short","title":"PR description (short)","text":"<ul> <li>Adds a minimal example showing how to run a HUF coherence audit on retrieval exports  </li> <li>Answers: dominant namespaces/collections, concentration (items_to_cover_90pct), and declared discards (error budget) </li> <li>No live Weaviate connection required \u2014 JSONL in, HUF artifacts out  </li> </ul>"},{"location":"partnerships/weaviate_outreach/#two-command-demo-windows-safe","title":"Two-command demo (Windows-safe)","text":"<pre><code>$py = \".\\.venv\\Scripts\\python.exe\"\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in cases/vector_db/inputs/retrieval.jsonl `\n  --out out/vector_db_demo `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out out/vector_db_demo\n</code></pre> <p>Expected shape:</p> <pre><code>[tail] items_to_cover_90pct=3\n\nTop regimes by rho_global_post:\n  1. kb       rho_post=0.619658\n  2. tickets  rho_post=0.380342\n</code></pre>"},{"location":"partnerships/weaviate_outreach/#email-template","title":"Email (template)","text":"<p>Subject: <code>HUF coherence adapter for Weaviate exports \u2014 retrieval audit integration (PR open)</code></p> <p>Body:</p> <pre><code>Hi &lt;Name&gt;,\n\nI'm Peter Higgins, the author of HUF Core (Higgins Unity Framework) \u2014 an artifact-first audit tool for long-tail distributions in retrieval outputs.\n\nI opened a PR to weaviate/partner-integration-examples that adds a HUF coherence adapter for Weaviate retrieval exports: &lt;link to PR&gt;.\n\nIt runs in two commands and outputs:\n- a regime ranking by collection/namespace (rho_global_post)\n- a concentration score (items_to_cover_90pct)\n- an explicit discard ledger (error budget)\n\nThis surfaces something retrieval metrics miss: silent namespace dominance in multi-collection deployments.\n\nHappy to do a quick walkthrough, contribute a short co-authored blog draft, or just let the PR speak for itself.\n\nDocs: https://peterhiggins19.github.io/huf_core_github_v1.1.8_no_inputs/vector_db_coherence_one_pager/\n\nPeter Higgins\nhttps://github.com/PeterHiggins19/huf_core_github_v1.1.8_no_inputs\n</code></pre>"},{"location":"partnerships/case_studies/","title":"Case studies","text":"<p>These case studies are written to be:</p> <ul> <li>runnable (script-first)</li> <li>copy/paste safe for Windows/Conda</li> <li>tied to contract artifacts (CSV/JSON)</li> <li>easy to link in partner outreach</li> </ul>"},{"location":"partnerships/case_studies/#vector-databases","title":"Vector databases","text":"<ul> <li>Weaviate \u2014 Vector DB coherence &amp; integration case study</li> <li>Qdrant \u2014 collection/payload coherence audit</li> <li>Pinecone \u2014 namespace dominance in multi-tenant deployments</li> <li>Milvus/Zilliz \u2014 collection dominance + drift detection</li> </ul>"},{"location":"partnerships/case_studies/#orchestration-frameworks","title":"Orchestration frameworks","text":"<ul> <li>LangChain / LlamaIndex \u2014 retrieval callback \u2192 coherence report per query</li> </ul>"},{"location":"partnerships/case_studies/#evaluation-platforms","title":"Evaluation platforms","text":"<ul> <li>Arize / W&amp;B / Ragas \u2014 composition audit complements quality metrics</li> </ul>"},{"location":"partnerships/case_studies/#public-sector-science","title":"Public sector + science","text":"<ul> <li>Municipal budgets/logs \u2014 long-tail accounting lens</li> <li>Planck 70 GHz \u2014 scientific computing validation</li> </ul>"},{"location":"partnerships/case_studies/evaluation_platforms/","title":"Arize / Weights &amp; Biases / Ragas \u2014 composition audit layer","text":""},{"location":"partnerships/case_studies/evaluation_platforms/#why-it-fits","title":"Why it fits","text":"<p>Quality metrics answer \u201cwas the response good?\u201d HUF answers \u201cwhat drove the response?\u201d (composition + discards).</p>"},{"location":"partnerships/case_studies/evaluation_platforms/#integration-path","title":"Integration path","text":"<ul> <li>log HUF artifacts as run artifacts</li> <li>chart <code>items_to_cover_90pct</code> and top-regime mass over time</li> <li>attach <code>artifact_4_error_budget.json</code> as a governance ledger</li> </ul>"},{"location":"partnerships/case_studies/orchestration/","title":"LangChain / LlamaIndex \u2014 retrieval callback \u2192 coherence report","text":""},{"location":"partnerships/case_studies/orchestration/#why-it-fits","title":"Why it fits","text":"<p>Orchestrators already intercept retrieval results per query. That is the ideal hook point:</p> <ul> <li>export per-query retrieval to JSONL</li> <li>run HUF coherence audit</li> <li>attach the artifacts to your evaluation/logging pipeline</li> </ul>"},{"location":"partnerships/case_studies/orchestration/#output-to-emphasize","title":"Output to emphasize","text":"<ul> <li>per-query <code>items_to_cover_90pct</code> trends over time</li> <li>\u201ctop regimes changed\u201d alerts (dominance drift)</li> </ul>"},{"location":"partnerships/case_studies/pinecone/","title":"Pinecone \u2014 namespace dominance audit (multi-tenant)","text":""},{"location":"partnerships/case_studies/pinecone/#why-it-fits","title":"Why it fits","text":"<p>Pinecone namespaces map 1:1 to <code>--regime-field namespace</code>.</p>"},{"location":"partnerships/case_studies/pinecone/#entry-point","title":"Entry point","text":"<ul> <li>Export <code>id</code>, <code>score</code>, and <code>namespace</code> to JSONL</li> <li>Run the HUF coherence audit</li> </ul>"},{"location":"partnerships/case_studies/pinecone/#what-to-show","title":"What to show","text":"<ul> <li>when one namespace silently dominates</li> <li>how tightening tau changes concentration (proof line)</li> </ul>"},{"location":"partnerships/case_studies/public_sector/","title":"Public sector \u2014 long-tail accounting lens","text":"<p>HUF long-tail here is not ML class imbalance.</p> <p>It means:</p> <ul> <li>mass distribution (where spending/volume concentrates)</li> <li>exception reweighting (what changes after thresholding)</li> </ul> <p>Example: baseline P&amp;L \u2192 exception-only P&amp;L \u2192 ranked variance review.</p> <p>Use cases: - budget line items (Markham) - operational logs (Toronto traffic)</p>"},{"location":"partnerships/case_studies/qdrant/","title":"Qdrant \u2014 collection/payload coherence audit","text":""},{"location":"partnerships/case_studies/qdrant/#why-it-fits","title":"Why it fits","text":"<p>Qdrant payload fields (e.g., <code>collection</code>, <code>source</code>, <code>tenant</code>) are natural regime fields for HUF.</p>"},{"location":"partnerships/case_studies/qdrant/#entry-point","title":"Entry point","text":"<ul> <li>Export Qdrant search results to JSONL (<code>id</code>, <code>score</code>, plus regime field)</li> <li>Run HUF coherence audit on the export</li> </ul>"},{"location":"partnerships/case_studies/qdrant/#what-to-show","title":"What to show","text":"<ul> <li><code>rho_global_post</code> by collection/payload regime</li> <li><code>items_to_cover_90pct</code> as a \u201crisk of stale top chunks\u201d metric</li> <li><code>artifact_4_error_budget.json</code> as a declared discard ledger</li> </ul>"},{"location":"partnerships/case_studies/scientific_planck/","title":"Scientific computing \u2014 Planck 70 GHz validation","text":"<p>Why this matters: - shows HUF works on non-business scientific data - builds credibility for numerical stability and reproducibility</p> <p>Workflow: - fetch Planck FITS input (manual guide) - run <code>huf planck ...</code> - inspect coherence map and active set</p>"},{"location":"partnerships/case_studies/weaviate_vector_db_coherence/","title":"Weaviate \u2014 Vector DB coherence case study","text":"<p>This case study is designed as a linkable context page for a PR/email.</p> <p>Time sensitivity</p> <p>Names, partner programs, and priorities can change. Treat contact details as examples and verify current contacts.</p>"},{"location":"partnerships/case_studies/weaviate_vector_db_coherence/#read-the-full-html-case-study","title":"Read the full HTML case study","text":"<ul> <li><code>partnerships/case_studies/weaviate_vector_db_coherence_full.html</code></li> </ul>"},{"location":"partnerships/case_studies/weaviate_vector_db_coherence/#the-runnable-demo-two-commands","title":"The runnable demo (two commands)","text":"<pre><code>$py  = \".\\.venv\\Scripts\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_demo\"\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out $out\n</code></pre> <p>What to expect:</p> <ul> <li>a regime ranking (<code>artifact_1_coherence_map.csv</code>)</li> <li>a ranked review list (<code>artifact_2_active_set.csv</code>)</li> <li>a trace report (<code>artifact_3_trace_report.jsonl</code>)</li> <li>an error budget (<code>artifact_4_error_budget.json</code>)</li> <li>plus <code>items_to_cover_90pct</code> printed to console</li> </ul>"},{"location":"partnerships/case_studies/weaviate_vector_db_coherence/#what-this-proves","title":"What this proves","text":"<p>1) Dominance: which namespace/collection supplies most mass 2) Concentration: how many items explain 90% of mass (<code>items_to_cover_90pct</code>) 3) Declared discards: what got dropped, explicitly (error budget + trace)</p> <p>This is \u201cretrieval observability\u201d in artifact form.</p>"}]}