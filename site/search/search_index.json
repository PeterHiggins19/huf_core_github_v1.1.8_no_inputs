{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Higgins Unity Framework (HUF) \u2014 Documentation","text":"<p>This site is meant to help you run HUF first, then learn the rest in small steps.</p>"},{"location":"#start-here","title":"Start here","text":"<ul> <li>\u2705 Beginner (no GitHub knowledge required): Get Started (Zero GitHub)</li> <li>\u25b6\ufe0f Copy/paste demo runner: Quick Run</li> <li>Recommended reading order: Learning Path</li> <li>Download data (Markham + Toronto): Data Sources &amp; Fetching</li> <li>\u25b6\ufe0f Run examples (\u201ccases\u201d): Cases</li> <li>Fix common problems: Troubleshooting</li> </ul>"},{"location":"#long-tail-accounting-lens","title":"Long tail (accounting lens)","text":"<p>Not ML class imbalance: here \u201clong tail\u201d means mass distribution + exception reweighting (baseline vs filtered view). Start here: Long tail (accounting lens)</p>"},{"location":"#what-is-huf","title":"What is HUF?","text":"<ul> <li>What is the Higgins Unity Framework?</li> </ul>"},{"location":"#for-developers","title":"For developers","text":"<ul> <li>Start Here (Developer)</li> <li>Reference Manual</li> <li>Theory Notes (optional)</li> <li>GitHub for Beginners</li> </ul>"},{"location":"The_Higgins_Unity_Framework/","title":"The Higgins Unity Framework (HUF)","text":"<p>This project is the HUF Core implementation: a practical toolkit you can run to turn messy real\u2011world datasets into consistent, comparable outputs.</p> <p>If you\u2019re not technical, don\u2019t worry \u2014 you can still use HUF by following the step\u2011by\u2011step guides.</p>"},{"location":"The_Higgins_Unity_Framework/#plainenglish-idea","title":"Plain\u2011English idea","text":"<p>Real systems produce lots of different signals:</p> <ul> <li>budgets, traffic timing, anomalies, logs, counts, categories\u2026</li> <li>all with different units, scales, and missing values</li> </ul> <p>HUF\u2019s core trick is to convert those signals into a normalized representation so that:</p> <ul> <li>different sources can be compared fairly</li> <li>changes over time are easier to detect</li> <li>\u201cwhat matters most\u201d can be ranked without hand\u2011tuning every dataset</li> </ul> <p>In this repo, that \u201cnormalization\u201d mostly shows up as:</p> <ul> <li>cleaning inputs</li> <li>mapping columns into a consistent schema</li> <li>producing standardized outputs you can analyze or visualize</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#what-you-get-from-this-repository","title":"What you get from this repository","text":"<ul> <li>Repeatable demos (\u201ccases\u201d) with real civic datasets (Markham + Toronto)</li> <li>A command line tool (<code>huf ...</code>) to run those cases</li> <li>A structure you can copy to add your own data adapters and cases</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#key-concepts-no-math","title":"Key concepts (no math)","text":""},{"location":"The_Higgins_Unity_Framework/#1-inputs-adapters-outputs","title":"1) Inputs \u2192 adapters \u2192 outputs","text":"<p>A \u201ccase\u201d takes some input file(s), runs a transformation, and writes results to an output folder.</p> <ul> <li>Input examples: <code>.xlsx</code>, <code>.csv</code>, large datasets (Planck is guided/manual)</li> <li>Output examples: cleaned tables, normalized metrics, reports</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#2-normalization-the-unity-idea","title":"2) Normalization (the \u201cunity\u201d idea)","text":"<p>Normalization means turning different kinds of numbers into a consistent scale so they can be compared.</p> <p>Example: - Dataset A ranges from 0\u201310 - Dataset B ranges from 0\u201310,000</p> <p>After normalization, both can live on the same scale, so ranking and anomaly detection are meaningful.</p>"},{"location":"The_Higgins_Unity_Framework/#3-cases-are-learning-modules","title":"3) \u201cCases\u201d are learning modules","text":"<p>Each case is both: - a working example you can run today - a template you can copy when adding your own workflow</p>"},{"location":"The_Higgins_Unity_Framework/#where-to-begin","title":"Where to begin","text":"<ol> <li>Follow the beginner path: Learning Path </li> <li>Run a demo: Cases </li> <li>If you hit errors: Troubleshooting</li> </ol>"},{"location":"The_Higgins_Unity_Framework/#advanced-theory-optional","title":"Advanced / theory (optional)","text":"<p>Some HUF writings discuss deeper mathematics (categories, morphisms, topology, etc.). Those are not required to run the tools in this repo.</p> <p>If you want the deeper background, start with: - Theory Notes - Handbook</p>"},{"location":"The_Higgins_Unity_Framework/#glossary","title":"Glossary","text":"<ul> <li>Case: a runnable example workflow (input \u2192 process \u2192 output).</li> <li>Adapter: code that reads a particular dataset shape and maps it into HUF\u2019s expected schema.</li> <li>Normalization: converting values into a consistent scale to compare across sources.</li> <li>Schema: the column names / fields that HUF expects for a given workflow.</li> </ul> <p>Note: The original author notes and drafts existed as <code>.Markdown</code>. This repo now keeps documentation in Markdown (<code>.md</code>) so it renders well on GitHub and GitHub Pages.</p>"},{"location":"cases/","title":"Included cases","text":"<p>These cases are ready-to-run from a fresh clone.</p>"},{"location":"cases/#quick-commands-windows-powershell","title":"Quick commands (Windows PowerShell)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n\n.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"cases/#two-minute-long-tail-demo","title":"Two-minute long-tail demo","text":"<pre><code>.\\.venv\\Scripts\\python scripts/run_long_tail_demo.py --status \"Green Termination\"\n</code></pre> <p>Look for:</p> <ul> <li><code>PROOF: items_to_cover_90pct 37 -&gt; 12</code> (example)</li> </ul>"},{"location":"cases/#traffic-phase-vs-traffic-anomaly-accounting-lens","title":"Traffic Phase vs Traffic Anomaly (accounting lens)","text":"<p>Not ML class imbalance: here \u201clong tail\u201d means mass distribution + exception reweighting (baseline vs filtered view).</p> <p>Full explainer: - Long tail (accounting lens)</p>"},{"location":"cli_huf_reference/","title":"CLI: HUF command lists, labels, terminology","text":"<p>This page is a \u201csingle place\u201d to answer: - what commands exist, - what files they expect, - what artifacts they emit, - and what words mean (regime, \u03c4, active set\u2026).</p>"},{"location":"cli_huf_reference/#run-commands-in-the-shell-powershell-not-inside-python","title":"Run commands in the shell (PowerShell), not inside Python","text":"<p>If your prompt looks like this:</p> <ul> <li><code>&gt;&gt;&gt;</code></li> </ul> <p>\u2026you are inside the Python REPL. Shell commands like <code>huf ...</code> will fail with <code>SyntaxError</code>.</p> <p>Exit back to PowerShell:</p> <ul> <li>type <code>exit()</code> or</li> <li>press Ctrl+Z then Enter</li> </ul> <p>Then run commands like:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"cli_huf_reference/#windowsconda-rule-copypaste-reliability","title":"Windows/Conda rule (copy/paste reliability)","text":"<p>After the repo venv exists, always run tools via the repo executables:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>For file paths inside commands and docs, prefer forward slashes: - \u2705 <code>scripts/fetch_data.py</code> - \u2705 <code>cases/traffic_phase/inputs/...</code> - Only use backslashes for the venv executables: <code>.\\.venv\\Scripts\\python</code></p>"},{"location":"cli_huf_reference/#discover-commands-dont-guess","title":"Discover commands (don\u2019t guess)","text":"<p>Canonical command lists come from <code>--help</code>:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n.\\.venv\\Scripts\\huf traffic --help\n.\\.venv\\Scripts\\huf traffic-anomaly --help\n</code></pre> <p>If a flag name differs between versions, trust <code>--help</code> over any doc page.</p>"},{"location":"cli_huf_reference/#planck-guide-windows","title":"Planck guide (Windows)","text":"<p>There is no <code>make</code> on Windows. Print the Planck download guide like this:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>Then run Planck after placing the FITS and installing <code>astropy</code> in the same venv:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n.\\.venv\\Scripts\\huf planck --fits \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\" --out out/planck70 --retained-target 0.97 --nside-out 64\n</code></pre>"},{"location":"cli_huf_reference/#output-artifacts-the-contract","title":"Output artifacts (the contract)","text":"<p>Every valid HUF run emits the \u201ccontract artifacts\u201d in the run output folder:</p> <ul> <li><code>artifact_1_coherence_map.csv</code> \u2014 \u201cWhere the budget went\u201d by regime (ranked)</li> <li><code>artifact_2_active_set.csv</code> \u2014 retained items with global + local shares</li> <li><code>artifact_3_trace_report.jsonl</code> \u2014 line-by-line trace records (provenance)</li> <li><code>artifact_4_error_budget.json</code> \u2014 explicit discarded budget + diagnostics</li> </ul> <p>If any of these are missing, treat the run as non-auditable.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome \u2014 even small things like typo fixes or \u201cthis step confused me\u201d issues help a lot.</p>"},{"location":"contributing/#the-easiest-ways-to-help","title":"The easiest ways to help","text":"<ol> <li>Open an Issue (best for feedback / questions)</li> <li>Describe what you tried, what happened, and what you expected.</li> <li> <p>If it\u2019s about a command, paste the exact command + the terminal output.</p> </li> <li> <p>Send a Pull Request</p> </li> <li>Fork the repo \u2192 create a branch \u2192 make changes \u2192 open a PR.</li> <li>Docs-only PRs are totally fine (they\u2019re often the most valuable).</li> </ol>"},{"location":"contributing/#suggested-contribution-ideas","title":"Suggested contribution ideas","text":"<ul> <li>Add a small new \u201cworked example\u201d page for a dataset you care about</li> <li>Improve Windows copy/paste reliability</li> <li>Add tiny helper scripts (inspect artifacts, sanity checks, etc.)</li> </ul>"},{"location":"contributing/#repo-settings-that-help-contributors","title":"Repo settings that help contributors","text":"<ul> <li>Issues: Enabled</li> <li>Pull requests from forks: Enabled</li> <li>Branch protection (optional): require CI checks on <code>main</code></li> </ul> <p>The canonical contributor guidance lives in the root CONTRIBUTING.md in the repo.</p>"},{"location":"data_sources/","title":"Data Sources &amp; Fetching","text":"<p>This repo ships small inputs for Markham and Toronto via <code>scripts/fetch_data.py</code>. Planck is guide-only because the file is large.</p>"},{"location":"data_sources/#fetch-markham-toronto-inputs","title":"Fetch Markham + Toronto inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>If you haven't created the venv yet:</p> <pre><code>python scripts/bootstrap.py\n</code></pre>"},{"location":"data_sources/#docs-preview","title":"Docs preview","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"get_started_readme/","title":"HUF Get Started Package","text":"<p>Open Start_Here.md or Start_Here.md.</p> <ul> <li>If you already have the HUF GitHub package, run the start scripts in the repo root:</li> <li>Windows: <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: <code>START_HERE_MAC.command</code></li> <li>Linux: <code>start_here_linux.sh</code></li> </ul> <p>This package does not include large input datasets. Data sources and instructions are in <code>docs/data_sources.md</code>.</p>"},{"location":"get_started_zero_github/","title":"Start Here (Zero GitHub Knowledge)","text":"<p>You can run HUF without learning command-line git. The goal is:</p> <ul> <li>you can run <code>.\\.venv\\Scripts\\huf --help</code></li> <li>you can produce <code>out/.../run_stamp.json</code></li> </ul>"},{"location":"get_started_zero_github/#option-1-easiest-recommended-the-one-click-starter","title":"Option 1 \u2014 easiest (recommended): the one-click starter","text":"<p>From the repo folder:</p> <ul> <li>Windows: double-click <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: right-click <code>START_HERE_MAC.command</code> \u2192 Open</li> <li>Linux: <code>./start_here_linux.sh</code></li> </ul> <p>This creates a local <code>.venv</code> and installs what you need.</p>"},{"location":"get_started_zero_github/#option-2-manual-windows-powershell","title":"Option 2 \u2014 manual (Windows PowerShell)","text":"<p>From the repo root:</p>"},{"location":"get_started_zero_github/#1-create-a-repo-virtual-environment","title":"1) Create a repo virtual environment","text":"<pre><code>python -m venv .venv\n.\\.venv\\Scripts\\python -m pip install --upgrade pip setuptools wheel\n.\\.venv\\Scripts\\python -m pip install -e \".[dev]\"\n</code></pre>"},{"location":"get_started_zero_github/#2-fetch-the-civic-inputs-markham-toronto","title":"2) Fetch the civic inputs (Markham + Toronto)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"get_started_zero_github/#3-run-the-demo-cases","title":"3) Run the demo cases","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"get_started_zero_github/#4-preview-the-docs-locally-optional","title":"4) Preview the docs locally (optional)","text":"<p>Always run MkDocs through the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"get_started_zero_github/#important-windows-note-slashes","title":"Important Windows note: slashes","text":"<ul> <li>Use forward slashes for file paths in docs and commands: <code>scripts/fetch_data.py</code>, <code>cases/...</code>, <code>out/...</code></li> <li>Use backslashes only for the venv executables: <code>.\\.venv\\Scripts\\python</code>, <code>.\\.venv\\Scripts\\huf</code></li> </ul>"},{"location":"github_for_beginners/","title":"GitHub for HUF (Beginner, GUI-first)","text":"<p>This is a plain-language guide to using HUF on GitHub with minimal jargon.</p>"},{"location":"github_for_beginners/#the-easiest-way-github-desktop-point-and-click","title":"The easiest way: GitHub Desktop (point-and-click)","text":"<ol> <li>Install GitHub Desktop</li> <li>Clone the repository</li> <li>Run the one-click starter scripts</li> </ol> <p>Then fetch data:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>Run a demo:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"gui_quickstart/","title":"GUI Quickstart (non\u2011GitHub\u2011native users)","text":"<p>This page is for people who prefer GUI workflows (e.g., GitHub Desktop, file explorers, Word/Excel) but still want to run HUF and keep record copies.</p>"},{"location":"gui_quickstart/#note","title":"Note","text":"<p>This docs-only package does not include the code/CLI. To run HUF, download the GitHub package release as well.</p>"},{"location":"gui_quickstart/#what-you-can-do-without-git","title":"What you can do without Git","text":"<p>If you don\u2019t want Git at all:</p> <ol> <li>Download the latest release ZIP from GitHub (look for Releases on the right side of the repo page).</li> <li>Unzip it to a folder like <code>Documents/HUF/</code>.</li> <li>Open the Markdown record copies in <code>docs/</code>:</li> <li><code>docs/handbook.md</code></li> <li><code>docs/reference_manual.md</code></li> <li><code>docs/data_sources.md</code></li> </ol> <p>You can still run the CLI from this unzipped folder (see below).</p>"},{"location":"gui_quickstart/#using-github-desktop-recommended-for-updates","title":"Using GitHub Desktop (recommended for updates)","text":"<p>If you want one-click updates:</p> <ol> <li>Install GitHub Desktop.</li> <li>In GitHub Desktop: File \u2192 Clone repository\u2026</li> <li>Pick a local folder (e.g., <code>Documents/GitHub/huf-core</code>).</li> <li>To update later: press Fetch origin then Pull origin.</li> </ol>"},{"location":"gui_quickstart/#one-time-setup-to-run-huf","title":"One-time setup to run HUF","text":"<p>You need Python 3.10+ installed.</p>"},{"location":"gui_quickstart/#step-1-open-a-terminal-in-the-repo-folder","title":"Step 1 \u2014 Open a terminal in the repo folder","text":"<ul> <li>Windows: open File Explorer \u2192 go to the repo folder \u2192 right\u2011click \u2192 Open in Terminal (or PowerShell).</li> <li>macOS: Finder \u2192 repo folder \u2192 right\u2011click \u2192 New Terminal at Folder (or open Terminal and <code>cd</code>).</li> <li>Linux: open Terminal and <code>cd</code> into the folder.</li> </ul>"},{"location":"gui_quickstart/#step-2-run-the-bootstrap-crossplatform","title":"Step 2 \u2014 Run the bootstrap (cross\u2011platform)","text":"<p>From the repo root:</p> <pre><code>python scripts/bootstrap.py\n</code></pre> <p>This creates <code>.venv/</code> and installs everything you need.</p> <p>If you\u2019re on macOS/Linux you can also use: <code>make bootstrap</code></p>"},{"location":"gui_quickstart/#download-the-real-input-data-no-big-inputs-are-bundled","title":"Download the real input data (no big inputs are bundled)","text":""},{"location":"gui_quickstart/#markham-toronto-automatic","title":"Markham + Toronto (automatic)","text":"<p>After bootstrap, run one of these:</p> <pre><code>make fetch-data\n# or:\npython scripts/fetch_data.py --markham --toronto\n</code></pre>"},{"location":"gui_quickstart/#toronto-non-interactive-yes","title":"Toronto non-interactive (<code>--yes</code>)","text":"<p>For scripted demos (no prompts):</p> <pre><code>make fetch-toronto-yes\n# or:\npython scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"gui_quickstart/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<p>Planck files are large, so HUF prints the steps instead of downloading by default:</p> <pre><code>make planck-guide\n# or:\npython scripts/fetch_data.py --planck-guide\n</code></pre>"},{"location":"gui_quickstart/#run-the-demos","title":"Run the demos","text":""},{"location":"gui_quickstart/#markham","title":"Markham","text":"<pre><code>huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018 --tau-global 0.005 --tau-local 0.02\n</code></pre>"},{"location":"gui_quickstart/#toronto-traffic","title":"Toronto traffic","text":"<pre><code>huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase --tau-local 0.05\n</code></pre>"},{"location":"gui_quickstart/#where-outputs-go","title":"Where outputs go","text":"<p>Each run writes a folder like <code>out/markham2018/</code> or <code>out/traffic_phase/</code> containing the mandatory artifacts:</p> <ul> <li><code>artifact_1_coherence_map.csv</code></li> <li><code>artifact_2_active_set.csv</code></li> <li><code>artifact_3_trace_report.jsonl</code></li> <li><code>artifact_4_error_budget.json</code></li> </ul> <p>You can open the CSVs in Excel and keep them with your meeting notes.</p>"},{"location":"handbook/","title":"Higgins Unity Framework (HUF) Handbook","text":"<p>Edition: v1.1.8 (docs refresh) Updated: 2026-02-17  </p> <p>This handbook is the conceptual and contractual description of HUF: what the Unity-Budgeted Hierarchy (UBH) is, how HUF emits auditable artifacts, and how to interpret stability sweeps.</p> <p>Real-data demos included in this repo: - Markham (2018 budget) \u2014 real Excel input fetched from the City of Markham open data site. - Toronto (traffic signals timing) \u2014 real CSV derived from the City of Toronto open data \u201cTraffic signals timing\u201d ZIP. - Planck (70 GHz all-sky map) \u2014 real FITS map not shipped in the repo (too large). You fetch it from PLA or IRSA (guided in <code>scripts/fetch_data.py --planck-guide</code>).</p> <p>Synthetic data: only small \u201ctoy\u201d examples (used for quick sanity checks) are synthetic. The headline demos above are real data.</p>"},{"location":"handbook/#origins-why-this-exists","title":"Origins (why this exists)","text":"<p>HUF grew out of a very practical question: how to solve diffraction and dispersion problems in loudspeakers well enough that the \u201cwhy\u201d became impossible to ignore. The working path was:</p> <ol> <li>solve the physical problem (dispersion / diffraction) empirically</li> <li>notice an \u201cenergy budget\u201d invariant when moving from 2\u03c0 to 4\u03c0 radiation equalization</li> <li>formalize the invariant as an isotropic budget / unity constraint</li> <li>generalize it into a contract for hierarchies \u2192 the Unity\u2011Budgeted Hierarchy (UBH)</li> <li>treat every run as a reproducible artifact emitter \u2192 HUF</li> </ol> <p>That\u2019s the reason the framework is written like a lab protocol: it is designed to let people verify \u201cis this real?\u201d before debating \u201cis this beautiful?\u201d.</p> <p>Higgins Unity Framework (HUF) Handbook</p> <p>A contract-first method for unity\u2011budgeted hierarchies, auditable reduction, and stable anomaly localization</p> <p>Handbook Edition \u2022 Version 1.0 February 2026</p> <p>Peter Higgins</p>"},{"location":"handbook/#front-matter","title":"Front matter","text":"<p>This handbook replaces the earlier \u2018meeting spec\u2019 lineage. It is written to be implementable, teachable, and hard to misread. The tone is intentionally contract\u2011driven: if you cannot verify finite elements, conserve a declared unity budget, emit the required artifacts, and pass stability checks, then you are not doing HUF \u2014 you are doing storytelling.</p> <p>The handbook contains two comprehensive, real-data case studies (Planck 70\u202fGHz and City of Markham public data) and a third operational case study (traffic signal telemetry) as an anomaly\u2011localization template.</p>"},{"location":"handbook/#how-to-use-this-handbook","title":"How to use this handbook","text":"<ul> <li> <p>If you need the method: read Part I and implement the contract (required artifacts + stability packet).</p> </li> <li> <p>If you need proof: read Part II and reproduce the reference runs (Planck and Markham).</p> </li> <li> <p>If you need to teach or deploy: read Part III (implementation patterns, templates, and training exercises).</p> </li> </ul>"},{"location":"handbook/#table-of-contents","title":"Table of contents","text":"<p>In Word: Right\u2011click the TOC \u2192 Update Field \u2192 Update entire table.</p>"},{"location":"handbook/#part-i-huf-core-normative","title":"Part I \u2014 HUF Core (Normative)","text":""},{"location":"handbook/#1-definition-in-one-page-the-core-stripped","title":"1. Definition in one page (the core, stripped)","text":"<p>HUF defines a system as a unity\u2011budgeted hierarchy with auditable finite elements.</p> <ol> <li> <p>Finite elements: verifiable units that contribute to a conserved budget.</p> </li> <li> <p>Regimes: named groupings of finite elements (nestable) used for interpretability.</p> </li> <li> <p>Unity budget: a declared conserved quantity (mass/weight or energy/power) with total sum exactly 1.0.</p> </li> <li> <p>Locked cycle: Normalize \u2192 Propagate \u2192 Aggregate \u2192 Exclude \u2192 Renormalize.</p> </li> <li> <p>Contract: a run is invalid unless it emits the required artifacts and passes declared stability checks.</p> </li> </ol>"},{"location":"handbook/#2-motivation-the-shortest-honest-version","title":"2. Motivation (the shortest honest version)","text":"<p>Every serious system ends up doing some form of reduction: compressing models, pruning portfolios, prioritizing interventions, or summarizing telemetry. The failure mode is consistent: reduction happens, but the justification is ad hoc. HUF exists to make reduction auditable.</p> <p>HUF does not promise \u2018truth.\u2019 It promises four things you can test: (1) unity conservation, (2) explicit retained set, (3) explicit discarded budget, and (4) backward trace to finite elements. That\u2019s the entire game.</p>"},{"location":"handbook/#3-primitives-and-invariants","title":"3. Primitives and invariants","text":"<p>3.1 Finite element</p> <p>A finite element is the smallest unit you agree to audit. It must have: a unique identifier, a repeatable method of computing its contribution, and stored provenance.</p> <p>Minimum finite-element record:</p> <ul> <li> <p>id: stable string key (do not recycle IDs across runs)</p> </li> <li> <p>inputs: pointers to measured data, logs, or upstream artifacts</p> </li> <li> <p>contribution: a non-negative scalar (or paired positive/negative extension) used by the unity budget</p> </li> <li> <p>provenance: hash or stamp sufficient to reproduce the number</p> </li> </ul> <p>3.2 Regime</p> <p>A regime is a partition (or nested partition) used to contextualize budget. A regime answers: \u2018where did the budget go?\u2019 Regimes must not double-count contributions. If an element belongs to multiple regimes, you must explicitly split its budget.</p> <p>3.3 Unity budget</p> <p>Unity is the only invariant HUF treats as sacred: after normalization, the sum of contributions equals 1.0 globally. Local unity (within a regime) may be enforced for a local view, but the global unity must always be satisfied.</p>"},{"location":"handbook/#4-budget-semantics-choose-once-dont-cheat","title":"4. Budget semantics (choose once; don\u2019t cheat)","text":"<p>HUF is ruthless about budget semantics. Declare one of the following and never mix them mid-run:</p> <ul> <li> <p>Mass/weight budget: \u03c1\u1d62 \u2265 0 and \u03a3\u03c1\u1d62 = 1. Examples: expenditure shares, portfolio weights, probability mass.</p> </li> <li> <p>Energy/power budget: \u03c1\u1d62 = e\u1d62 / \u03a3e with e\u1d62 = |x\u1d62|\u00b2 or another Parseval-consistent energy under a declared orthogonal basis.</p> </li> </ul> <p>If your domain has cancellation (signed contributions), do not fake it by allowing negative \u03c1. Use a paired-budget extension (track positive and negative magnitudes separately) or an explicitly signed framework with stability proofs.</p>"},{"location":"handbook/#5-the-locked-cycle-and-what-each-step-is-allowed-to-do","title":"5. The locked cycle and what each step is allowed to do","text":"<p>Figure 1. The locked HUF cycle. You may extend steps, but you may not reorder them without breaking audit expectations.</p> <p>Normalize</p> <p>Normalize converts raw contributions into a unity budget. For mass budgets: \u03c1\u1d62 = w\u1d62 / \u03a3w. For energy budgets: \u03c1\u1d62 = |x\u1d62|\u00b2 / \u03a3|x|\u00b2. Normalization must be deterministic and logged.</p> <p>Propagate</p> <p>Propagation moves budget between representations (e.g., from fine pixels to coarse blocks, from categories to wards, from events to root causes). Propagation is admissible only if it is conservative and traceable.</p> <ul> <li> <p>Conservation check: |\u03a3\u03c1_out \u2212 \u03a3\u03c1_in| \u2264 \u03b5 (declare \u03b5).</p> </li> <li> <p>Traceability check: every output element stores a map back to input elements with weights.</p> </li> <li> <p>No hidden state: propagation must be a pure function of inputs + declared parameters (seeded if stochastic).</p> </li> </ul> <p>Aggregate</p> <p>Aggregation merges elements to reduce complexity while preserving the budget. Examples: cluster similar items, sum within a regime, downsample by known hierarchical structure.</p> <p>Exclude</p> <p>Exclusion removes elements below a threshold \u03c4 or keeps the smallest set reaching a retained budget target. Exclusion must emit a discard ledger (what was removed and how much budget it carried).</p> <p>Renormalize and validate</p> <p>Renormalize after exclusion (and after any operation that may introduce floating-point drift). Then validate the contract: unity checks, trace completeness, artifact emission, and stability packet results.</p>"},{"location":"handbook/#6-the-contract-required-artifacts","title":"6. The contract (required artifacts)","text":"<p>Contract: a HUF run is invalid unless it emits all artifacts</p>"},{"location":"handbook/#7-artifact-schemas-minimum-workable-forms","title":"7. Artifact schemas (minimum workable forms)","text":"<p>HUF does not mandate file formats, but it does mandate fields. Minimal schemas:</p> <p>Schema A \u2014 Active set</p> <p>Schema B \u2014 Backward trace (per retained element)</p> <p>Schema C \u2014 Error/Budget report</p>"},{"location":"handbook/#8-stability-packet-required-anti-brittleness-tests","title":"8. Stability packet (required anti-brittleness tests)","text":"<p>Minimum stability packet</p>"},{"location":"handbook/#9-deployment-hazards-the-things-critics-correctly-attack","title":"9. Deployment hazards (the things critics correctly attack)","text":"<ul> <li> <p>Semantics drift: changing what unity means mid-run (e.g., mixing weight and energy).</p> </li> <li> <p>Black-box propagation: learned or heuristic mapping with no trace and no conservation validation.</p> </li> <li> <p>Double counting: elements belonging to overlapping regimes without explicit splitting.</p> </li> <li> <p>Unstable thresholds: large near-\u03c4 mass and low overlap across sweeps.</p> </li> <li> <p>Overfitting the narrative: tuning \u03c4 until your preferred story appears.</p> </li> </ul> <p>HUF\u2019s job is to make these failures visible. If your run fails, that is not \u2018HUF failing\u2019; that is the system refusing to be compressed honestly.</p>"},{"location":"handbook/#part-ii-comprehensive-reference-runs-real-data","title":"Part II \u2014 Comprehensive Reference Runs (Real Data)","text":""},{"location":"handbook/#10-case-study-a-planck-lfi-70-ghz-healpix-nside1024","title":"10. Case Study A \u2014 Planck LFI 70\u202fGHz (HEALPix, nside=1024)","text":"<p>This case demonstrates energy\u2011budget HUF on a large scientific dataset. Input file: LFI_SkyMap_070_1024_R3.00_full.fits. We use the Stokes I column (I_STOKES). The finite elements are pixels; the energy contribution is I\u00b2.</p>"},{"location":"handbook/#101-data-model","title":"10.1 Data model","text":"<ul> <li> <p>Raw finite elements: nside=1024 pixels (12\u00d71024\u00b2 = 12,582,912 elements).</p> </li> <li> <p>Aggregation: NESTED parent blocks at nside=64 (12\u00d764\u00b2 = 49,152 coarse elements), each covering 256 child pixels.</p> </li> <li> <p>Regimes: 12 HEALPix base faces (each face = 4,096 coarse blocks).</p> </li> <li> <p>Budget: energy share \u03c1\u1d62 = e\u1d62 / \u03a3e, with e\u1d62 = \u03a3child I\u00b2 (for coarse blocks).</p> </li> </ul>"},{"location":"handbook/#102-run-configuration","title":"10.2 Run configuration","text":"<p>Aggregation: nside 1024 \u2192 64 (ratio 16; 256 children per parent).</p> <p>Retain target: 0.97 of total energy.</p> <p>Outcome: K = 18,198 retained coarse blocks out of 49,152. Threshold \u03c4 = 1.66e-06.</p> <p>Energy retained = 0.9700; discarded = 0.0300.</p> <p>Pixel\u2011basis RMSE under keep\u2011or\u2011zero reconstruction = 7.6942e-05 (same units as I_STOKES).</p>"},{"location":"handbook/#103-coherence-map","title":"10.3 Coherence map","text":"<p>Figure 2. Planck 70\u202fGHz \u2014 global retained vs discarded energy share.</p> <p>Figure 3. Planck 70\u202fGHz \u2014 per\u2011face unity bars (faces as regimes).</p> <p>Figure 4. Planck 70\u202fGHz \u2014 active\u2011set growth curve (sorted by \u03c1).</p> <p>Table 10\u2011A. Per\u2011face energy shares (global \u03c1)</p> <p>Table 10\u2011B. Top retained coarse blocks (traceable sample)</p>"},{"location":"handbook/#104-traceability-how-to-audit-a-retained-block","title":"10.4 Traceability (how to audit a retained block)","text":"<p>Because the map uses HEALPix NESTED ordering, each nside=64 parent block corresponds to a contiguous range of 256 nside=1024 child pixels. For a retained parent with index p, the child range is [256p, 256p+255]. This makes backward traces compact and exact.</p> <p>Example: a compact backward trace for an aggregated HEALPix block</p>"},{"location":"handbook/#105-stability-packet-retaintarget-sweep","title":"10.5 Stability packet (retain\u2011target sweep)","text":"<p>Table 10\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 10\u2011D. Active\u2011set overlap (Jaccard) between sweep points</p> <p>Table 10\u2011E. Regime ranking stability (faces) across sweep points</p>"},{"location":"handbook/#106-what-this-run-teaches-and-what-it-does-not","title":"10.6 What this run teaches (and what it does not)","text":"<ul> <li> <p>HUF can reduce 49,152 coarse blocks to ~18k while retaining 97% pixel-basis energy, with exact accounting.</p> </li> <li> <p>Per-regime views (faces) remain stable across threshold sweeps: the \u2018where\u2019 of energy is robust.</p> </li> <li> <p>The discard fraction is a quantitative error bound under the declared reconstruction.</p> </li> <li> <p>This is not cosmological inference. HUF is an auditable reduction layer; domain science still happens above it.</p> </li> </ul>"},{"location":"handbook/#11-case-study-b-city-of-markham-2018-budget-civic-layers","title":"11. Case Study B \u2014 City of Markham (2018 budget + civic layers)","text":"<p>This case demonstrates mass/weight HUF on municipal public data. The conserved quantity is money. Primary budget workbook: 2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx (values in $000). We focus on expenditures (the allocation of outgoing funds), then show a propagation example onto wards using census population as a proxy.</p>"},{"location":"handbook/#111-data-inventory-what-we-used","title":"11.1 Data inventory (what we used)","text":"<ul> <li> <p>2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx \u2014 fund-level revenues/expenditures by category.</p> </li> <li> <p>2018-Operating-Budget-by-Account.xlsx \u2014 operating revenue/expense categories and year comparisons.</p> </li> <li> <p>2016-Tax-Rates.xlsx and 2018-Tax-Rates.xlsx \u2014 rate context (not used as budget, used for narrative checks).</p> </li> <li> <p>GIS layers: WARD.geojson, Parks.geojson, Fire_Stations.geojson, City_Facilities.geojson (used for a propagation demo).</p> </li> <li> <p>Census DA layer (Age/Sex) for Markham \u2014 used only to compute ward population shares (proxy).</p> </li> </ul>"},{"location":"handbook/#112-budget-declaration-and-finite-elements","title":"11.2 Budget declaration and finite elements","text":"<p>Global budget: total 2018 expenditures across all funds = 456,171 ($000). Unity budget is \u2018share of total expenditures\u2019.</p> <p>Finite element for the primary run: (Fund \u00d7 ExpenditureCategory). Regimes: Funds. This gives a clean \u2018where does the city spend money\u2019 decomposition.</p>"},{"location":"handbook/#113-primary-run-results-fundcategory","title":"11.3 Primary run results (Fund\u00d7Category)","text":"<p>Retain target: 0.97. Outcome: K = 23 retained elements out of 67. Threshold \u03c4 = 0.004. Retained = 0.9710; discarded = 0.0290.</p> <p>Figure 5. Markham 2018 expenditures \u2014 global retained vs discarded budget share.</p> <p>Figure 6. Markham 2018 expenditures \u2014 per-fund unity bars (funds as regimes).</p> <p>Figure 7. Markham 2018 expenditures \u2014 active-set growth curve (Fund\u00d7Category).</p> <p>Table 11\u2011A. Fund regimes: totals and global shares</p> <p>Table 11\u2011B. Largest spending contributors (Fund\u00d7Category)</p>"},{"location":"handbook/#114-stability-packet","title":"11.4 Stability packet","text":"<p>Table 11\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 11\u2011D. Active-set overlap (Jaccard) across sweep points</p>"},{"location":"handbook/#115-backward-trace-example-auditing-a-spending-line","title":"11.5 Backward trace example (auditing a spending line)","text":"<p>In this run, the backward trace is trivial but non\u2011negotiable: each retained element points back to a specific worksheet row/column (Fund, Category, cell location) plus workbook hash. If you can\u2019t point to the cell, you can\u2019t claim the number.</p> <p>Example: backward trace record for a budget line</p>"},{"location":"handbook/#116-propagation-demo-operating-fund-to-wards-proxy-allocation","title":"11.6 Propagation demo \u2014 Operating Fund to wards (proxy allocation)","text":"<p>This section demonstrates propagation constraints on civic geography. We do NOT claim this is the real ward budget \u2014 the city budget is not ward\u2011allocated in this dataset. We demonstrate a conservative, auditable proxy mapping.</p> <p>Propagation map: allocate Operating Fund expenditures to wards proportional to 2016 census population share. This is admissible as a mapping only if it is declared as a proxy, conservative (sums match), and traceable.</p> <p>Figure 8. Markham wards \u2014 population shares (proxy weights for propagation).</p> <p>Figure 9. Operating Fund propagated to wards \u2014 per-regime unity bars (retained vs discarded at target 0.97).</p> <p>Table 11\u2011E. Ward proxy table: population, facilities counts, and Operating Fund allocation ($M)</p> <p>Why include facilities counts? Not as causal claims \u2014 as audit context. They provide additional regimes for future propagation (e.g., allocate a parks-maintenance budget proportional to park count or area). Any such mapping must be declared and tested for stability.</p>"},{"location":"handbook/#117-what-dominates-and-what-to-do-next","title":"11.7 What dominates and what to do next","text":"<p>The Fund\u00d7Category decomposition typically reveals (a) how concentrated spending is, (b) whether one fund dominates the budget narrative, and (c) which categories are \u2018structural\u2019 versus \u2018tail.\u2019 This run is a starting point.</p> <ul> <li> <p>Next expansion: link operating categories to performance measures (if definitions match).</p> </li> <li> <p>Next expansion: add revenues as a parallel budget and compare structural mismatch (revenue concentration vs expenditure concentration).</p> </li> <li> <p>Next expansion: incorporate capital project lists and apply HUF to project portfolios (true finite elements with trace to project IDs).</p> </li> </ul>"},{"location":"handbook/#12-case-study-c-traffic-signal-telemetry-anomaly-localization-template","title":"12. Case Study C \u2014 Traffic signal telemetry (anomaly localization template)","text":"<p>This case shows how HUF behaves on operational event streams. The goal is not \u2018compress for beauty\u2019 \u2014 it is: what dominates anomalies, and where should you look first?</p>"},{"location":"handbook/#121-finite-element-and-budget-definition-recommended","title":"12.1 Finite element and budget definition (recommended)","text":"<p>Recommended finite element for anomaly work: Finite element = TCS \u00d7 PHASE \u00d7 PHASE_STATUS_TEXT (optionally \u00d7 PHASE_CALL_TEXT) Budget = event share or severity\u2011weighted share (declare weights) Output = which intersections/phases dominate drops/terminations/clearance with full trace to raw rows.</p> <p>In this run we define a simple severity budget: Dropped calls weight 3, Termination statuses weight 2, everything else weight 1, then restrict the anomaly view to rows with severity &gt; 1.</p>"},{"location":"handbook/#122-compressed-phase-activity-distribution-what-dominates-anomalies","title":"12.2 Compressed phase activity distribution (what dominates anomalies)","text":"<p>Figure 10. Traffic telemetry \u2014 anomaly severity budget by intersection (top contributors).</p> <p>Figure 11. Traffic telemetry \u2014 anomaly severity budget by phase.</p> <p>Figure 12. Traffic telemetry \u2014 anomaly severity budget by status.</p> <p>Table 12\u2011A. Top intersections by anomaly severity budget share</p> <p>Table 12\u2011B. Phases dominating the anomaly budget</p> <p>Table 12\u2011C. Status distribution within anomaly budget</p>"},{"location":"handbook/#123-traceability-and-actionability","title":"12.3 Traceability and actionability","text":"<p>A practical HUF anomaly run ends with a short, actionable list: top intersections, top phases, and the raw event rows supporting them. Backward traces should include timestamp ranges and source row IDs so an engineer can replay the evidence.</p> <ul> <li> <p>If one intersection dominates: inspect controller configuration and detector health first.</p> </li> <li> <p>If one phase dominates across many intersections: inspect phase timing policy or coordination logic.</p> </li> <li> <p>If one status dominates: inspect the semantic definition (what exactly triggers \u2018Termination\u2019 in your system).</p> </li> </ul>"},{"location":"handbook/#part-iii-implementation-extension-and-training","title":"Part III \u2014 Implementation, extension, and training","text":""},{"location":"handbook/#13-reference-implementation-patterns","title":"13. Reference implementation patterns","text":"<p>A handbook is useless if it can\u2019t be implemented. This section defines the minimal architecture that prevents HUF from collapsing back into prose.</p> <ul> <li> <p>Core data model: Element(id, rho, regime_path, trace).</p> </li> <li> <p>Adapters: domain-specific loaders and propagators that output the same element schema.</p> </li> <li> <p>I/O: artifact writers (CSV/JSON) that always include run stamps and file hashes.</p> </li> <li> <p>Tests: each reference run must have an automated test that checks unity, artifact emission, and stability packet generation.</p> </li> </ul> <p>Listing 13\u2011A. Reference core (excerpt, huf_core/core.py)</p> <p>(Full source is intended for the accompanying repository/package; this excerpt is included for handbook completeness.)</p>"},{"location":"handbook/#14-how-huf-prunes-itself-expansion-contraction-as-a-method","title":"14. How HUF prunes itself (expansion \u2192 contraction as a method)","text":"<p>The development history that produced this handbook is not a shameful detour \u2014 it is the method. You expand to explore, then you contract to ship. HUF applies to itself:</p> <ol> <li> <p>Expansion phase: explore candidate operations, artifacts, and narratives to discover what actually matters in practice.</p> </li> <li> <p>Contraction phase: declare the contract, delete optionality from the core, and move everything else into extensions.</p> </li> <li> <p>Stability phase: treat the framework definition as a system under HUF \u2014 track which sections survive pruning across reviewer critiques.</p> </li> </ol> <p>A useful internal exercise: assign a unity budget to sections of your draft (by reader time, by risk, or by implementation cost), then run HUF to see which sections dominate confusion or contribute little. That is \u2018HUF on HUF.\u2019</p>"},{"location":"handbook/#15-training-exercises-from-toy-to-real","title":"15. Training exercises (from toy to real)","text":"<p>Exercises are designed to build the habit of declaring budgets, regimes, and traces before you compute.</p> <ol> <li> <p>Take any spreadsheet with line items. Define finite elements and a mass budget. Produce the four artifacts.</p> </li> <li> <p>Repeat with two regime partitions (by department vs by fund). Compare regime stability across thresholds.</p> </li> <li> <p>Take an event log. Define anomaly budget weights. Produce a top\u2011N actionable list with backward traces to row IDs.</p> </li> <li> <p>Design a propagation map (e.g., cost \u2192 ward) and prove conservation + traceability in one paragraph.</p> </li> <li> <p>Perform a stability sweep and write the two-sentence interpretation of the stability packet.</p> </li> </ol>"},{"location":"handbook/#appendix-a-data-samples-print-friendly-excerpts","title":"Appendix A \u2014 Data samples (print-friendly excerpts)","text":"<p>A1. Planck sample (first 5 coarse blocks; energies are in I\u00b2 units)</p> <p>A2. Markham sample (top 10 Fund\u00d7Category elements)</p> <p>A3. Traffic sample (first 12 telemetry rows; severity weights shown)</p>"},{"location":"handbook/#appendix-b-artifact-checklists-what-a-reviewer-will-ask-for","title":"Appendix B \u2014 Artifact checklists (what a reviewer will ask for)","text":"<ul> <li> <p>Unity checks: global \u03a3\u03c1=1.0 after every normalization and renormalization step (log the tolerance).</p> </li> <li> <p>Discard ledger: list of excluded elements with their \u03c1; discarded sum must match 1\u2212retained.</p> </li> <li> <p>Trace completeness: every retained element has a backward trace to finite elements (no null traces).</p> </li> <li> <p>Stability packet: sweep points, overlap metrics, regime rank stability, near\u2011\u03c4 band.</p> </li> <li> <p>Repro stamp: file hashes, code version, run_id, parameters (\u03c4/target, seeds).</p> </li> </ul>"},{"location":"handbook/#appendix-c-glossary-minimal","title":"Appendix C \u2014 Glossary (minimal)","text":"<p>Glossary</p>"},{"location":"handbook/#appendix-d-reproducibility-stamps-recommended-minimum","title":"Appendix D \u2014 Reproducibility stamps (recommended minimum)","text":"<p>Run stamp</p>"},{"location":"huf_math_form_and_function/","title":"Mathematical form and function","text":"<p>\\</p>"},{"location":"huf_math_form_and_function/#higgins-unity-framework-mathematical-form-and-function","title":"Higgins Unity Framework: Mathematical form and function","text":"<p>This page is the \u201cmath spine\u201d that connects the HUF contract (artifacts + stability packet) to a minimal formal model.</p> <p>Not ML class imbalance: here \u201clong tail\u201d means mass distribution + exception reweighting (baseline vs filtered view).</p>"},{"location":"huf_math_form_and_function/#1-the-object-huf-normalizes","title":"1) The object HUF normalizes","text":"<p>HUF starts from a non\u2011negative contribution table and turns it into a unity budget.</p> <ul> <li>Finite elements: indices (i = 1..N)</li> <li>Raw contributions: (w_i \\ge 0)</li> <li>Unity\u2011budget weights (\u201cmass share\u201d or \u201cenergy share\u201d):</li> <li>Mass: (\\rho_i = \\frac{w_i}{\\sum_k w_k})</li> <li>Energy / Parseval: (\\rho_i = \\frac{|x_i|^2}{\\sum_k |x_k|^2})</li> </ul>"},{"location":"huf_math_form_and_function/#proof-sketch-unity-is-enforced","title":"Proof sketch: unity is enforced","text":"<p>Let (S = \\sum_k w_k). Then: - (\\rho_i \\ge 0) because (w_i \\ge 0) - (\\sum_i \\rho_i = \\sum_i \\frac{w_i}{S} = \\frac{1}{S}\\sum_i w_i = 1)</p> <p>This is the core invariant HUF treats as sacred: global unity.</p>"},{"location":"huf_math_form_and_function/#2-regimes-local-views-that-stay-auditable","title":"2) Regimes (local views that stay auditable)","text":"<p>A regime is a partition (or nested partition) of finite elements: - Regimes (R_1, \\dots, R_m) where (R_j \\subseteq {1..N}) - Regime mass:   [   \\rho(R_j) = \\sum_{i \\in R_j} \\rho_i   ]</p> <p>The coherence map artifact is exactly \u201c(\\rho(R_j)) for all regimes\u201d plus ranking, so you can answer:</p> <p>\u201cWhere did the budget go?\u201d</p>"},{"location":"huf_math_form_and_function/#3-exclusion-reduction-as-a-truncation-operator","title":"3) Exclusion / reduction as a truncation operator","text":"<p>Most practical HUF runs reduce the system to an auditable subset.</p>"},{"location":"huf_math_form_and_function/#31-threshold-form","title":"3.1 Threshold form (\u03c4)","text":"<p>Define a truncation operator: [ T_\\tau(\\rho)_i = \\rho_i \\cdot \\mathbf{1}[\\rho_i \\ge \\tau] ]</p> <p>Discarded budget (explicitly reported in <code>artifact_4_error_budget.json</code>): [ \\delta(\\tau) = 1 - \\sum_i T_\\tau(\\rho)_i ]</p> <p>Let (K(\\tau) = { i : \\rho_i \\ge \\tau }) be the retained set and (Z(\\tau)=\\sum_{k\\in K(\\tau)}\\rho_k = 1-\\delta(\\tau)).</p> <p>Renormalized retained distribution: [ \\hat\\rho_i(\\tau) = \\frac{\\rho_i}{Z(\\tau)} \\quad \\text{for } i \\in K(\\tau) ]</p> <p>Proof sketch (renormalized unity): [ \\sum_{i \\in K(\\tau)} \\hat\\rho_i(\\tau) = \\frac{\\sum_{i \\in K(\\tau)} \\rho_i}{Z(\\tau)} = 1 ]</p> <p>This is why HUF can be \u201ccompression + audit\u201d: you can discard mass, but you must (1) declare it, and (2) renormalize what remains.</p>"},{"location":"huf_math_form_and_function/#32-retainedtarget-form","title":"3.2 Retained\u2011target form (\u03b1)","text":"<p>Sometimes you don\u2019t choose (\\tau) directly. You choose a retained target (\\alpha) (e.g. 0.90), and HUF keeps the smallest set (K) such that: [ \\sum_{i \\in K} \\rho_i \\ge \\alpha ]</p> <p>Operationally: sort by (\\rho_i) descending; take the shortest prefix that reaches (\\alpha).</p> <p>This is exactly the \u201citems to cover 90%\u201d headline used in the long\u2011tail demo: - baseline run: items_to_cover_90pct = 37 - anomaly run: items_to_cover_90pct = 12 \u2192 concentration increased.</p>"},{"location":"huf_math_form_and_function/#4-fixed-points-why-the-cycle-is-stable","title":"4) Fixed points (why the cycle is stable)","text":""},{"location":"huf_math_form_and_function/#41-normalization-is-idempotent-on-the-simplex","title":"4.1 Normalization is idempotent on the simplex","text":"<p>Define normalization: [ N(w) = \\frac{w}{\\sum_k w_k} ]</p> <p>If (\\rho) already satisfies (\\sum \\rho = 1), then: [ N(\\rho) = \\rho ] So all unity\u2011budget distributions are fixed points of (N).</p>"},{"location":"huf_math_form_and_function/#42-a-lyapunov-view-stability-to-unity","title":"4.2 A Lyapunov view (stability to unity)","text":"<p>A simple \u201cdistance to unity\u201d function: [ V(\\rho) = 1 - \\sum_i \\rho_i ] After normalization, (V(\\rho)=0). Any drift away from unity is measurable, correctable, and auditable.</p> <p>In practice, HUF treats \u201cunity drift\u201d as a bug: either a numerical issue (float accumulation) or a forbidden operation (non\u2011conservative propagation).</p>"},{"location":"huf_math_form_and_function/#5-information-theory-optional-but-useful","title":"5) Information theory (optional, but useful)","text":"<p>Once (\\rho) is a probability\u2011like distribution, information tools become usable:</p>"},{"location":"huf_math_form_and_function/#51-entropy-as-concentration","title":"5.1 Entropy as \u201cconcentration\u201d","text":"<p>[ H(\\rho) = -\\sum_i \\rho_i \\log \\rho_i ]</p> <ul> <li>High entropy \u2192 diffuse mass (less concentrated)</li> <li>Low entropy \u2192 concentrated mass (few items dominate)</li> </ul> <p>A friendly scalar is the effective number of items: [ N_{\\mathrm{eff}} = \\exp(H(\\rho)) ] When your anomaly run concentrates, (H) tends to drop and (N_{\\mathrm{eff}}) shrinks.</p>"},{"location":"huf_math_form_and_function/#52-regime-shift-as-divergence","title":"5.2 Regime shift as divergence","text":"<p>Let (\\rho^{(base)}) be baseline (Traffic Phase) and (\\rho^{(anom)}) be exception view (Traffic Anomaly). A regime\u2011shift measure is KL divergence: [ D_{KL}(\\rho^{(anom)} \\Vert \\rho^{(base)}) = \\sum_i \\rho^{(anom)}_i \\log \\frac{\\rho^{(anom)}_i}{\\rho^{(base)}_i} ] You don\u2019t need this to run HUF \u2014 but it\u2019s a clean way to quantify \u201cthe mass moved\u201d.</p>"},{"location":"huf_math_form_and_function/#6-how-this-maps-to-the-three-artifact-first-pillars","title":"6) How this maps to the three \u201cartifact-first\u201d pillars","text":"<p>HUF\u2019s elevator pitch is not \u201cmath for math\u2019s sake.\u201d It\u2019s math that forces auditability:</p> <ul> <li>Coherence map \u2192 (\\rho(R_j)) (where the budget went, by regime)</li> <li>Active set \u2192 (K) (what you kept, explicitly)</li> <li>Trace report \u2192 provenance map (why each kept item is kept, and what it came from)</li> </ul> <p>If you can\u2019t show all three, you\u2019re not doing HUF \u2014 you\u2019re doing storytelling.</p>"},{"location":"huf_math_form_and_function/#math-appendix-artifact-columns-formulas","title":"Math appendix: artifact columns \u2194 formulas","text":"<p>This section lets you jump from an artifact column name to the math above.</p> <p>Important notes: - Column presence varies by adapter, but these names are common across HUF runs. - Suffix meanings are consistent:   - <code>*_pre</code> \u2192 computed on the original unity budget (\\rho)   - <code>*_post</code> \u2192 computed after exclusions + renormalization on the retained distribution (\\hat\\rho) - Let (K) be the retained set, (Z=\\sum_{k\\in K}\\rho_k=1-\\delta).</p>"},{"location":"huf_math_form_and_function/#a-element-level-columns-typical-in-artifact_2_active_setcsv","title":"A) Element-level columns (typical in <code>artifact_2_active_set.csv</code>)","text":"Column Formula Meaning <code>rho_global_pre</code> (\\rho_i) Element\u2019s share of the original unity budget <code>rho_global_post</code> (\\hat\\rho_i=\\rho_i/Z) for (i\\in K) Element\u2019s share after exclusion + renormalization <code>rho_local_pre</code> (\\rho_i / \\rho(R)) where (i\\in R) Element\u2019s share within its regime (pre) <code>rho_local_post</code> (\\hat\\rho_i / \\hat\\rho(R)) Element\u2019s share within its regime (post) <p>Where: - (\\rho(R)=\\sum_{j\\in R}\\rho_j) - (\\hat\\rho(R)=\\sum_{j\\in R\\cap K}\\hat\\rho_j = \\frac{\\sum_{j\\in R\\cap K}\\rho_j}{Z})</p> <p>A useful simplification: [ \\rho_local_post(i\\in R) = \\frac{\\rho_i}{\\sum_{j\\in R\\cap K}\\rho_j} ] (renormalization cancels (Z) inside the regime).</p> <p>Practical reading: <code>rho_global_post</code> answers \u201chow important is this element overall (after pruning)?\u201d <code>rho_local_post</code> answers \u201chow dominant is this element inside its regime?\u201d</p>"},{"location":"huf_math_form_and_function/#b-regime-level-columns-typical-in-artifact_1_coherence_mapcsv","title":"B) Regime-level columns (typical in <code>artifact_1_coherence_map.csv</code>)","text":"Column Formula Meaning <code>rho_global_pre</code> (\\rho(R)=\\sum_{i\\in R}\\rho_i) Regime share in the original distribution <code>rho_global_post</code> (\\hat\\rho(R)=\\sum_{i\\in R\\cap K}\\rho_i/Z) Regime share after exclusion + renormalization <code>rho_discarded_pre</code> (\\sum_{i\\in R\\setminus K}\\rho_i) Amount of original mass discarded inside the regime <p>So the coherence map can be read as: - who dominates now (<code>rho_global_post</code>) - how much tail was cut away (<code>rho_discarded_pre</code>)</p>"},{"location":"huf_math_form_and_function/#c-error-budget-artifact_4_error_budgetjson","title":"C) Error budget (<code>artifact_4_error_budget.json</code>)","text":"<p>Common keys and their math:</p> Key Formula Meaning <code>discarded_budget_global</code> (or similar) (\\delta = 1 - \\sum_{i\\in K}\\rho_i) Total mass discarded globally <code>retained_budget_global</code> (if present) (Z = \\sum_{i\\in K}\\rho_i = 1-\\delta) Total mass retained before renormalization"},{"location":"huf_math_form_and_function/#d-the-items-to-cover-90-headline-used-in-demos","title":"D) The \u201citems to cover 90%\u201d headline (used in demos)","text":"<p>Given active set rows sorted by <code>rho_global_post</code> descending, define: [ k_{0.90} = \\min \\left{k : \\sum_{i=1}^k \\rho^{post}_{(i)} \\ge 0.90 \\right} ]</p> <p>This is what the demo prints as:</p> <ul> <li><code>items_to_cover_90pct baseline -&gt; exception</code></li> </ul> <p>If (k_{0.90}) shrinks in the exception view, you can legitimately say:</p> <p>\u201cConcentration increased.\u201d</p>"},{"location":"huf_math_form_and_function/#e-trace-report-artifact_3_trace_reportjsonl","title":"E) Trace report (<code>artifact_3_trace_report.jsonl</code>)","text":"<p>The trace report isn\u2019t one formula; it\u2019s the provenance map for each retained item: - which input rows/cells formed the finite element, - what regime labels were assigned, - what exclusions applied, - what post-normalized shares were computed.</p> <p>Think of it as a serialized proof object that supports the numbers above.</p>"},{"location":"huf_math_form_and_function/#next","title":"Next","text":"<ul> <li>For the accounting\u2011facing explanation and the baseline\u2192exception\u2192variance flow, see:</li> <li>Long tail (accounting lens) (<code>docs/long_tail_accounting_lens.md</code>)</li> <li>For command discovery and artifact labels, see:</li> <li>CLI command lists + terminology (<code>docs/cli_huf_reference.md</code>)</li> </ul>"},{"location":"jupyter_demos/","title":"Jupyter demos (optional)","text":"<p>Jupyter is optional. It\u2019s useful when you want to read and summarize artifacts interactively.</p>"},{"location":"jupyter_demos/#install-launch-windows-powershell","title":"Install + launch (Windows PowerShell)","text":"<pre><code>.\\.venv\\Scripts\\python -m pip install notebook pandas\n.\\.venv\\Scripts\\python -m notebook\n</code></pre> <p>A browser window opens. Create a new notebook (Python).</p>"},{"location":"jupyter_demos/#important-powershell-is-not-python","title":"Important: PowerShell is not Python","text":"<p>If you type <code>import pandas as pd</code> at a PowerShell prompt, it will fail.</p> <p>Run Python code: - in a notebook cell, or - inside <code>python</code> interactive (<code>.\\.venv\\Scripts\\python</code>), or - from a script file.</p>"},{"location":"jupyter_demos/#suggested-notebook-pattern","title":"Suggested notebook pattern","text":""},{"location":"jupyter_demos/#cell-1-run-a-case-cli","title":"Cell 1 \u2014 run a case (CLI)","text":"<pre><code>import subprocess, sys\nsubprocess.check_call([sys.executable, \"-m\", \"huf_core.cli\", \"--help\"])\n</code></pre> <p>(Or just run the case in PowerShell first, then open artifacts in the next cells.)</p>"},{"location":"jupyter_demos/#cell-2-open-artifacts-markham","title":"Cell 2 \u2014 open artifacts (Markham)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/markham2018/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/markham2018/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(10)\n</code></pre>"},{"location":"jupyter_demos/#cell-3-how-many-items-cover-90","title":"Cell 3 \u2014 \u201chow many items cover 90%?\u201d","text":"<pre><code>active[\"cum\"] = active[\"rho_global_post\"].cumsum()\nactive.loc[active[\"cum\"] &gt;= 0.90, [\"rank\",\"item_id\",\"cum\"]].head(1)\n</code></pre>"},{"location":"jupyter_demos/#cell-4-open-artifacts-traffic-phase","title":"Cell 4 \u2014 open artifacts (Traffic Phase)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/traffic_phase/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/traffic_phase/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(15)\n</code></pre>"},{"location":"jupyter_demos/#export","title":"Export","text":"<p>You can export notebooks to HTML/PDF from the Jupyter UI (File \u2192 Download).</p>"},{"location":"learning_path/","title":"Learning path","text":"<p>HUF is easiest to learn by running a case, then reading the artifacts it produces. This path is designed so the left sidebar is a \u201cdo-this-next\u201d guide.</p> <p>Windows / Conda rule</p> <p>After the repo venv exists, always run tools via the repo executables:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"learning_path/#step-1-install-first-run","title":"Step 1 \u2014 Install + first run","text":"<p>Choose one:</p> <ul> <li>Start here (developer): Start Here \u2192 Developer</li> <li>Start here (beginner): Start Here \u2192 Zero GitHub knowledge</li> </ul> <p>Goal: you can run <code>.\\.venv\\Scripts\\huf --help</code> and produce an <code>out/.../run_stamp.json</code>.</p>"},{"location":"learning_path/#step-2-run-the-two-core-cases","title":"Step 2 \u2014 Run the \u201ctwo core\u201d cases","text":"<p>1) Markham (budget allocation) \u2192 then read: - Worked examples \u2192 Markham</p> <p>2) Traffic Phase (signal phases) \u2192 then read: - Worked examples \u2192 Traffic phase</p>"},{"location":"learning_path/#step-3-understand-the-long-tail-story-accounting-lens","title":"Step 3 \u2014 Understand the \u201clong tail\u201d story (accounting lens)","text":"<ul> <li>Long tail (accounting lens)</li> </ul> <p>Then run the 2\u2011minute demo:</p> <pre><code>.\\.venv\\Scripts\\python scripts/run_long_tail_demo.py --status \"Green Termination\"\n</code></pre>"},{"location":"learning_path/#step-4-try-an-adapter-style-use-case","title":"Step 4 \u2014 Try an adapter-style use case","text":"<ul> <li>Adapters \u2192 Vector DB coherence</li> </ul>"},{"location":"learning_path/#step-5-optional-notebooks","title":"Step 5 \u2014 Optional: notebooks","text":"<ul> <li>Jupyter demos (optional)</li> </ul>"},{"location":"long_tail_accounting_lens/","title":"Long tail (accounting lens)","text":"<p>\\     # Long tail (accounting lens)</p> <pre><code>**Disambiguation (important):** this is **not** \u201cML class imbalance.\u201d  \nHere **long tail** means **mass distribution + exception reweighting** \u2014 the way a budget, ledger, or log stream becomes *more concentrated* when you filter to exceptions.\n\n&gt; **Baseline view** (everything) can look stable, while an **exception-only view** becomes sharply concentrated \u2014 a few regimes dominate and the review list collapses into a small \u201ctop K\u201d.\n\n## Source repo (canonical)\n\n- https://github.com/PeterHiggins19/huf_core_github_v1.1.8_no_inputs\n</code></pre>"},{"location":"markham_worked_example/","title":"Markham worked example (2018 budget)","text":"<p>Run:</p> <pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre> <p>Then open:</p> <ul> <li><code>out/markham2018/artifact_1_coherence_map.csv</code></li> <li><code>out/markham2018/artifact_2_active_set.csv</code></li> <li><code>out/markham2018/artifact_3_trace_report.jsonl</code></li> </ul>"},{"location":"planck/","title":"Planck (LFI 70 GHz) demo","text":"<p>This case demonstrates HUF on a very large HEALPix all\u2011sky map (Planck PR3, LFI 70 GHz). The demo produces the standard HUF artifacts (coherence map, active set, trace report, error budget) so you can inspect what HUF retained vs. discarded at the chosen retained\u2011target.</p> <p>Why this is not auto-downloaded</p> <p>The Planck FITS file is large (~480\u2013500 MB) and some users prefer downloading from ESA\u2019s Planck Legacy Archive vs NASA/IPAC IRSA.</p>"},{"location":"planck/#1-get-the-fits-input","title":"1) Get the FITS input","text":"<p>Expected path in this repo:</p> <pre><code>cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\n</code></pre>"},{"location":"planck/#option-a-recommended-on-windows-bits-download","title":"Option A (recommended on Windows): BITS download","text":"<pre><code>$dest = Join-Path $PWD \"cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits\"\nNew-Item -ItemType Directory -Force (Split-Path $dest) | Out-Null\n$src  = \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\nStart-BitsTransfer -Source $src -Destination $dest\n</code></pre>"},{"location":"planck/#option-b-curlwget","title":"Option B: curl/wget","text":"<pre><code>curl -L -o \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\"   \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\n</code></pre> <p>Windows PowerShell curl alias</p> <p>In Windows PowerShell, <code>curl</code> is an alias for <code>Invoke-WebRequest</code>. Use <code>curl.exe</code> (or use BITS above):</p> <pre><code>curl.exe -L -o \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\"       \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\n</code></pre> <p>Preview page (manual download button):</p> <ul> <li>https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/previews/LFI_SkyMap_070_1024_R3.00_full/index.html</li> </ul>"},{"location":"planck/#2-install-planck-extras","title":"2) Install Planck extras","text":"<p>If you are using the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n</code></pre>"},{"location":"planck/#3-run-the-demo","title":"3) Run the demo","text":"<pre><code>.\\.venv\\Scripts\\huf planck `\n  --fits cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits `\n  --out out\\planck70 `\n  --retained-target 0.97 `\n  --nside-out 64\n</code></pre>"},{"location":"planck/#4-read-the-artifacts","title":"4) Read the artifacts","text":"<p>The output folder contains:</p> <ul> <li><code>artifact_1_coherence_map.csv</code> \u2014 regimes and their retained mass/energy (post\u2011filter)</li> <li><code>artifact_2_active_set.csv</code> \u2014 the retained items (ranked)</li> <li><code>artifact_3_trace_report.jsonl</code> \u2014 what changed across the pass (debug/audit)</li> <li><code>artifact_4_error_budget.json</code> \u2014 global + local discard summary</li> <li><code>run_stamp.json</code>, <code>meta.json</code></li> </ul>"},{"location":"planck/#quick-inspection-no-notebooks-required","title":"Quick inspection (no notebooks required)","text":"<pre><code>.\\.venv\\Scripts\\python - &lt;&lt;'PY'\nimport pandas as pd\ncoh = pd.read_csv('out/planck70/artifact_1_coherence_map.csv')\nact = pd.read_csv('out/planck70/artifact_2_active_set.csv').sort_values('rank')\nprint('\nTop regimes by rho_global_post:')\nprint(coh.sort_values('rho_global_post', ascending=False).head(10).to_string(index=False))\nprint('\nTop 10 retained items:')\nprint(act[['rank','regime_id','item_id','value','rho_global_post','rho_local_post']].head(10).to_string(index=False))\nPY\n</code></pre> <p>What to look for</p> <ul> <li>If one regime dominates the coherence map, it\u2019s a sign the retained budget is concentrated.</li> <li>If you want more/less sparsity, adjust <code>--retained-target</code> or <code>--nside-out</code>.</li> </ul>"},{"location":"quick_run/","title":"Quick Run (copy/paste)","text":"<p>Goal: create a local <code>.venv</code>, fetch inputs, and run the included demos.</p> <p>Run these commands from the repo root (the folder that contains <code>pyproject.toml</code>).</p>"},{"location":"quick_run/#windows-powershell","title":"Windows (PowerShell)","text":""},{"location":"quick_run/#1-bootstrap-install","title":"1) Bootstrap + install","text":"<pre><code>python scripts/bootstrap.py\n.\\.venv\\Scripts\\python -m pip install -e .\n</code></pre>"},{"location":"quick_run/#2-fetch-markham-toronto-inputs","title":"2) Fetch Markham + Toronto inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"quick_run/#3-run-the-demos","title":"3) Run the demos","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"quick_run/#4-two-minute-long-tail-demo-recommended","title":"4) Two-minute long-tail demo (recommended)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/run_long_tail_demo.py --status \"Green Termination\"\n</code></pre>"},{"location":"quick_run/#5-docs-site-local","title":"5) Docs site (local)","text":"<p>Always:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Strict check:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs build --strict\n</code></pre>"},{"location":"quick_run/#macos-linux-bashzsh","title":"macOS / Linux (bash/zsh)","text":"<pre><code>python3 scripts/bootstrap.py\n./.venv/bin/python -m pip install -e .\n./.venv/bin/python scripts/fetch_data.py --markham --toronto --yes\n\n./.venv/bin/huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n./.venv/bin/huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n./.venv/bin/huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"reference_manual/","title":"HUF Reference Manual","text":"<p>Updated: 2026-02-17</p> <p>This manual is the \u201chow to run it\u201d companion to the handbook. It\u2019s written for:</p> <ul> <li>GUI-only users (download a ZIP, double-click a Windows starter),</li> <li>researchers who live in Excel + theory,</li> <li>anyone who wants reproducible artifacts without learning Git on day one.</li> </ul>"},{"location":"reference_manual/#1-quick-start-windows-no-git-required","title":"1) Quick Start (Windows, no Git required)","text":""},{"location":"reference_manual/#option-a-easiest-github-release-zip","title":"Option A \u2014 easiest: GitHub Release ZIP","text":"<ol> <li>Download the ZIP from the project\u2019s GitHub Releases page.</li> <li>Unzip it somewhere simple (Desktop is fine).</li> <li>Double-click: <code>START_HERE_WINDOWS.bat</code></li> </ol> <p>What it does:</p> <ul> <li>creates a local virtual environment in <code>.venv</code></li> <li>installs HUF in editable mode (local)</li> <li>fetches Markham + Toronto inputs (unless you skip)</li> <li>prints the exact commands to run the demos</li> </ul> <p>Tip: If Windows shows a security warning the first time, click \u201cMore info\u201d \u2192 \u201cRun anyway\u201d.</p>"},{"location":"reference_manual/#option-b-github-desktop-recommended-once-youre-comfortable","title":"Option B \u2014 GitHub Desktop (recommended once you\u2019re comfortable)","text":"<p>Use GitHub Desktop to keep your folder synced with GitHub.</p> <p>Day-to-day:</p> <ul> <li>Fetch checks for updates.</li> <li>Pull downloads updates.</li> <li>Commit records your changes.</li> <li>Push/Sync uploads your changes.</li> </ul>"},{"location":"reference_manual/#2-fetching-input-data-real-public-sources","title":"2) Fetching input data (real public sources)","text":"<p>Run these from the repo root (the folder that contains <code>pyproject.toml</code>).</p>"},{"location":"reference_manual/#markham-2018-budget-allocation-xlsx","title":"Markham (2018 Budget Allocation XLSX)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham\n</code></pre> <p>Expected file:</p> <ul> <li><code>cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></li> </ul>"},{"location":"reference_manual/#toronto-traffic-signals-timing-csv","title":"Toronto (Traffic signals timing \u2192 CSV)","text":"<p>Non-interactive default selection:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre> <p>Expected files:</p> <ul> <li><code>cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv</code></li> <li><code>cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv</code></li> </ul> <p>Toronto schema expected by HUF traffic adapters:</p> <ul> <li>required: <code>TCS</code>, <code>PHASE</code></li> <li>optional: <code>PHASE_STATUS_TEXT</code>, <code>PHASE_CALL_TEXT</code></li> </ul>"},{"location":"reference_manual/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>You\u2019ll end up with a FITS file such as:</p> <ul> <li><code>cases/planck70/inputs/...70...fits</code></li> </ul>"},{"location":"reference_manual/#3-running-the-included-cases-windows-powershell","title":"3) Running the included cases (Windows PowerShell)","text":""},{"location":"reference_manual/#a-markham-2018-fund-weighted-expenditures","title":"A) Markham 2018 (fund-weighted expenditures)","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre>"},{"location":"reference_manual/#b-toronto-traffic-phase-band-extraction","title":"B) Toronto traffic phase (band extraction)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre>"},{"location":"reference_manual/#c-toronto-traffic-anomaly-share-hotspots","title":"C) Toronto traffic anomaly (share + hotspots)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"reference_manual/#d-planck-70-ghz-map-coherence-stability","title":"D) Planck 70 GHz (map \u2192 coherence \u2192 stability)","text":"<pre><code>.\\.venv\\Scripts\\huf planck --fits cases/planck70/inputs/YOUR_70GHZ_MAP.fits --out out/planck70\n</code></pre>"},{"location":"reference_manual/#4-understanding-run_stampjson-your-reproducibility-receipt","title":"4) Understanding <code>run_stamp.json</code> (your reproducibility receipt)","text":"<p>HUF writes a stamp like:</p> <pre><code>{\n  \"dataset_id\": \"...\",\n  \"code_hash\": \"...\",\n  \"param_hash\": \"...\",\n  \"created_utc\": \"...\",\n  \"run_id\": \"...\"\n}\n</code></pre> <p>Interpretation:</p> <ul> <li><code>dataset_id</code> \u2014 identifier derived from the input file(s)</li> <li><code>code_hash</code> \u2014 identifier for the code state that produced artifacts</li> <li><code>param_hash</code> \u2014 identifier for your parameterization (\u03c4 grid, budgets, etc.)</li> <li><code>run_id</code> \u2014 unique run identifier</li> </ul> <p>If two runs have the same <code>dataset_id + code_hash + param_hash</code>, their artifacts should match (modulo timestamps).</p>"},{"location":"reference_manual/#5-troubleshooting-windows-focused","title":"5) Troubleshooting (Windows-focused)","text":""},{"location":"reference_manual/#ssl-certificate_verify_failed","title":"\u201cSSL: CERTIFICATE_VERIFY_FAILED\u201d","text":"<p>Try:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\python -m pip install certifi\n.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"reference_manual/#http-error-404-during-toronto-fetch","title":"\u201cHTTP Error 404\u201d during Toronto fetch","text":"<p>Default:</p> <ul> <li><code>https://open.toronto.ca/api/3/action</code></li> </ul> <p>Override explicitly:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes --toronto-ckan https://open.toronto.ca/api/3/action\n</code></pre>"},{"location":"reference_manual/#file-not-found-casesinputs","title":"\u201cFile not found \u2026 cases/.../inputs/...\u201d","text":"<p>Run fetch first:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"reference_manual/#6-build-preview-the-docs-site","title":"6) Build / preview the docs site","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Strict build check:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs build --strict\n</code></pre>"},{"location":"start_here/","title":"Start Here (Developer)","text":"<p>This page assumes you already have the repo locally (git clone or GitHub Desktop).</p> <p>Goal: get a working <code>.venv</code>, fetch inputs, run demos.</p> <p>Run commands from the repo root (folder containing <code>pyproject.toml</code>).</p>"},{"location":"start_here/#windows-powershell","title":"Windows (PowerShell)","text":""},{"location":"start_here/#create-venv-install","title":"Create venv + install","text":"<pre><code>python scripts/bootstrap.py\n.\\.venv\\Scripts\\python -m pip install -e .\n</code></pre>"},{"location":"start_here/#ensure-the-repo-venv-huf-wins-over-conda","title":"Ensure the repo venv <code>huf</code> wins over conda","text":"<p>Prefer calling the repo executables explicitly:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"start_here/#fetch-inputs","title":"Fetch inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"start_here/#run-demos","title":"Run demos","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"start_here/#planck-optional","title":"Planck (optional)","text":"<pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n# (place the FITS at cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits)\n.\\.venv\\Scripts\\huf planck --fits cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits --out out/planck70 --retained-target 0.97 --nside-out 64\n</code></pre>"},{"location":"start_here/#macos-linux-bashzsh","title":"macOS / Linux (bash/zsh)","text":"<pre><code>python3 scripts/bootstrap.py\n./.venv/bin/python -m pip install -e .\n./.venv/bin/python scripts/fetch_data.py --markham --toronto --yes\n\n./.venv/bin/huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n./.venv/bin/huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n./.venv/bin/huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"theory_notes/","title":"Theory Notes (HUF / UBH)","text":"<p>Updated: 2026-02-17</p> <p>This repo is deliberately artifact-first: you can run real datasets and inspect outputs without accepting any theory claims.</p> <p>If you do want the formal structure (definitions, taxonomy, and expanded proofs), see:</p> <ul> <li><code>docs/The_Higgins_Unity_Framework.md</code> (full theoretical handbook)</li> <li>Handbook (conceptual + case-study narrative)</li> </ul>"},{"location":"theory_notes/#what-huf-is-in-one-paragraph","title":"What HUF is (in one paragraph)","text":"<p>HUF is a reproducibility wrapper around a single contract: a Unity\u2011Budgeted Hierarchy (UBH). A UBH is a hierarchy where each node\u2019s outgoing weights form a budgeted, normalized distribution (a \u201cunity\u201d constraint). HUF turns inputs into UBH elements, then emits auditable artifacts (tables, maps, images) plus a stability sweep that shows what structure survives across \u03c4.</p>"},{"location":"theory_notes/#why-unity-budget-matters","title":"Why \u201cunity budget\u201d matters","text":"<p>In practice, a unity budget behaves like a conserved quantity: - it forces competing explanations to share the same budget, - it makes comparisons across scales meaningful (local vs global), - it makes stability sweeps interpretable (what stays when \u03c4 tightens?).</p> <p>This was originally motivated by loudspeaker dispersion/diffraction work, but the same contract applies anywhere \u201cparts must sum to a whole\u201d.</p>"},{"location":"theory_notes/#proof-burden-and-how-huf-helps","title":"Proof burden and how HUF helps","text":"<p>HUF does not ask you to \u201cbelieve the proof.\u201d It asks you to: 1) run the same public dataset, 2) confirm you get the same artifacts, 3) inspect the stability packet, 4) only then argue about interpretation.</p> <p>That\u2019s why every run writes a <code>run_stamp.json</code>.</p>"},{"location":"traffic_phase_worked_example/","title":"Traffic Phase worked example (Toronto signals)","text":"<p>Run baseline:</p> <pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre> <p>Run exception-only:</p> <pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre> <p>See: - Long tail (accounting lens)</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This page collects common \u201cWindows reality\u201d problems people hit when they\u2019re new to Python tooling.</p>"},{"location":"troubleshooting/#i-typed-huf-and-got-syntaxerror","title":"\u201cI typed <code>huf ...</code> and got <code>SyntaxError</code>\u201d","text":"<p>If you see this:</p> <ul> <li><code>&gt;&gt;&gt; huf traffic ...</code></li> <li><code>SyntaxError: invalid syntax</code></li> </ul> <p>\u2026you typed a shell command inside Python.</p> <p>Fix:</p> <p>1) exit Python: type <code>exit()</code> (or Ctrl+Z then Enter) 2) run the command in PowerShell:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"troubleshooting/#make-is-not-recognized","title":"\u201c<code>make</code> is not recognized\u201d","text":"<p>Windows does not ship <code>make</code>.</p> <p>For the Planck download guide, use:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre>"},{"location":"troubleshooting/#venv-exists-but-commands-run-the-wrong-python","title":"\u201c.venv exists but commands run the wrong Python\u201d","text":"<p>If you see paths like <code>miniconda3\\Scripts\\huf.exe</code>, you\u2019re running a global install, not the repo venv.</p> <p>Use the venv explicitly:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"troubleshooting/#ssl-certificate-errors-certificate_verify_failed","title":"SSL certificate errors (CERTIFICATE_VERIFY_FAILED)","text":"<p>Fix:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install certifi\n.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"vector_db_coherence/","title":"Vector DB coherence (from retrieval results)","text":"<p>This adapter turns retrieval results into a HUF run so you can audit composition (not just \u201cquality\u201d):</p> <ul> <li>Regime dominance: which namespace / collection / tenant / source dominates the kept set</li> <li>Concentration: do a few items explain most of the kept mass?</li> <li>Declared discards: what fell below threshold, and how much mass was discarded (no silent drops)</li> <li>Trace: why an item is retained (provenance + reasoning)</li> </ul> <p>No live vector DB required. You provide a JSONL/CSV/TSV export of retrieval results.</p> <p>Disambiguation: this is not \u201cML class imbalance.\u201d Here \u201clong tail\u201d means mass distribution + exception reweighting \u2014 the accounting move: baseline P&amp;L \u2192 exception-only P&amp;L \u2192 ranked variance review.</p> <p>PowerShell vs Python: run commands in the shell</p> <p>If your prompt looks like <code>&gt;&gt;&gt;</code>, you are inside Python. Exit back to PowerShell with <code>exit()</code> (or Ctrl+Z then Enter), then run the commands below.</p>"},{"location":"vector_db_coherence/#start-here","title":"Start here","text":"<ul> <li>One-page brief: <code>vector_db_coherence_one_pager.md</code></li> <li>This page: full walkthrough + \u201cwhat to look for\u201d + future extension patterns</li> </ul>"},{"location":"vector_db_coherence/#concepts","title":"Concepts","text":""},{"location":"vector_db_coherence/#regimes","title":"Regimes","text":"<p>A regime is the grouping you care about: <code>namespace</code>, <code>collection</code>, <code>tenant</code>, <code>source</code>, etc.</p> <p>You choose it via <code>--regime-field</code>.</p>"},{"location":"vector_db_coherence/#tau-global-threshold","title":"Tau (global threshold)","text":"<p><code>--tau-global</code> sets the discard boundary in the mass frame.</p> <ul> <li>Larger <code>tau</code> = stricter threshold = more discards (often more concentration)</li> <li>Smaller <code>tau</code> = looser threshold = fewer discards (often less concentration)</li> </ul>"},{"location":"vector_db_coherence/#the-proof-line-items_to_cover_90pct","title":"The proof line: items_to_cover_90pct","text":"<p><code>items_to_cover_90pct = k</code> means:</p> <p>The top k retained items explain 90% of the post-normalized mass.</p> <p>Smaller <code>k</code> \u21d2 more concentrated \u21d2 a tiny set dominates retrieval.</p>"},{"location":"vector_db_coherence/#input-format-jsonl","title":"Input format (JSONL)","text":"<p>One JSON object per line.</p>"},{"location":"vector_db_coherence/#required-fields","title":"Required fields","text":"<ul> <li><code>id</code> (string): unique item id (document id, chunk id, ticket id, etc.)</li> <li><code>score</code> (number): similarity / relevance score (higher = better)</li> </ul>"},{"location":"vector_db_coherence/#optional-fields-regimes","title":"Optional fields (regimes)","text":"<p>Include any grouping fields you want to audit by, e.g.:</p> <ul> <li><code>namespace</code></li> <li><code>collection</code></li> <li><code>source</code></li> <li><code>tenant</code></li> <li><code>index</code></li> </ul> <p>Example:</p> <pre><code>{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_002\",\"score\":0.63,\"namespace\":\"kb\",\"source\":\"manual\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n{\"id\":\"doc_102\",\"score\":0.12,\"namespace\":\"tickets\",\"source\":\"ops\"}\n</code></pre>"},{"location":"vector_db_coherence/#60-second-run-windows-powershell","title":"60-second run (Windows PowerShell)","text":"<p>PowerShell note: use backticks for line continuation (not <code>\\</code>).</p> <pre><code>$py  = \".\\.venv\\Scripts\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_demo\"\n\nNew-Item -ItemType Directory -Force (Split-Path $in) | Out-Null\nNew-Item -ItemType Directory -Force $out | Out-Null\n\n@'\n{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_002\",\"score\":0.63,\"namespace\":\"kb\",\"source\":\"manual\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n{\"id\":\"doc_102\",\"score\":0.12,\"namespace\":\"tickets\",\"source\":\"ops\"}\n'@ | Set-Content -Encoding utf8 $in\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out $out\n</code></pre>"},{"location":"vector_db_coherence/#two-tau-delta-the-repeatable-headline","title":"Two-tau delta (the repeatable headline)","text":"<p>Sometimes you want one line a teammate can repeat:</p> <p>Concentration increased: items_to_cover_90pct X -&gt; Y</p> <pre><code>$py  = \".\\.venv\\Scripts\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_delta\"\n\n&amp; $py scripts/run_vector_db_concentration_delta.py `\n  --in $in `\n  --out $out `\n  --tau-a 0.005 `\n  --tau-b 0.02 `\n  --regime-field namespace\n</code></pre> <p>Example:</p> <pre><code>Concentration increased: items_to_cover_90pct 37 -&gt; 12\n</code></pre>"},{"location":"vector_db_coherence/#artifacts-the-contract","title":"Artifacts (the contract)","text":"<p>A valid run folder should contain at least:</p> <ul> <li><code>artifact_1_coherence_map.csv</code> (regime ranking)</li> <li><code>artifact_2_active_set.csv</code> (retained items)</li> <li><code>artifact_4_error_budget.json</code> (declared discards)</li> </ul> <p>Optional but strongly recommended:</p> <ul> <li><code>artifact_3_trace_report.jsonl</code> (why retained)</li> <li><code>meta.json</code>, <code>run_stamp.json</code></li> </ul>"},{"location":"vector_db_coherence/#example-output-interpretation-screenshot-style","title":"Example output interpretation (screenshot-style)","text":"<p>Think of this as \u201cwhat you would circle in a screenshot.\u201d</p>"},{"location":"vector_db_coherence/#1-artifact_1_coherence_mapcsv-regime-ranking","title":"1) artifact_1_coherence_map.csv (regime ranking)","text":"<p>Open in Excel and sort descending by <code>rho_global_post</code>.</p> <p>Look for:</p> <ul> <li>Top regime &gt; 0.50 (dominance)</li> <li>Top 2\u20133 regimes cover most of the mass (regime concentration)</li> </ul>"},{"location":"vector_db_coherence/#2-artifact_2_active_setcsv-ranked-review-list","title":"2) artifact_2_active_set.csv (ranked review list)","text":"<p>Sort descending by <code>rho_global_post</code>:</p> <ul> <li>This is your global \u201creview list\u201d (what actually matters).</li> </ul> <p>Then filter by <code>regime_id</code> and sort by <code>rho_local_post</code>:</p> <ul> <li>Top items inside a regime.</li> </ul>"},{"location":"vector_db_coherence/#3-artifact_4_error_budgetjson-declared-discards","title":"3) artifact_4_error_budget.json (declared discards)","text":"<p>Look for:</p> <ul> <li><code>discarded_budget_global</code> (or similarly named key)</li> </ul> <p>Large discard means tau is aggressively pruning.</p>"},{"location":"vector_db_coherence/#patterns-youll-care-about-later-future-interest","title":"Patterns you\u2019ll care about later (future interest)","text":""},{"location":"vector_db_coherence/#regime-drift-over-time","title":"Regime drift over time","text":"<p>Run the same query daily and watch:</p> <ul> <li>top regimes change</li> <li><code>items_to_cover_90pct</code> trend down (concentration risk) or up (dispersion)</li> </ul>"},{"location":"vector_db_coherence/#multi-tenant-isolation-checks","title":"Multi-tenant isolation checks","text":"<p>Use <code>--regime-field tenant</code> and look for:</p> <ul> <li>one tenant dominating another tenant\u2019s query output</li> </ul>"},{"location":"vector_db_coherence/#ci-guardrails","title":"CI guardrails","text":"<p>After any retrieval pipeline change:</p> <ul> <li>run coherence on a fixed set of queries</li> <li>fail if concentration spikes or a regime monopolizes results</li> </ul>"},{"location":"vector_db_coherence/#accounting-mapping","title":"Accounting mapping","text":"<p>Treat regimes like cost centers:</p> <ul> <li>baseline P&amp;L = full retrieval results</li> <li>exception-only P&amp;L = tighter tau</li> <li>ranked variance review = active set sorted by <code>rho_global_post</code></li> </ul>"},{"location":"vector_db_coherence/#common-issues","title":"Common issues","text":""},{"location":"vector_db_coherence/#i-typed-huf-and-got-syntaxerror","title":"\u201cI typed <code>huf ...</code> and got SyntaxError\u201d","text":"<p>If you see <code>&gt;&gt;&gt;</code>, you\u2019re inside Python. Exit with <code>exit()</code> and run in PowerShell.</p>"},{"location":"vector_db_coherence_one_pager/","title":"Vector DB coherence (one-page brief)","text":"<p>No live vector DB required: export retrieval results (JSONL/CSV/TSV) and audit composition.</p>"},{"location":"vector_db_coherence_one_pager/#what-you-get","title":"What you get","text":"<p>A repeatable audit that shows:</p> <ul> <li>which regimes dominate (<code>rho_global_post</code>)</li> <li>how concentrated the kept set is (<code>items_to_cover_90pct</code>)</li> <li>what was discarded (error budget)</li> </ul>"},{"location":"vector_db_coherence_one_pager/#artifacts-open-in-this-order","title":"Artifacts (open in this order)","text":"<p>1) <code>artifact_1_coherence_map.csv</code> \u2014 regime ranking    Sort by <code>rho_global_post</code> \u21d2 which regimes dominate 2) <code>artifact_2_active_set.csv</code> \u2014 ranked review list    Sort by <code>rho_global_post</code> \u21d2 which items matter most overall 3) <code>artifact_4_error_budget.json</code> \u2014 declared discards    Look for <code>discarded_budget_global</code></p>"},{"location":"vector_db_coherence_one_pager/#60-second-run-windows-repo-venv","title":"60-second run (Windows / repo venv)","text":"<pre><code>$py  = \".\\.venv\\Scripts\\python.exe\"\n$in  = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_demo\"\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\n&amp; $py scripts/inspect_huf_artifacts.py --out $out\n</code></pre>"},{"location":"vector_db_coherence_one_pager/#two-tau-headline-optional","title":"Two-tau headline (optional)","text":"<pre><code>$out = \"out/vector_db_delta\"\n&amp; $py scripts/run_vector_db_concentration_delta.py `\n  --in $in `\n  --out $out `\n  --tau-a 0.005 `\n  --tau-b 0.02 `\n  --regime-field namespace\n</code></pre> <p>Example:</p> <pre><code>Concentration increased: items_to_cover_90pct 37 -&gt; 12\n</code></pre>"}]}