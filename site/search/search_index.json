{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Higgins Unity Framework (HUF) \u2014 HUF Core docs","text":"<p>HUF Core is a runnable, artifact-first toolkit: you run a case, then you read the outputs it produced.</p>"},{"location":"#where-to-start","title":"Where to start","text":"<ul> <li>Learning Path: follow the \u201cdo-this-next\u201d flow in the left sidebar.   \u2192 Learning Path</li> <li>Beginner (no Git): point-and-click setup, then copy/paste commands.   \u2192 Start Here \u2192 Zero GitHub Knowledge</li> <li>Developer: bootstrap a repo venv + run docs locally.   \u2192 Start Here \u2192 Developer</li> <li>If anything breaks: Windows/Conda fixes.   \u2192 Troubleshooting</li> </ul>"},{"location":"#one-minute-demo-windows-powershell","title":"One-minute demo (Windows PowerShell)","text":"<p>After you have created the repo virtual environment (<code>.venv</code>) and installed dependencies:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre> <p>Then open:</p> <ul> <li><code>out/markham2018/artifact_1_coherence_map.csv</code> (regimes)</li> <li><code>out/markham2018/artifact_2_active_set.csv</code> (retained set)</li> <li><code>out/markham2018/artifact_3_trace_report.jsonl</code> (audit trail)</li> </ul>"},{"location":"#run-the-docs-site-locally-windows","title":"Run the docs site locally (Windows)","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Tip: If copy/paste ever seems \u201cweird\u201d on Windows, prefer forward slashes in file paths (e.g., <code>scripts/fetch_data.py</code>, <code>cases/...</code>) and only use backslashes for the venv executables (e.g., <code>.\\.venv\\Scripts\\python</code>).</p>"},{"location":"The_Higgins_Unity_Framework/","title":"The Higgins Unity Framework (HUF)","text":"<p>This project is the HUF Core implementation: a practical toolkit you can run to turn messy real\u2011world datasets into consistent, comparable outputs.</p> <p>If you\u2019re not technical, don\u2019t worry \u2014 you can still use HUF by following the step\u2011by\u2011step guides.</p>"},{"location":"The_Higgins_Unity_Framework/#plainenglish-idea","title":"Plain\u2011English idea","text":"<p>Real systems produce lots of different signals:</p> <ul> <li>budgets, traffic timing, anomalies, logs, counts, categories\u2026</li> <li>all with different units, scales, and missing values</li> </ul> <p>HUF\u2019s core trick is to convert those signals into a normalized representation so that:</p> <ul> <li>different sources can be compared fairly</li> <li>changes over time are easier to detect</li> <li>\u201cwhat matters most\u201d can be ranked without hand\u2011tuning every dataset</li> </ul> <p>In this repo, that \u201cnormalization\u201d mostly shows up as:</p> <ul> <li>cleaning inputs</li> <li>mapping columns into a consistent schema</li> <li>producing standardized outputs you can analyze or visualize</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#what-you-get-from-this-repository","title":"What you get from this repository","text":"<ul> <li>Repeatable demos (\u201ccases\u201d) with real civic datasets (Markham + Toronto)</li> <li>A command line tool (<code>huf ...</code>) to run those cases</li> <li>A structure you can copy to add your own data adapters and cases</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#key-concepts-no-math","title":"Key concepts (no math)","text":""},{"location":"The_Higgins_Unity_Framework/#1-inputs-adapters-outputs","title":"1) Inputs \u2192 adapters \u2192 outputs","text":"<p>A \u201ccase\u201d takes some input file(s), runs a transformation, and writes results to an output folder.</p> <ul> <li>Input examples: <code>.xlsx</code>, <code>.csv</code>, large datasets (Planck is guided/manual)</li> <li>Output examples: cleaned tables, normalized metrics, reports</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#2-normalization-the-unity-idea","title":"2) Normalization (the \u201cunity\u201d idea)","text":"<p>Normalization means turning different kinds of numbers into a consistent scale so they can be compared.</p> <p>Example: - Dataset A ranges from 0\u201310 - Dataset B ranges from 0\u201310,000</p> <p>After normalization, both can live on the same scale, so ranking and anomaly detection are meaningful.</p>"},{"location":"The_Higgins_Unity_Framework/#3-cases-are-learning-modules","title":"3) \u201cCases\u201d are learning modules","text":"<p>Each case is both: - a working example you can run today - a template you can copy when adding your own workflow</p>"},{"location":"The_Higgins_Unity_Framework/#where-to-begin","title":"Where to begin","text":"<ol> <li>Follow the beginner path: Learning Path </li> <li>Run a demo: Cases </li> <li>If you hit errors: Troubleshooting</li> </ol>"},{"location":"The_Higgins_Unity_Framework/#advanced-theory-optional","title":"Advanced / theory (optional)","text":"<p>Some HUF writings discuss deeper mathematics (categories, morphisms, topology, etc.). Those are not required to run the tools in this repo.</p> <p>If you want the deeper background, start with: - Theory Notes - Handbook</p>"},{"location":"The_Higgins_Unity_Framework/#glossary","title":"Glossary","text":"<ul> <li>Case: a runnable example workflow (input \u2192 process \u2192 output).</li> <li>Adapter: code that reads a particular dataset shape and maps it into HUF\u2019s expected schema.</li> <li>Normalization: converting values into a consistent scale to compare across sources.</li> <li>Schema: the column names / fields that HUF expects for a given workflow.</li> </ul> <p>Note: The original author notes and drafts existed as <code>.Markdown</code>. This repo now keeps documentation in Markdown (<code>.md</code>) so it renders well on GitHub and GitHub Pages.</p>"},{"location":"cases/","title":"Included cases","text":"<p>These cases are ready-to-run from a fresh clone.</p>"},{"location":"cases/#inputs","title":"Inputs","text":"<ul> <li>\u2705 Markham XLSX: shipped in <code>cases/markham2018/inputs/</code></li> <li>\u2705 Toronto traffic CSV: shipped in <code>cases/traffic_phase/inputs/</code> and <code>cases/traffic_anomaly/inputs/</code></li> <li>\u274c Planck FITS: not shipped (large). Use <code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide</code> for a copy/paste download guide.</li> </ul>"},{"location":"cases/#outputs","title":"Outputs","text":"<ul> <li>New runs write to <code>out/</code> (recommended).</li> <li> <p>Each run produces the core artifacts:</p> </li> <li> <p><code>artifact_1_coherence_map.csv</code></p> </li> <li><code>artifact_2_active_set.csv</code></li> <li><code>artifact_3_trace_report.jsonl</code></li> <li><code>artifact_4_error_budget.json</code></li> <li>plus <code>meta.json</code> and <code>run_stamp.json</code></li> </ul>"},{"location":"cases/#quick-commands-windows-powershell","title":"Quick commands (Windows PowerShell)","text":"<p>Fetch (optional refresh of shipped inputs):</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>Run Markham:</p> <pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre> <p>Run Traffic Phase:</p> <pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre> <p>Run Traffic Anomaly:</p> <pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre> <p>Planck guide (prints download steps, does not download automatically):</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre>"},{"location":"cases/#traffic-phase-vs-traffic-anomaly","title":"Traffic Phase vs Traffic Anomaly","text":""},{"location":"cases/#a-practical-accounting-lens-on-non-linear-long-tail-behavior","title":"A practical \u201caccounting lens\u201d on non-linear + long-tail behavior","text":"<p>Traffic Phase and Traffic Anomaly use the same input CSV, but they answer different questions:</p> <ul> <li>Traffic Phase (baseline): \u201cWhat does normal operation look like, and where is most of the mass?\u201d</li> <li>Traffic Anomaly (diagnostic): \u201cWithin a specific exception status, where is the mass now \u2014 and what changed?\u201d</li> </ul> <p>If you\u2019re coming from accounting, map it like this:</p> <ul> <li> <p>Traffic Phase = the whole ledger.   You look at all transactions and build a stable picture of allocation across cost centers.</p> </li> <li> <p>Traffic Anomaly = a filtered sub-ledger.   For example: only refunds, only manual journal entries, only write-offs, or only policy exceptions.</p> </li> </ul> <p>Why this is powerful:</p> <p>1) Long-tail: In real systems, you usually have many small contributors.    Most of them don\u2019t matter operationally \u2014 until you filter to a rare event type. Then the \u201ctail\u201d can become the story.</p> <p>2) Non-linear: The impact is not proportional to row counts.    A small fraction of records (or a rare status) can concentrate into a few regimes (intersections / cost centers) and dominate your risk or operational burden.</p> <p>3) Auditability: HUF gives you the \u201cwhere the mass is\u201d ranking plus a trace report.    That means you can justify why \u201cthese 12 intersections\u201d or \u201cthese 7 accounts\u201d are your top review list, without hand-waving.</p> <p>How to use both cases together:</p> <ul> <li>Run Traffic Phase to establish the stable baseline distribution.</li> <li>Run Traffic Anomaly for a named status (e.g., <code>\"Green Termination\"</code>) and compare:</li> <li>which regimes jump up the ranking,</li> <li>how concentrated the retained set becomes,</li> <li>and how much mass sits \u201cnear tau\u201d (stability sensitivity).</li> </ul> <p>This is the same workflow as: baseline P&amp;L \u2192 exception-only P&amp;L \u2192 ranked variance review.</p>"},{"location":"cases/#verify-a-run-quickly","title":"Verify a run quickly","text":"<p>After any run, check the output folder has at least:</p> <ul> <li><code>run_stamp.json</code></li> <li><code>artifact_1_coherence_map.csv</code></li> <li><code>artifact_2_active_set.csv</code></li> </ul> <p>Example:</p> <pre><code>Test-Path out/markham2018/run_stamp.json\nTest-Path out/markham2018/artifact_1_coherence_map.csv\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome \u2014 even small things like typo fixes or \u201cthis step confused me\u201d issues help a lot.</p>"},{"location":"contributing/#the-easiest-ways-to-help","title":"The easiest ways to help","text":"<ol> <li>Open an Issue (best for feedback / questions)</li> <li>Describe what you tried, what happened, and what you expected.</li> <li> <p>If it\u2019s about a command, paste the exact command + the terminal output.</p> </li> <li> <p>Send a Pull Request</p> </li> <li>Fork the repo \u2192 create a branch \u2192 make changes \u2192 open a PR.</li> <li>Docs-only PRs are totally fine (they\u2019re often the most valuable).</li> </ol>"},{"location":"contributing/#suggested-contribution-ideas","title":"Suggested contribution ideas","text":"<ul> <li>Add a small new \u201cworked example\u201d page for a dataset you care about</li> <li>Improve Windows copy/paste reliability</li> <li>Add tiny helper scripts (inspect artifacts, sanity checks, etc.)</li> </ul>"},{"location":"contributing/#repo-settings-that-help-contributors","title":"Repo settings that help contributors","text":"<ul> <li>Issues: Enabled</li> <li>Pull requests from forks: Enabled</li> <li>Branch protection (optional): require CI checks on <code>main</code></li> </ul> <p>The canonical contributor guidance lives in the root CONTRIBUTING.md in the repo.</p>"},{"location":"data_sources/","title":"Data Sources &amp; Fetching","text":"<p>HUF Core demos use a mix of bundled inputs and fetched inputs.</p>"},{"location":"data_sources/#recommended-rule-windowsconda","title":"Recommended rule (Windows/Conda)","text":"<p>After the repo venv exists, always run fetch via:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --help\n</code></pre>"},{"location":"data_sources/#markham-2018-budget-allocation-workbook","title":"Markham (2018 Budget Allocation workbook)","text":"<p>Fetch:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham\n</code></pre> <p>Expected file:</p> <ul> <li><code>cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></li> </ul>"},{"location":"data_sources/#toronto-traffic-signals-timing-csv","title":"Toronto (Traffic signals timing \u2192 CSV)","text":"<p>Non-interactive (best for copy/paste):</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre> <p>Expected files:</p> <ul> <li><code>cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv</code></li> <li><code>cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv</code></li> </ul>"},{"location":"data_sources/#planck-70-ghz-guidedmanual","title":"Planck 70\u202fGHz (guided/manual)","text":"<p>Planck files are large; HUF prints a copy/paste guide instead of downloading automatically:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>You will download a 70\u202fGHz FITS file into:</p> <ul> <li><code>cases/planck70/inputs/</code></li> </ul> <p>Then run:</p> <pre><code>.\\.venv\\Scripts\\huf planck --fits cases/planck70/inputs/YOUR_70GHZ_MAP.fits --out out/planck70\n</code></pre>"},{"location":"get_started_readme/","title":"HUF Get Started Package","text":"<p>Open Start_Here.md or Start_Here.md.</p> <ul> <li>If you already have the HUF GitHub package, run the start scripts in the repo root:</li> <li>Windows: <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: <code>START_HERE_MAC.command</code></li> <li>Linux: <code>start_here_linux.sh</code></li> </ul> <p>This package does not include large input datasets. Data sources and instructions are in <code>docs/data_sources.md</code>.</p>"},{"location":"get_started_zero_github/","title":"Start Here (Zero GitHub Knowledge)","text":"<p>You can run HUF without learning command-line git. The goal is:</p> <ul> <li>you can run <code>.\\.venv\\Scripts\\huf --help</code></li> <li>you can produce <code>out/.../run_stamp.json</code></li> </ul>"},{"location":"get_started_zero_github/#option-1-easiest-recommended-the-one-click-starter","title":"Option 1 \u2014 easiest (recommended): the one-click starter","text":"<p>From the repo folder:</p> <ul> <li>Windows: double-click <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: right-click <code>START_HERE_MAC.command</code> \u2192 Open</li> <li>Linux: <code>./start_here_linux.sh</code></li> </ul> <p>This creates a local <code>.venv</code> and installs what you need.</p>"},{"location":"get_started_zero_github/#option-2-manual-windows-powershell","title":"Option 2 \u2014 manual (Windows PowerShell)","text":"<p>From the repo root:</p>"},{"location":"get_started_zero_github/#1-create-a-repo-virtual-environment","title":"1) Create a repo virtual environment","text":"<pre><code>python -m venv .venv\n.\\.venv\\Scripts\\python -m pip install --upgrade pip setuptools wheel\n.\\.venv\\Scripts\\python -m pip install -e \".[dev]\"\n</code></pre>"},{"location":"get_started_zero_github/#2-fetch-the-civic-inputs-markham-toronto","title":"2) Fetch the civic inputs (Markham + Toronto)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"get_started_zero_github/#3-run-the-demo-cases","title":"3) Run the demo cases","text":"<p>Markham:</p> <pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre> <p>Traffic Phase:</p> <pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre> <p>Traffic Anomaly (diagnostic):</p> <pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"get_started_zero_github/#4-preview-the-docs-locally-optional","title":"4) Preview the docs locally (optional)","text":"<p>Always run MkDocs through the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"get_started_zero_github/#important-windows-note-slashes","title":"Important Windows note: slashes","text":"<ul> <li>Use forward slashes for file paths in docs and commands: <code>scripts/fetch_data.py</code>, <code>cases/...</code>, <code>out/...</code></li> <li>Use backslashes only for the venv executables: <code>.\\.venv\\Scripts\\python</code>, <code>.\\.venv\\Scripts\\huf</code></li> </ul>"},{"location":"github_for_beginners/","title":"GitHub for HUF (Beginner, GUI-first)","text":"<p>This is a plain-language guide to using HUF on GitHub with minimal jargon. You do not need to learn command-line git to run HUF.</p>"},{"location":"github_for_beginners/#what-is-github","title":"What is GitHub?","text":"<p>GitHub is a website that stores a project folder online and keeps a history of every change.</p> <p>For HUF, GitHub is where:</p> <ul> <li>the code lives (the library + CLI)</li> <li>the docs live (Handbook + Reference Manual)</li> <li>fixes and improvements can be shared safely</li> </ul>"},{"location":"github_for_beginners/#the-easiest-way-github-desktop-point-and-click","title":"The easiest way: GitHub Desktop (point-and-click)","text":""},{"location":"github_for_beginners/#1-create-a-github-account-optional-but-recommended","title":"1) Create a GitHub account (optional but recommended)","text":"<ul> <li>Go to GitHub and create an account.</li> <li>You can still download HUF without an account, but GitHub Desktop works best when signed in.</li> </ul>"},{"location":"github_for_beginners/#2-install-github-desktop","title":"2) Install GitHub Desktop","text":"<ul> <li>Download and install GitHub Desktop.</li> </ul>"},{"location":"github_for_beginners/#3-get-huf-onto-your-computer-clone","title":"3) Get HUF onto your computer (\u201cClone\u201d)","text":"<ol> <li>Open GitHub Desktop</li> <li>File \u2192 Clone repository\u2026</li> <li>Paste the HUF repository URL</li> <li>Choose a local folder (example: <code>Documents/HUF</code>)</li> <li>Click Clone</li> </ol> <p>Now HUF is a normal folder on your computer.</p>"},{"location":"github_for_beginners/#how-to-run-huf-after-cloning","title":"How to run HUF after cloning","text":"<p>From the HUF folder:</p> <ul> <li>Windows: double-click <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: right-click <code>START_HERE_MAC.command</code> \u2192 Open</li> <li>Linux: run <code>./start_here_linux.sh</code></li> </ul> <p>Then fetch data (Windows PowerShell copy/paste):</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>Run a demo:</p> <pre><code>.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"github_for_beginners/#how-to-get-updates-no-command-line","title":"How to get updates (no command line)","text":"<p>In GitHub Desktop:</p> <ol> <li>Open the HUF repository</li> <li>Click Fetch origin</li> <li>If updates are available, click Pull origin</li> </ol> <p>That\u2019s it \u2014 your local folder updates.</p>"},{"location":"github_for_beginners/#do-i-need-branches-and-pull-requests","title":"Do I need branches and pull requests?","text":"<p>Not to run HUF. Branches and pull requests matter when you want to propose changes or safely test edits.</p> <ul> <li>Branch = a safe copy of the project to experiment in</li> <li>Pull Request = a polite way to ask: \u201cCan we add my changes?\u201d</li> </ul>"},{"location":"gui_quickstart/","title":"GUI Quickstart (non\u2011GitHub\u2011native users)","text":"<p>This page is for people who prefer GUI workflows (e.g., GitHub Desktop, file explorers, Word/Excel) but still want to run HUF and keep record copies.</p>"},{"location":"gui_quickstart/#note","title":"Note","text":"<p>This docs-only package does not include the code/CLI. To run HUF, download the GitHub package release as well.</p>"},{"location":"gui_quickstart/#what-you-can-do-without-git","title":"What you can do without Git","text":"<p>If you don\u2019t want Git at all:</p> <ol> <li>Download the latest release ZIP from GitHub (look for Releases on the right side of the repo page).</li> <li>Unzip it to a folder like <code>Documents/HUF/</code>.</li> <li>Open the Markdown record copies in <code>docs/</code>:</li> <li><code>docs/handbook.md</code></li> <li><code>docs/reference_manual.md</code></li> <li><code>docs/data_sources.md</code></li> </ol> <p>You can still run the CLI from this unzipped folder (see below).</p>"},{"location":"gui_quickstart/#using-github-desktop-recommended-for-updates","title":"Using GitHub Desktop (recommended for updates)","text":"<p>If you want one-click updates:</p> <ol> <li>Install GitHub Desktop.</li> <li>In GitHub Desktop: File \u2192 Clone repository\u2026</li> <li>Pick a local folder (e.g., <code>Documents/GitHub/huf-core</code>).</li> <li>To update later: press Fetch origin then Pull origin.</li> </ol>"},{"location":"gui_quickstart/#one-time-setup-to-run-huf","title":"One-time setup to run HUF","text":"<p>You need Python 3.10+ installed.</p>"},{"location":"gui_quickstart/#step-1-open-a-terminal-in-the-repo-folder","title":"Step 1 \u2014 Open a terminal in the repo folder","text":"<ul> <li>Windows: open File Explorer \u2192 go to the repo folder \u2192 right\u2011click \u2192 Open in Terminal (or PowerShell).</li> <li>macOS: Finder \u2192 repo folder \u2192 right\u2011click \u2192 New Terminal at Folder (or open Terminal and <code>cd</code>).</li> <li>Linux: open Terminal and <code>cd</code> into the folder.</li> </ul>"},{"location":"gui_quickstart/#step-2-run-the-bootstrap-crossplatform","title":"Step 2 \u2014 Run the bootstrap (cross\u2011platform)","text":"<p>From the repo root:</p> <pre><code>python scripts/bootstrap.py\n</code></pre> <p>This creates <code>.venv/</code> and installs everything you need.</p> <p>If you\u2019re on macOS/Linux you can also use: <code>make bootstrap</code></p>"},{"location":"gui_quickstart/#download-the-real-input-data-no-big-inputs-are-bundled","title":"Download the real input data (no big inputs are bundled)","text":""},{"location":"gui_quickstart/#markham-toronto-automatic","title":"Markham + Toronto (automatic)","text":"<p>After bootstrap, run one of these:</p> <pre><code>make fetch-data\n# or:\npython scripts/fetch_data.py --markham --toronto\n</code></pre>"},{"location":"gui_quickstart/#toronto-non-interactive-yes","title":"Toronto non-interactive (<code>--yes</code>)","text":"<p>For scripted demos (no prompts):</p> <pre><code>make fetch-toronto-yes\n# or:\npython scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"gui_quickstart/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<p>Planck files are large, so HUF prints the steps instead of downloading by default:</p> <pre><code>make planck-guide\n# or:\npython scripts/fetch_data.py --planck-guide\n</code></pre>"},{"location":"gui_quickstart/#run-the-demos","title":"Run the demos","text":""},{"location":"gui_quickstart/#markham","title":"Markham","text":"<pre><code>huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018 --tau-global 0.005 --tau-local 0.02\n</code></pre>"},{"location":"gui_quickstart/#toronto-traffic","title":"Toronto traffic","text":"<pre><code>huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase --tau-local 0.05\n</code></pre>"},{"location":"gui_quickstart/#where-outputs-go","title":"Where outputs go","text":"<p>Each run writes a folder like <code>out/markham2018/</code> or <code>out/traffic_phase/</code> containing the mandatory artifacts:</p> <ul> <li><code>artifact_1_coherence_map.csv</code></li> <li><code>artifact_2_active_set.csv</code></li> <li><code>artifact_3_trace_report.jsonl</code></li> <li><code>artifact_4_error_budget.json</code></li> </ul> <p>You can open the CSVs in Excel and keep them with your meeting notes.</p>"},{"location":"handbook/","title":"Higgins Unity Framework (HUF) Handbook","text":"<p>Edition: v1.1.8 (docs refresh) Updated: 2026-02-17  </p> <p>This handbook is the conceptual and contractual description of HUF: what the Unity-Budgeted Hierarchy (UBH) is, how HUF emits auditable artifacts, and how to interpret stability sweeps.</p> <p>Real-data demos included in this repo: - Markham (2018 budget) \u2014 real Excel input fetched from the City of Markham open data site. - Toronto (traffic signals timing) \u2014 real CSV derived from the City of Toronto open data \u201cTraffic signals timing\u201d ZIP. - Planck (70 GHz all-sky map) \u2014 real FITS map not shipped in the repo (too large). You fetch it from PLA or IRSA (guided in <code>scripts/fetch_data.py --planck-guide</code>).</p> <p>Synthetic data: only small \u201ctoy\u201d examples (used for quick sanity checks) are synthetic. The headline demos above are real data.</p>"},{"location":"handbook/#origins-why-this-exists","title":"Origins (why this exists)","text":"<p>HUF grew out of a very practical question: how to solve diffraction and dispersion problems in loudspeakers well enough that the \u201cwhy\u201d became impossible to ignore. The working path was:</p> <ol> <li>solve the physical problem (dispersion / diffraction) empirically</li> <li>notice an \u201cenergy budget\u201d invariant when moving from 2\u03c0 to 4\u03c0 radiation equalization</li> <li>formalize the invariant as an isotropic budget / unity constraint</li> <li>generalize it into a contract for hierarchies \u2192 the Unity\u2011Budgeted Hierarchy (UBH)</li> <li>treat every run as a reproducible artifact emitter \u2192 HUF</li> </ol> <p>That\u2019s the reason the framework is written like a lab protocol: it is designed to let people verify \u201cis this real?\u201d before debating \u201cis this beautiful?\u201d.</p> <p>Higgins Unity Framework (HUF) Handbook</p> <p>A contract-first method for unity\u2011budgeted hierarchies, auditable reduction, and stable anomaly localization</p> <p>Handbook Edition \u2022 Version 1.0 February 2026</p> <p>Peter Higgins</p>"},{"location":"handbook/#front-matter","title":"Front matter","text":"<p>This handbook replaces the earlier \u2018meeting spec\u2019 lineage. It is written to be implementable, teachable, and hard to misread. The tone is intentionally contract\u2011driven: if you cannot verify finite elements, conserve a declared unity budget, emit the required artifacts, and pass stability checks, then you are not doing HUF \u2014 you are doing storytelling.</p> <p>The handbook contains two comprehensive, real-data case studies (Planck 70\u202fGHz and City of Markham public data) and a third operational case study (traffic signal telemetry) as an anomaly\u2011localization template.</p>"},{"location":"handbook/#how-to-use-this-handbook","title":"How to use this handbook","text":"<ul> <li> <p>If you need the method: read Part I and implement the contract (required artifacts + stability packet).</p> </li> <li> <p>If you need proof: read Part II and reproduce the reference runs (Planck and Markham).</p> </li> <li> <p>If you need to teach or deploy: read Part III (implementation patterns, templates, and training exercises).</p> </li> </ul>"},{"location":"handbook/#table-of-contents","title":"Table of contents","text":"<p>In Word: Right\u2011click the TOC \u2192 Update Field \u2192 Update entire table.</p>"},{"location":"handbook/#part-i-huf-core-normative","title":"Part I \u2014 HUF Core (Normative)","text":""},{"location":"handbook/#1-definition-in-one-page-the-core-stripped","title":"1. Definition in one page (the core, stripped)","text":"<p>HUF defines a system as a unity\u2011budgeted hierarchy with auditable finite elements.</p> <ol> <li> <p>Finite elements: verifiable units that contribute to a conserved budget.</p> </li> <li> <p>Regimes: named groupings of finite elements (nestable) used for interpretability.</p> </li> <li> <p>Unity budget: a declared conserved quantity (mass/weight or energy/power) with total sum exactly 1.0.</p> </li> <li> <p>Locked cycle: Normalize \u2192 Propagate \u2192 Aggregate \u2192 Exclude \u2192 Renormalize.</p> </li> <li> <p>Contract: a run is invalid unless it emits the required artifacts and passes declared stability checks.</p> </li> </ol>"},{"location":"handbook/#2-motivation-the-shortest-honest-version","title":"2. Motivation (the shortest honest version)","text":"<p>Every serious system ends up doing some form of reduction: compressing models, pruning portfolios, prioritizing interventions, or summarizing telemetry. The failure mode is consistent: reduction happens, but the justification is ad hoc. HUF exists to make reduction auditable.</p> <p>HUF does not promise \u2018truth.\u2019 It promises four things you can test: (1) unity conservation, (2) explicit retained set, (3) explicit discarded budget, and (4) backward trace to finite elements. That\u2019s the entire game.</p>"},{"location":"handbook/#3-primitives-and-invariants","title":"3. Primitives and invariants","text":"<p>3.1 Finite element</p> <p>A finite element is the smallest unit you agree to audit. It must have: a unique identifier, a repeatable method of computing its contribution, and stored provenance.</p> <p>Minimum finite-element record:</p> <ul> <li> <p>id: stable string key (do not recycle IDs across runs)</p> </li> <li> <p>inputs: pointers to measured data, logs, or upstream artifacts</p> </li> <li> <p>contribution: a non-negative scalar (or paired positive/negative extension) used by the unity budget</p> </li> <li> <p>provenance: hash or stamp sufficient to reproduce the number</p> </li> </ul> <p>3.2 Regime</p> <p>A regime is a partition (or nested partition) used to contextualize budget. A regime answers: \u2018where did the budget go?\u2019 Regimes must not double-count contributions. If an element belongs to multiple regimes, you must explicitly split its budget.</p> <p>3.3 Unity budget</p> <p>Unity is the only invariant HUF treats as sacred: after normalization, the sum of contributions equals 1.0 globally. Local unity (within a regime) may be enforced for a local view, but the global unity must always be satisfied.</p>"},{"location":"handbook/#4-budget-semantics-choose-once-dont-cheat","title":"4. Budget semantics (choose once; don\u2019t cheat)","text":"<p>HUF is ruthless about budget semantics. Declare one of the following and never mix them mid-run:</p> <ul> <li> <p>Mass/weight budget: \u03c1\u1d62 \u2265 0 and \u03a3\u03c1\u1d62 = 1. Examples: expenditure shares, portfolio weights, probability mass.</p> </li> <li> <p>Energy/power budget: \u03c1\u1d62 = e\u1d62 / \u03a3e with e\u1d62 = |x\u1d62|\u00b2 or another Parseval-consistent energy under a declared orthogonal basis.</p> </li> </ul> <p>If your domain has cancellation (signed contributions), do not fake it by allowing negative \u03c1. Use a paired-budget extension (track positive and negative magnitudes separately) or an explicitly signed framework with stability proofs.</p>"},{"location":"handbook/#5-the-locked-cycle-and-what-each-step-is-allowed-to-do","title":"5. The locked cycle and what each step is allowed to do","text":"<p>Figure 1. The locked HUF cycle. You may extend steps, but you may not reorder them without breaking audit expectations.</p> <p>Normalize</p> <p>Normalize converts raw contributions into a unity budget. For mass budgets: \u03c1\u1d62 = w\u1d62 / \u03a3w. For energy budgets: \u03c1\u1d62 = |x\u1d62|\u00b2 / \u03a3|x|\u00b2. Normalization must be deterministic and logged.</p> <p>Propagate</p> <p>Propagation moves budget between representations (e.g., from fine pixels to coarse blocks, from categories to wards, from events to root causes). Propagation is admissible only if it is conservative and traceable.</p> <ul> <li> <p>Conservation check: |\u03a3\u03c1_out \u2212 \u03a3\u03c1_in| \u2264 \u03b5 (declare \u03b5).</p> </li> <li> <p>Traceability check: every output element stores a map back to input elements with weights.</p> </li> <li> <p>No hidden state: propagation must be a pure function of inputs + declared parameters (seeded if stochastic).</p> </li> </ul> <p>Aggregate</p> <p>Aggregation merges elements to reduce complexity while preserving the budget. Examples: cluster similar items, sum within a regime, downsample by known hierarchical structure.</p> <p>Exclude</p> <p>Exclusion removes elements below a threshold \u03c4 or keeps the smallest set reaching a retained budget target. Exclusion must emit a discard ledger (what was removed and how much budget it carried).</p> <p>Renormalize and validate</p> <p>Renormalize after exclusion (and after any operation that may introduce floating-point drift). Then validate the contract: unity checks, trace completeness, artifact emission, and stability packet results.</p>"},{"location":"handbook/#6-the-contract-required-artifacts","title":"6. The contract (required artifacts)","text":"<p>Contract: a HUF run is invalid unless it emits all artifacts</p>"},{"location":"handbook/#7-artifact-schemas-minimum-workable-forms","title":"7. Artifact schemas (minimum workable forms)","text":"<p>HUF does not mandate file formats, but it does mandate fields. Minimal schemas:</p> <p>Schema A \u2014 Active set</p> <p>Schema B \u2014 Backward trace (per retained element)</p> <p>Schema C \u2014 Error/Budget report</p>"},{"location":"handbook/#8-stability-packet-required-anti-brittleness-tests","title":"8. Stability packet (required anti-brittleness tests)","text":"<p>Minimum stability packet</p>"},{"location":"handbook/#9-deployment-hazards-the-things-critics-correctly-attack","title":"9. Deployment hazards (the things critics correctly attack)","text":"<ul> <li> <p>Semantics drift: changing what unity means mid-run (e.g., mixing weight and energy).</p> </li> <li> <p>Black-box propagation: learned or heuristic mapping with no trace and no conservation validation.</p> </li> <li> <p>Double counting: elements belonging to overlapping regimes without explicit splitting.</p> </li> <li> <p>Unstable thresholds: large near-\u03c4 mass and low overlap across sweeps.</p> </li> <li> <p>Overfitting the narrative: tuning \u03c4 until your preferred story appears.</p> </li> </ul> <p>HUF\u2019s job is to make these failures visible. If your run fails, that is not \u2018HUF failing\u2019; that is the system refusing to be compressed honestly.</p>"},{"location":"handbook/#part-ii-comprehensive-reference-runs-real-data","title":"Part II \u2014 Comprehensive Reference Runs (Real Data)","text":""},{"location":"handbook/#10-case-study-a-planck-lfi-70-ghz-healpix-nside1024","title":"10. Case Study A \u2014 Planck LFI 70\u202fGHz (HEALPix, nside=1024)","text":"<p>This case demonstrates energy\u2011budget HUF on a large scientific dataset. Input file: LFI_SkyMap_070_1024_R3.00_full.fits. We use the Stokes I column (I_STOKES). The finite elements are pixels; the energy contribution is I\u00b2.</p>"},{"location":"handbook/#101-data-model","title":"10.1 Data model","text":"<ul> <li> <p>Raw finite elements: nside=1024 pixels (12\u00d71024\u00b2 = 12,582,912 elements).</p> </li> <li> <p>Aggregation: NESTED parent blocks at nside=64 (12\u00d764\u00b2 = 49,152 coarse elements), each covering 256 child pixels.</p> </li> <li> <p>Regimes: 12 HEALPix base faces (each face = 4,096 coarse blocks).</p> </li> <li> <p>Budget: energy share \u03c1\u1d62 = e\u1d62 / \u03a3e, with e\u1d62 = \u03a3child I\u00b2 (for coarse blocks).</p> </li> </ul>"},{"location":"handbook/#102-run-configuration","title":"10.2 Run configuration","text":"<p>Aggregation: nside 1024 \u2192 64 (ratio 16; 256 children per parent).</p> <p>Retain target: 0.97 of total energy.</p> <p>Outcome: K = 18,198 retained coarse blocks out of 49,152. Threshold \u03c4 = 1.66e-06.</p> <p>Energy retained = 0.9700; discarded = 0.0300.</p> <p>Pixel\u2011basis RMSE under keep\u2011or\u2011zero reconstruction = 7.6942e-05 (same units as I_STOKES).</p>"},{"location":"handbook/#103-coherence-map","title":"10.3 Coherence map","text":"<p>Figure 2. Planck 70\u202fGHz \u2014 global retained vs discarded energy share.</p> <p>Figure 3. Planck 70\u202fGHz \u2014 per\u2011face unity bars (faces as regimes).</p> <p>Figure 4. Planck 70\u202fGHz \u2014 active\u2011set growth curve (sorted by \u03c1).</p> <p>Table 10\u2011A. Per\u2011face energy shares (global \u03c1)</p> <p>Table 10\u2011B. Top retained coarse blocks (traceable sample)</p>"},{"location":"handbook/#104-traceability-how-to-audit-a-retained-block","title":"10.4 Traceability (how to audit a retained block)","text":"<p>Because the map uses HEALPix NESTED ordering, each nside=64 parent block corresponds to a contiguous range of 256 nside=1024 child pixels. For a retained parent with index p, the child range is [256p, 256p+255]. This makes backward traces compact and exact.</p> <p>Example: a compact backward trace for an aggregated HEALPix block</p>"},{"location":"handbook/#105-stability-packet-retaintarget-sweep","title":"10.5 Stability packet (retain\u2011target sweep)","text":"<p>Table 10\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 10\u2011D. Active\u2011set overlap (Jaccard) between sweep points</p> <p>Table 10\u2011E. Regime ranking stability (faces) across sweep points</p>"},{"location":"handbook/#106-what-this-run-teaches-and-what-it-does-not","title":"10.6 What this run teaches (and what it does not)","text":"<ul> <li> <p>HUF can reduce 49,152 coarse blocks to ~18k while retaining 97% pixel-basis energy, with exact accounting.</p> </li> <li> <p>Per-regime views (faces) remain stable across threshold sweeps: the \u2018where\u2019 of energy is robust.</p> </li> <li> <p>The discard fraction is a quantitative error bound under the declared reconstruction.</p> </li> <li> <p>This is not cosmological inference. HUF is an auditable reduction layer; domain science still happens above it.</p> </li> </ul>"},{"location":"handbook/#11-case-study-b-city-of-markham-2018-budget-civic-layers","title":"11. Case Study B \u2014 City of Markham (2018 budget + civic layers)","text":"<p>This case demonstrates mass/weight HUF on municipal public data. The conserved quantity is money. Primary budget workbook: 2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx (values in $000). We focus on expenditures (the allocation of outgoing funds), then show a propagation example onto wards using census population as a proxy.</p>"},{"location":"handbook/#111-data-inventory-what-we-used","title":"11.1 Data inventory (what we used)","text":"<ul> <li> <p>2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx \u2014 fund-level revenues/expenditures by category.</p> </li> <li> <p>2018-Operating-Budget-by-Account.xlsx \u2014 operating revenue/expense categories and year comparisons.</p> </li> <li> <p>2016-Tax-Rates.xlsx and 2018-Tax-Rates.xlsx \u2014 rate context (not used as budget, used for narrative checks).</p> </li> <li> <p>GIS layers: WARD.geojson, Parks.geojson, Fire_Stations.geojson, City_Facilities.geojson (used for a propagation demo).</p> </li> <li> <p>Census DA layer (Age/Sex) for Markham \u2014 used only to compute ward population shares (proxy).</p> </li> </ul>"},{"location":"handbook/#112-budget-declaration-and-finite-elements","title":"11.2 Budget declaration and finite elements","text":"<p>Global budget: total 2018 expenditures across all funds = 456,171 ($000). Unity budget is \u2018share of total expenditures\u2019.</p> <p>Finite element for the primary run: (Fund \u00d7 ExpenditureCategory). Regimes: Funds. This gives a clean \u2018where does the city spend money\u2019 decomposition.</p>"},{"location":"handbook/#113-primary-run-results-fundcategory","title":"11.3 Primary run results (Fund\u00d7Category)","text":"<p>Retain target: 0.97. Outcome: K = 23 retained elements out of 67. Threshold \u03c4 = 0.004. Retained = 0.9710; discarded = 0.0290.</p> <p>Figure 5. Markham 2018 expenditures \u2014 global retained vs discarded budget share.</p> <p>Figure 6. Markham 2018 expenditures \u2014 per-fund unity bars (funds as regimes).</p> <p>Figure 7. Markham 2018 expenditures \u2014 active-set growth curve (Fund\u00d7Category).</p> <p>Table 11\u2011A. Fund regimes: totals and global shares</p> <p>Table 11\u2011B. Largest spending contributors (Fund\u00d7Category)</p>"},{"location":"handbook/#114-stability-packet","title":"11.4 Stability packet","text":"<p>Table 11\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 11\u2011D. Active-set overlap (Jaccard) across sweep points</p>"},{"location":"handbook/#115-backward-trace-example-auditing-a-spending-line","title":"11.5 Backward trace example (auditing a spending line)","text":"<p>In this run, the backward trace is trivial but non\u2011negotiable: each retained element points back to a specific worksheet row/column (Fund, Category, cell location) plus workbook hash. If you can\u2019t point to the cell, you can\u2019t claim the number.</p> <p>Example: backward trace record for a budget line</p>"},{"location":"handbook/#116-propagation-demo-operating-fund-to-wards-proxy-allocation","title":"11.6 Propagation demo \u2014 Operating Fund to wards (proxy allocation)","text":"<p>This section demonstrates propagation constraints on civic geography. We do NOT claim this is the real ward budget \u2014 the city budget is not ward\u2011allocated in this dataset. We demonstrate a conservative, auditable proxy mapping.</p> <p>Propagation map: allocate Operating Fund expenditures to wards proportional to 2016 census population share. This is admissible as a mapping only if it is declared as a proxy, conservative (sums match), and traceable.</p> <p>Figure 8. Markham wards \u2014 population shares (proxy weights for propagation).</p> <p>Figure 9. Operating Fund propagated to wards \u2014 per-regime unity bars (retained vs discarded at target 0.97).</p> <p>Table 11\u2011E. Ward proxy table: population, facilities counts, and Operating Fund allocation ($M)</p> <p>Why include facilities counts? Not as causal claims \u2014 as audit context. They provide additional regimes for future propagation (e.g., allocate a parks-maintenance budget proportional to park count or area). Any such mapping must be declared and tested for stability.</p>"},{"location":"handbook/#117-what-dominates-and-what-to-do-next","title":"11.7 What dominates and what to do next","text":"<p>The Fund\u00d7Category decomposition typically reveals (a) how concentrated spending is, (b) whether one fund dominates the budget narrative, and (c) which categories are \u2018structural\u2019 versus \u2018tail.\u2019 This run is a starting point.</p> <ul> <li> <p>Next expansion: link operating categories to performance measures (if definitions match).</p> </li> <li> <p>Next expansion: add revenues as a parallel budget and compare structural mismatch (revenue concentration vs expenditure concentration).</p> </li> <li> <p>Next expansion: incorporate capital project lists and apply HUF to project portfolios (true finite elements with trace to project IDs).</p> </li> </ul>"},{"location":"handbook/#12-case-study-c-traffic-signal-telemetry-anomaly-localization-template","title":"12. Case Study C \u2014 Traffic signal telemetry (anomaly localization template)","text":"<p>This case shows how HUF behaves on operational event streams. The goal is not \u2018compress for beauty\u2019 \u2014 it is: what dominates anomalies, and where should you look first?</p>"},{"location":"handbook/#121-finite-element-and-budget-definition-recommended","title":"12.1 Finite element and budget definition (recommended)","text":"<p>Recommended finite element for anomaly work: Finite element = TCS \u00d7 PHASE \u00d7 PHASE_STATUS_TEXT (optionally \u00d7 PHASE_CALL_TEXT) Budget = event share or severity\u2011weighted share (declare weights) Output = which intersections/phases dominate drops/terminations/clearance with full trace to raw rows.</p> <p>In this run we define a simple severity budget: Dropped calls weight 3, Termination statuses weight 2, everything else weight 1, then restrict the anomaly view to rows with severity &gt; 1.</p>"},{"location":"handbook/#122-compressed-phase-activity-distribution-what-dominates-anomalies","title":"12.2 Compressed phase activity distribution (what dominates anomalies)","text":"<p>Figure 10. Traffic telemetry \u2014 anomaly severity budget by intersection (top contributors).</p> <p>Figure 11. Traffic telemetry \u2014 anomaly severity budget by phase.</p> <p>Figure 12. Traffic telemetry \u2014 anomaly severity budget by status.</p> <p>Table 12\u2011A. Top intersections by anomaly severity budget share</p> <p>Table 12\u2011B. Phases dominating the anomaly budget</p> <p>Table 12\u2011C. Status distribution within anomaly budget</p>"},{"location":"handbook/#123-traceability-and-actionability","title":"12.3 Traceability and actionability","text":"<p>A practical HUF anomaly run ends with a short, actionable list: top intersections, top phases, and the raw event rows supporting them. Backward traces should include timestamp ranges and source row IDs so an engineer can replay the evidence.</p> <ul> <li> <p>If one intersection dominates: inspect controller configuration and detector health first.</p> </li> <li> <p>If one phase dominates across many intersections: inspect phase timing policy or coordination logic.</p> </li> <li> <p>If one status dominates: inspect the semantic definition (what exactly triggers \u2018Termination\u2019 in your system).</p> </li> </ul>"},{"location":"handbook/#part-iii-implementation-extension-and-training","title":"Part III \u2014 Implementation, extension, and training","text":""},{"location":"handbook/#13-reference-implementation-patterns","title":"13. Reference implementation patterns","text":"<p>A handbook is useless if it can\u2019t be implemented. This section defines the minimal architecture that prevents HUF from collapsing back into prose.</p> <ul> <li> <p>Core data model: Element(id, rho, regime_path, trace).</p> </li> <li> <p>Adapters: domain-specific loaders and propagators that output the same element schema.</p> </li> <li> <p>I/O: artifact writers (CSV/JSON) that always include run stamps and file hashes.</p> </li> <li> <p>Tests: each reference run must have an automated test that checks unity, artifact emission, and stability packet generation.</p> </li> </ul> <p>Listing 13\u2011A. Reference core (excerpt, huf_core/core.py)</p> <p>(Full source is intended for the accompanying repository/package; this excerpt is included for handbook completeness.)</p>"},{"location":"handbook/#14-how-huf-prunes-itself-expansion-contraction-as-a-method","title":"14. How HUF prunes itself (expansion \u2192 contraction as a method)","text":"<p>The development history that produced this handbook is not a shameful detour \u2014 it is the method. You expand to explore, then you contract to ship. HUF applies to itself:</p> <ol> <li> <p>Expansion phase: explore candidate operations, artifacts, and narratives to discover what actually matters in practice.</p> </li> <li> <p>Contraction phase: declare the contract, delete optionality from the core, and move everything else into extensions.</p> </li> <li> <p>Stability phase: treat the framework definition as a system under HUF \u2014 track which sections survive pruning across reviewer critiques.</p> </li> </ol> <p>A useful internal exercise: assign a unity budget to sections of your draft (by reader time, by risk, or by implementation cost), then run HUF to see which sections dominate confusion or contribute little. That is \u2018HUF on HUF.\u2019</p>"},{"location":"handbook/#15-training-exercises-from-toy-to-real","title":"15. Training exercises (from toy to real)","text":"<p>Exercises are designed to build the habit of declaring budgets, regimes, and traces before you compute.</p> <ol> <li> <p>Take any spreadsheet with line items. Define finite elements and a mass budget. Produce the four artifacts.</p> </li> <li> <p>Repeat with two regime partitions (by department vs by fund). Compare regime stability across thresholds.</p> </li> <li> <p>Take an event log. Define anomaly budget weights. Produce a top\u2011N actionable list with backward traces to row IDs.</p> </li> <li> <p>Design a propagation map (e.g., cost \u2192 ward) and prove conservation + traceability in one paragraph.</p> </li> <li> <p>Perform a stability sweep and write the two-sentence interpretation of the stability packet.</p> </li> </ol>"},{"location":"handbook/#appendix-a-data-samples-print-friendly-excerpts","title":"Appendix A \u2014 Data samples (print-friendly excerpts)","text":"<p>A1. Planck sample (first 5 coarse blocks; energies are in I\u00b2 units)</p> <p>A2. Markham sample (top 10 Fund\u00d7Category elements)</p> <p>A3. Traffic sample (first 12 telemetry rows; severity weights shown)</p>"},{"location":"handbook/#appendix-b-artifact-checklists-what-a-reviewer-will-ask-for","title":"Appendix B \u2014 Artifact checklists (what a reviewer will ask for)","text":"<ul> <li> <p>Unity checks: global \u03a3\u03c1=1.0 after every normalization and renormalization step (log the tolerance).</p> </li> <li> <p>Discard ledger: list of excluded elements with their \u03c1; discarded sum must match 1\u2212retained.</p> </li> <li> <p>Trace completeness: every retained element has a backward trace to finite elements (no null traces).</p> </li> <li> <p>Stability packet: sweep points, overlap metrics, regime rank stability, near\u2011\u03c4 band.</p> </li> <li> <p>Repro stamp: file hashes, code version, run_id, parameters (\u03c4/target, seeds).</p> </li> </ul>"},{"location":"handbook/#appendix-c-glossary-minimal","title":"Appendix C \u2014 Glossary (minimal)","text":"<p>Glossary</p>"},{"location":"handbook/#appendix-d-reproducibility-stamps-recommended-minimum","title":"Appendix D \u2014 Reproducibility stamps (recommended minimum)","text":"<p>Run stamp</p>"},{"location":"jupyter_demos/","title":"Jupyter demos (optional)","text":"<p>Jupyter is optional. It\u2019s useful when you want to read and summarize artifacts interactively.</p>"},{"location":"jupyter_demos/#install-launch-windows-powershell","title":"Install + launch (Windows PowerShell)","text":"<pre><code>.\\.venv\\Scripts\\python -m pip install notebook pandas\n.\\.venv\\Scripts\\python -m notebook\n</code></pre> <p>A browser window opens. Create a new notebook (Python).</p>"},{"location":"jupyter_demos/#important-powershell-is-not-python","title":"Important: PowerShell is not Python","text":"<p>If you type <code>import pandas as pd</code> at a PowerShell prompt, it will fail.</p> <p>Run Python code: - in a notebook cell, or - inside <code>python</code> interactive (<code>.\\.venv\\Scripts\\python</code>), or - from a script file.</p>"},{"location":"jupyter_demos/#suggested-notebook-pattern","title":"Suggested notebook pattern","text":""},{"location":"jupyter_demos/#cell-1-run-a-case-cli","title":"Cell 1 \u2014 run a case (CLI)","text":"<pre><code>import subprocess, sys\nsubprocess.check_call([sys.executable, \"-m\", \"huf_core.cli\", \"--help\"])\n</code></pre> <p>(Or just run the case in PowerShell first, then open artifacts in the next cells.)</p>"},{"location":"jupyter_demos/#cell-2-open-artifacts-markham","title":"Cell 2 \u2014 open artifacts (Markham)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/markham2018/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/markham2018/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(10)\n</code></pre>"},{"location":"jupyter_demos/#cell-3-how-many-items-cover-90","title":"Cell 3 \u2014 \u201chow many items cover 90%?\u201d","text":"<pre><code>active[\"cum\"] = active[\"rho_global_post\"].cumsum()\nactive.loc[active[\"cum\"] &gt;= 0.90, [\"rank\",\"item_id\",\"cum\"]].head(1)\n</code></pre>"},{"location":"jupyter_demos/#cell-4-open-artifacts-traffic-phase","title":"Cell 4 \u2014 open artifacts (Traffic Phase)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/traffic_phase/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/traffic_phase/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(15)\n</code></pre>"},{"location":"jupyter_demos/#export","title":"Export","text":"<p>You can export notebooks to HTML/PDF from the Jupyter UI (File \u2192 Download).</p>"},{"location":"learning_path/","title":"Learning path","text":"<p>HUF is easiest to learn by running a case, then reading the artifacts it produces. This path is designed so the left sidebar is a \u201cdo-this-next\u201d guide.</p> <p>Windows / Conda rule</p> <p>After the repo venv exists, always run tools via the repo executables:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"learning_path/#step-1-install-first-run","title":"Step 1 \u2014 Install + first run","text":"<p>Choose one:</p> <ul> <li>Start here (developer): Start Here \u2192 Developer</li> <li>Start here (beginner): Start Here \u2192 Zero GitHub Knowledge</li> </ul> <p>Goal: you can run <code>.\\.venv\\Scripts\\huf --help</code> and you can produce an <code>out/.../run_stamp.json</code>.</p>"},{"location":"learning_path/#step-2-run-the-two-core-cases","title":"Step 2 \u2014 Run the \u201ctwo core\u201d cases","text":"<p>1) Markham (budget allocation) \u2192 then read: - Worked examples \u2192 Markham</p> <p>2) Traffic Phase (signal phases) \u2192 then read: - Worked examples \u2192 Traffic phase</p> <p>These two are the best introductions to how HUF turns a raw table into:</p> <ul> <li>a coherence map (regimes),</li> <li>an active set (retained items),</li> <li>and a trace report (auditable, line-by-line).</li> </ul>"},{"location":"learning_path/#step-3-try-an-adapter-style-use-case","title":"Step 3 \u2014 Try an adapter-style use case","text":"<ul> <li>Adapters \u2192 Vector DB coherence</li> </ul> <p>This shows how HUF can \u201cexplain\u201d retrieval results by grouping where the score mass comes from (namespaces, sources, etc.) and what gets excluded by <code>tau_global</code>.</p>"},{"location":"learning_path/#step-4-optional-big-data-scientific-demo","title":"Step 4 \u2014 Optional: big-data / scientific demo","text":"<ul> <li>Planck LFI/HFI 70\u202fGHz (optional): see Start Here \u2192 Developer (Planck section)</li> </ul>"},{"location":"learning_path/#step-5-optional-notebooks","title":"Step 5 \u2014 Optional: notebooks","text":"<ul> <li>Jupyter demos (optional)</li> </ul> <p>If you want plots + interactive exploration, notebooks are a nice fit.</p>"},{"location":"markham_worked_example/","title":"Markham worked example (2018 budget)","text":"<p>\u2190 Back to Cases</p> <p>This page walks through a full, reproducible analysis using the bundled workbook:</p> <ul> <li><code>cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></li> </ul> <p>Goal: show what HUF reveals that a normal \u201csum + chart\u201d spreadsheet workflow usually hides: concentration, tail mass, stable regime structure, and cell-level provenance.</p>"},{"location":"markham_worked_example/#1-run-it","title":"1) Run it","text":"<p>Windows PowerShell (from repo root):</p> <pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre> <p>You should see something like:</p> <ul> <li><code>active_set=24</code></li> <li><code>coherence_rows=6</code></li> <li><code>discarded_global\u22480.029</code></li> </ul>"},{"location":"markham_worked_example/#2-whats-in-the-input","title":"2) What\u2019s in the input","text":"<p>The adapter reads a simple fund \u00d7 account block from the workbook (units: k$):</p> <ul> <li>accounts: rows 18\u201338</li> <li>funds: columns 1\u20136</li> <li>blanks / zeros are dropped</li> </ul> <p>For the shipped workbook, HUF finds:</p> <ul> <li>67 non-zero cells (elements)</li> <li>total value in the selected block: 456,172 k$ (\u2248 $456.2M)</li> </ul>"},{"location":"markham_worked_example/#3-the-coherence-map-fund-level-regimes","title":"3) The coherence map (fund-level regimes)","text":"<p>Open:</p> <ul> <li><code>out/markham2018/artifact_1_coherence_map.csv</code></li> </ul> <p>This answers: which funds dominate the retained budget, and how much tail mass got dropped.</p> <p>Interpretation:</p> <ul> <li>\u201cShare of retained\u201d sums to 1.0 (unity budget after compression).</li> <li>\u201cDiscarded (k$)\u201d is what was below the global/local thresholds inside that fund.</li> <li>The Operating Fund typically carries the biggest within-fund tail (many tiny line items).</li> </ul>"},{"location":"markham_worked_example/#4-the-active-set-account-level-winners","title":"4) The active set (account-level winners)","text":"<p>Open:</p> <ul> <li><code>out/markham2018/artifact_2_active_set.csv</code></li> </ul> <p>This answers: which line-items explain most of the budget, globally and within each fund.</p> <p>Two quick \u201chidden\u201d facts this makes obvious:</p> <ul> <li>top 2 line-items cover a huge share of retained spend</li> <li>it takes surprisingly few line-items to cover 90% of the retained budget</li> </ul> <p>That\u2019s a concentration story you don\u2019t get from a typical workbook view unless you go hunting.</p>"},{"location":"markham_worked_example/#5-provenance-the-trace-report-the-why-chain","title":"5) Provenance: the trace report (the \u201cwhy\u201d chain)","text":"<p>Open:</p> <ul> <li><code>out/markham2018/artifact_3_trace_report.jsonl</code></li> </ul> <p>Each retained item includes the workbook pointer it came from (sheet + cell), so you can audit the pipeline end-to-end.</p>"},{"location":"markham_worked_example/#6-stability-how-sensitive-is-the-result","title":"6) Stability: how sensitive is the result?","text":"<p>Open:</p> <ul> <li><code>out/markham2018/stability_packet.csv</code></li> </ul> <p>Key fields:</p> <ul> <li><code>discarded_frac</code> \u2191 means more aggressive pruning</li> <li><code>jaccard_vs_base</code> close to 1.0 means \u201cmostly the same active set\u201d</li> <li><code>near_tau_count</code> high means lots of elements hover around the cutoff (more sensitivity)</li> </ul>"},{"location":"markham_worked_example/#7-explore-further-copypaste","title":"7) Explore further (copy/paste)","text":"<pre><code>.\\.venv\\Scripts\\python - &lt;&lt; 'PY'\nimport pandas as pd\n\ncoh = pd.read_csv(\"out/markham2018/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/markham2018/artifact_2_active_set.csv\").sort_values(\"rank\")\n\n# Which funds dominate?\nprint(coh[[\"regime_id\",\"rho_global_post\",\"rho_discarded_pre\"]].sort_values(\"rho_global_post\", ascending=False))\n\n# How many items cover 90%?\nactive[\"cum\"] = active[\"rho_global_post\"].cumsum()\nprint(active.loc[active[\"cum\"] &gt;= 0.90, [\"rank\",\"item_id\",\"cum\"]].head(1))\nPY\n</code></pre>"},{"location":"planck/","title":"Planck (LFI 70 GHz) demo","text":"<p>This case demonstrates HUF on a very large HEALPix all\u2011sky map (Planck PR3, LFI 70 GHz). The demo produces the standard HUF artifacts (coherence map, active set, trace report, error budget) so you can inspect what HUF retained vs. discarded at the chosen retained\u2011target.</p> <p>Why this is not auto-downloaded</p> <p>The Planck FITS file is large (~480\u2013500 MB) and some users prefer downloading from ESA\u2019s Planck Legacy Archive vs NASA/IPAC IRSA.</p>"},{"location":"planck/#1-get-the-fits-input","title":"1) Get the FITS input","text":"<p>Expected path in this repo:</p> <pre><code>cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\n</code></pre>"},{"location":"planck/#option-a-recommended-on-windows-bits-download","title":"Option A (recommended on Windows): BITS download","text":"<pre><code>$dest = Join-Path $PWD \"cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits\"\nNew-Item -ItemType Directory -Force (Split-Path $dest) | Out-Null\n$src  = \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\nStart-BitsTransfer -Source $src -Destination $dest\n</code></pre>"},{"location":"planck/#option-b-curlwget","title":"Option B: curl/wget","text":"<pre><code>curl -L -o \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\"   \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\n</code></pre> <p>Windows PowerShell curl alias</p> <p>In Windows PowerShell, <code>curl</code> is an alias for <code>Invoke-WebRequest</code>. Use <code>curl.exe</code> (or use BITS above):</p> <pre><code>curl.exe -L -o \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\"       \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\n</code></pre> <p>Preview page (manual download button):</p> <ul> <li>https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/previews/LFI_SkyMap_070_1024_R3.00_full/index.html</li> </ul>"},{"location":"planck/#2-install-planck-extras","title":"2) Install Planck extras","text":"<p>If you are using the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n</code></pre>"},{"location":"planck/#3-run-the-demo","title":"3) Run the demo","text":"<pre><code>.\\.venv\\Scripts\\huf planck `\n  --fits cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits `\n  --out out\\planck70 `\n  --retained-target 0.97 `\n  --nside-out 64\n</code></pre>"},{"location":"planck/#4-read-the-artifacts","title":"4) Read the artifacts","text":"<p>The output folder contains:</p> <ul> <li><code>artifact_1_coherence_map.csv</code> \u2014 regimes and their retained mass/energy (post\u2011filter)</li> <li><code>artifact_2_active_set.csv</code> \u2014 the retained items (ranked)</li> <li><code>artifact_3_trace_report.jsonl</code> \u2014 what changed across the pass (debug/audit)</li> <li><code>artifact_4_error_budget.json</code> \u2014 global + local discard summary</li> <li><code>run_stamp.json</code>, <code>meta.json</code></li> </ul>"},{"location":"planck/#quick-inspection-no-notebooks-required","title":"Quick inspection (no notebooks required)","text":"<pre><code>.\\.venv\\Scripts\\python - &lt;&lt;'PY'\nimport pandas as pd\ncoh = pd.read_csv('out/planck70/artifact_1_coherence_map.csv')\nact = pd.read_csv('out/planck70/artifact_2_active_set.csv').sort_values('rank')\nprint('\nTop regimes by rho_global_post:')\nprint(coh.sort_values('rho_global_post', ascending=False).head(10).to_string(index=False))\nprint('\nTop 10 retained items:')\nprint(act[['rank','regime_id','item_id','value','rho_global_post','rho_local_post']].head(10).to_string(index=False))\nPY\n</code></pre> <p>What to look for</p> <ul> <li>If one regime dominates the coherence map, it\u2019s a sign the retained budget is concentrated.</li> <li>If you want more/less sparsity, adjust <code>--retained-target</code> or <code>--nside-out</code>.</li> </ul>"},{"location":"quick_run/","title":"Quick Run (copy/paste)","text":"<p>This page is the fastest way to get a successful run on Windows + Conda.</p>"},{"location":"quick_run/#1-bootstrap-the-repo-venv","title":"1) Bootstrap the repo venv","text":"<p>From the repo root (the folder that contains <code>pyproject.toml</code>):</p> <pre><code>python scripts/bootstrap.py\n</code></pre> <p>Confirm you are using the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"quick_run/#2-fetch-inputs-markham-toronto","title":"2) Fetch inputs (Markham + Toronto)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"quick_run/#3-run-the-two-core-demos","title":"3) Run the two core demos","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre>"},{"location":"quick_run/#4-run-the-diagnostic-demo-traffic-anomaly","title":"4) Run the diagnostic demo (Traffic Anomaly)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"quick_run/#5-preview-the-docs-site-locally","title":"5) Preview the docs site locally","text":"<p>Always run MkDocs via the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Optional strict check (useful before a commit):</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs build --strict\n</code></pre>"},{"location":"quick_run/#notes","title":"Notes","text":"<ul> <li>Prefer forward slashes in file paths (<code>cases/...</code>, <code>scripts/fetch_data.py</code>). Windows PowerShell accepts them and it avoids <code>\\t</code> / <code>\\f</code> escape surprises in YAML and other contexts.</li> <li>If <code>python</code> is not found, try <code>py -3 scripts/bootstrap.py</code> instead.</li> </ul>"},{"location":"reference_manual/","title":"HUF Reference Manual","text":"<p>Updated: 2026-02-17</p> <p>This manual is the \u201chow to run it\u201d companion to the handbook. It\u2019s written for:</p> <ul> <li>GUI-only users (download a ZIP, double-click a Windows starter),</li> <li>researchers who live in Excel + theory,</li> <li>anyone who wants reproducible artifacts without learning Git on day one.</li> </ul>"},{"location":"reference_manual/#1-quick-start-windows-no-git-required","title":"1) Quick Start (Windows, no Git required)","text":""},{"location":"reference_manual/#option-a-easiest-github-release-zip","title":"Option A \u2014 easiest: GitHub Release ZIP","text":"<ol> <li>Download the ZIP from the project\u2019s GitHub Releases page.</li> <li>Unzip it somewhere simple (Desktop is fine).</li> <li>Double-click: <code>START_HERE_WINDOWS.bat</code></li> </ol> <p>What it does:</p> <ul> <li>creates a local virtual environment in <code>.venv</code></li> <li>installs HUF in editable mode (local)</li> <li>fetches Markham + Toronto inputs (unless you skip)</li> <li>prints the exact commands to run the demos</li> </ul> <p>Tip: If Windows shows a security warning the first time, click \u201cMore info\u201d \u2192 \u201cRun anyway\u201d.</p>"},{"location":"reference_manual/#option-b-github-desktop-recommended-once-youre-comfortable","title":"Option B \u2014 GitHub Desktop (recommended once you\u2019re comfortable)","text":"<p>Use GitHub Desktop to keep your folder synced with GitHub.</p> <p>Day-to-day:</p> <ul> <li>Fetch checks for updates.</li> <li>Pull downloads updates.</li> <li>Commit records your changes.</li> <li>Push/Sync uploads your changes.</li> </ul>"},{"location":"reference_manual/#2-fetching-input-data-real-public-sources","title":"2) Fetching input data (real public sources)","text":"<p>Run these from the repo root (the folder that contains <code>pyproject.toml</code>).</p>"},{"location":"reference_manual/#markham-2018-budget-allocation-xlsx","title":"Markham (2018 Budget Allocation XLSX)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham\n</code></pre> <p>Expected file:</p> <ul> <li><code>cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></li> </ul>"},{"location":"reference_manual/#toronto-traffic-signals-timing-csv","title":"Toronto (Traffic signals timing \u2192 CSV)","text":"<p>Non-interactive default selection:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre> <p>Expected files:</p> <ul> <li><code>cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv</code></li> <li><code>cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv</code></li> </ul> <p>Toronto schema expected by HUF traffic adapters:</p> <ul> <li>required: <code>TCS</code>, <code>PHASE</code></li> <li>optional: <code>PHASE_STATUS_TEXT</code>, <code>PHASE_CALL_TEXT</code></li> </ul>"},{"location":"reference_manual/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>You\u2019ll end up with a FITS file such as:</p> <ul> <li><code>cases/planck70/inputs/...70...fits</code></li> </ul>"},{"location":"reference_manual/#3-running-the-included-cases-windows-powershell","title":"3) Running the included cases (Windows PowerShell)","text":""},{"location":"reference_manual/#a-markham-2018-fund-weighted-expenditures","title":"A) Markham 2018 (fund-weighted expenditures)","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre>"},{"location":"reference_manual/#b-toronto-traffic-phase-band-extraction","title":"B) Toronto traffic phase (band extraction)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre>"},{"location":"reference_manual/#c-toronto-traffic-anomaly-share-hotspots","title":"C) Toronto traffic anomaly (share + hotspots)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre>"},{"location":"reference_manual/#d-planck-70-ghz-map-coherence-stability","title":"D) Planck 70 GHz (map \u2192 coherence \u2192 stability)","text":"<pre><code>.\\.venv\\Scripts\\huf planck --fits cases/planck70/inputs/YOUR_70GHZ_MAP.fits --out out/planck70\n</code></pre>"},{"location":"reference_manual/#4-understanding-run_stampjson-your-reproducibility-receipt","title":"4) Understanding <code>run_stamp.json</code> (your reproducibility receipt)","text":"<p>HUF writes a stamp like:</p> <pre><code>{\n  \"dataset_id\": \"...\",\n  \"code_hash\": \"...\",\n  \"param_hash\": \"...\",\n  \"created_utc\": \"...\",\n  \"run_id\": \"...\"\n}\n</code></pre> <p>Interpretation:</p> <ul> <li><code>dataset_id</code> \u2014 identifier derived from the input file(s)</li> <li><code>code_hash</code> \u2014 identifier for the code state that produced artifacts</li> <li><code>param_hash</code> \u2014 identifier for your parameterization (\u03c4 grid, budgets, etc.)</li> <li><code>run_id</code> \u2014 unique run identifier</li> </ul> <p>If two runs have the same <code>dataset_id + code_hash + param_hash</code>, their artifacts should match (modulo timestamps).</p>"},{"location":"reference_manual/#5-troubleshooting-windows-focused","title":"5) Troubleshooting (Windows-focused)","text":""},{"location":"reference_manual/#ssl-certificate_verify_failed","title":"\u201cSSL: CERTIFICATE_VERIFY_FAILED\u201d","text":"<p>Try:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\python -m pip install certifi\n.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"reference_manual/#http-error-404-during-toronto-fetch","title":"\u201cHTTP Error 404\u201d during Toronto fetch","text":"<p>Default:</p> <ul> <li><code>https://open.toronto.ca/api/3/action</code></li> </ul> <p>Override explicitly:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes --toronto-ckan https://open.toronto.ca/api/3/action\n</code></pre>"},{"location":"reference_manual/#file-not-found-casesinputs","title":"\u201cFile not found \u2026 cases/.../inputs/...\u201d","text":"<p>Run fetch first:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"reference_manual/#6-build-preview-the-docs-site","title":"6) Build / preview the docs site","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Strict build check:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs build --strict\n</code></pre>"},{"location":"start_here/","title":"Start Here (Developer)","text":"<p>This page assumes you're comfortable editing files and running commands, but it still prioritizes copy/paste success.</p>"},{"location":"start_here/#1-clone-or-download-the-repo","title":"1) Clone or download the repo","text":"<ul> <li>Git: <code>git clone ...</code></li> <li>Or use GitHub Desktop</li> <li>Or download the ZIP from GitHub and unzip it</li> </ul> <p>You are in the right folder if you can see <code>pyproject.toml</code>.</p>"},{"location":"start_here/#2-create-the-repo-virtual-environment-venv","title":"2) Create the repo virtual environment (<code>.venv</code>)","text":"<p>Recommended (works on Windows/macOS/Linux):</p> <pre><code>python scripts/bootstrap.py\n</code></pre> <p>After bootstrap, always call the repo executables explicitly:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n</code></pre> <p>Conda users</p> <p>Conda is fine, but avoid installing HUF into a global Conda environment. Bootstrap once, then run <code>.\\.venv\\Scripts\\python</code> / <code>.\\.venv\\Scripts\\huf</code> explicitly so you never \u201caccidentally\u201d execute <code>miniconda3\\Scripts\\huf.exe</code>.</p>"},{"location":"start_here/#3-fetch-demo-inputs-markham-toronto","title":"3) Fetch demo inputs (Markham + Toronto)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"start_here/#4-run-a-case","title":"4) Run a case","text":"<pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre>"},{"location":"start_here/#5-run-the-docs-site-locally","title":"5) Run the docs site locally","text":"<p>Docs preview command (always):</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Strict build check (CI-style):</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs build --strict\n</code></pre>"},{"location":"start_here/#6-planck-optional-large-file","title":"6) Planck (optional, large file)","text":"<p>Planck files are large and are intentionally guided/manual:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>Then run:</p> <pre><code>.\\.venv\\Scripts\\huf planck --fits cases/planck70/inputs/YOUR_70GHZ_MAP.fits --out out/planck70\n</code></pre> <p>(Use the filename you actually downloaded; the Planck adapter accepts common 70\u202fGHz products.)</p>"},{"location":"theory_notes/","title":"Theory Notes (HUF / UBH)","text":"<p>Updated: 2026-02-17</p> <p>This repo is deliberately artifact-first: you can run real datasets and inspect outputs without accepting any theory claims.</p> <p>If you do want the formal structure (definitions, taxonomy, and expanded proofs), see:</p> <ul> <li><code>docs/The_Higgins_Unity_Framework.md</code> (full theoretical handbook)</li> <li>Handbook (conceptual + case-study narrative)</li> </ul>"},{"location":"theory_notes/#what-huf-is-in-one-paragraph","title":"What HUF is (in one paragraph)","text":"<p>HUF is a reproducibility wrapper around a single contract: a Unity\u2011Budgeted Hierarchy (UBH). A UBH is a hierarchy where each node\u2019s outgoing weights form a budgeted, normalized distribution (a \u201cunity\u201d constraint). HUF turns inputs into UBH elements, then emits auditable artifacts (tables, maps, images) plus a stability sweep that shows what structure survives across \u03c4.</p>"},{"location":"theory_notes/#why-unity-budget-matters","title":"Why \u201cunity budget\u201d matters","text":"<p>In practice, a unity budget behaves like a conserved quantity: - it forces competing explanations to share the same budget, - it makes comparisons across scales meaningful (local vs global), - it makes stability sweeps interpretable (what stays when \u03c4 tightens?).</p> <p>This was originally motivated by loudspeaker dispersion/diffraction work, but the same contract applies anywhere \u201cparts must sum to a whole\u201d.</p>"},{"location":"theory_notes/#proof-burden-and-how-huf-helps","title":"Proof burden and how HUF helps","text":"<p>HUF does not ask you to \u201cbelieve the proof.\u201d It asks you to: 1) run the same public dataset, 2) confirm you get the same artifacts, 3) inspect the stability packet, 4) only then argue about interpretation.</p> <p>That\u2019s why every run writes a <code>run_stamp.json</code>.</p>"},{"location":"traffic_phase_worked_example/","title":"Traffic Phase worked example (Toronto signals)","text":"<p>\u2190 Back to Cases</p> <p>This page is a guided artifact-reading flow for the Traffic Phase case:</p> <ul> <li><code>cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv</code></li> </ul> <p>Goal: show what HUF reveals that a typical \u201ccount rows / pivot table\u201d workflow usually hides: a ranked, auditable \u201cwhere the mass is\u201d map, per-intersection signatures, and stable compression knobs (tau).</p>"},{"location":"traffic_phase_worked_example/#1-run-it","title":"1) Run it","text":"<p>Windows PowerShell (from repo root):</p> <pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre>"},{"location":"traffic_phase_worked_example/#2-whats-in-the-input","title":"2) What\u2019s in the input","text":"<p>HUF expects a Toronto traffic phase status CSV with at least:</p> <ul> <li><code>TCS</code> (signal controller / intersection id)</li> <li><code>PHASE</code> (phase number)</li> </ul>"},{"location":"traffic_phase_worked_example/#3-what-the-adapter-does-finite-elements","title":"3) What the adapter does (finite elements)","text":"<p>The Traffic Phase adapter compresses raw rows into finite elements:</p> <ul> <li>Regime (group): <code>TCS=</code> (one regime per intersection)</li> <li>Element (inside a regime): <code>PHASE_BAND=</code></li> </ul> <p>Where <code>PHASE_BAND</code> is a deliberate, human-readable grouping:</p> <ul> <li><code>MajorEven(2,4,6,8)</code></li> <li><code>MinorOdd(1,3,5,7)</code></li> <li><code>Other(9-12)</code></li> </ul> <p>So each intersection becomes a 2\u20133 element \u201csignature vector\u201d:</p> <pre><code>TCS= -&gt; [MajorEven share, MinorOdd share, Other share]\n</code></pre>"},{"location":"traffic_phase_worked_example/#4-the-outputs-what-to-open-first","title":"4) The outputs (what to open first)","text":"<p>A run writes to <code>out/traffic_phase/</code>:</p> <p>1) <code>artifact_1_coherence_map.csv</code> \u2014 Intersection ranking (one row per <code>TCS</code>) + discard reporting 2) <code>artifact_2_active_set.csv</code> \u2014 Retained elements (bands that survived tau) 3) <code>artifact_3_trace_report.jsonl</code> \u2014 Provenance chain (how each item was formed) 4) <code>artifact_4_error_budget.json</code> \u2014 single-number discard summary 5) <code>stability_packet.csv</code> \u2014 small sweep showing sensitivity to tau</p>"},{"location":"traffic_phase_worked_example/#5-next-step-the-diagnostic-lens-traffic-anomaly","title":"5) Next step: the diagnostic lens (Traffic Anomaly)","text":"<p>Traffic Phase is the baseline case. The anomaly case is the exception case.</p> <p>Accounting analogy:</p> <ul> <li>Traffic Phase = whole ledger (stable allocation picture)</li> <li>Traffic Anomaly = filtered sub-ledger (refunds / overrides / exceptions)</li> </ul> <p>Run it:</p> <pre><code>.\\.venv\\Scripts\\huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\"\n</code></pre> <p>What to look for:</p> <ul> <li>Do the top regimes change (which intersections jump up)?</li> <li>Does concentration increase (fewer regimes explain most mass)?</li> <li>Does the long tail shrink or expand inside the exception status?</li> </ul> <p>That\u2019s the \u201cnon-linear + long-tail\u201d story: rare events often re-weight the system in ways that a baseline pivot table won\u2019t show clearly.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Updated: 2026-02-17</p> <p>This page collects common \u201cWindows reality\u201d problems people hit when they\u2019re new to Python tooling.</p>"},{"location":"troubleshooting/#1-venv-exists-but-commands-run-the-wrong-python","title":"1) \u201c.venv exists but commands run the wrong Python\u201d","text":"<p>If you see paths like <code>miniconda3\\Scripts\\huf.exe</code>, you\u2019re running a global install, not the repo venv.</p> <p>Use the venv explicitly:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"troubleshooting/#2-ssl-certificate-errors-certificate_verify_failed","title":"2) SSL certificate errors (CERTIFICATE_VERIFY_FAILED)","text":"<p>Symptoms:</p> <ul> <li><code>ssl.SSLCertVerificationError: certificate verify failed</code></li> </ul> <p>Fix:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install certifi\n.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes\n</code></pre> <p>If you are on a corporate network or behind a TLS-inspecting proxy, you may need to:</p> <ul> <li>download the dataset ZIP manually in a browser, then place the resulting CSV into the expected <code>cases/.../inputs/</code> folders</li> </ul>"},{"location":"troubleshooting/#3-toronto-fetch-gets-http-404","title":"3) Toronto fetch gets HTTP 404","text":"<p>Use the default CKAN base:</p> <ul> <li><code>https://open.toronto.ca/api/3/action</code></li> </ul> <p>Explicit override:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --toronto --yes --toronto-ckan https://open.toronto.ca/api/3/action\n</code></pre>"},{"location":"troubleshooting/#4-the-windows-starter-bat-prints-weird-characters","title":"4) The Windows starter <code>.bat</code> prints weird characters","text":"<p>If you see \u201c\u0393\u00a3\u00e0\u201d or similar, that\u2019s a console encoding mismatch.</p> <p>It does not affect the run. If you edited the <code>.bat</code> file, save it as:</p> <ul> <li>ANSI or UTF-8 (not UTF-16)</li> <li>with normal Windows line endings</li> </ul>"},{"location":"troubleshooting/#5-file-not-found-for-case-inputs","title":"5) \u201cFile not found\u201d for case inputs","text":"<p>Run fetch first:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>Then run the case commands.</p>"},{"location":"vector_db_coherence/","title":"Vector DB coherence (from retrieval results)","text":"<p>This is a small adapter that turns vector retrieval results into a HUF run so you can audit:</p> <ul> <li>which groups/\u201cregimes\u201d dominate the result set,</li> <li>which items are retained vs discarded (and why),</li> <li>how much probability mass lives in the long tail.</li> </ul> <p>It does not require a live vector database. You provide a JSONL export of results.</p>"},{"location":"vector_db_coherence/#input-format-jsonl","title":"Input format (JSONL)","text":"<p>One JSON object per line:</p> <pre><code>{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n</code></pre> <p>Required fields:</p> <ul> <li><code>id</code> (string): unique item id</li> <li><code>score</code> (number): similarity / relevance score (higher = better)</li> </ul> <p>Optional fields:</p> <ul> <li>any grouping field you want to treat as a \u201cregime\u201d, e.g. <code>namespace</code>, <code>collection</code>, <code>source</code></li> </ul>"},{"location":"vector_db_coherence/#run-windows-powershell","title":"Run (Windows PowerShell)","text":"<p>PowerShell note: use backticks for line continuation (not <code>\\</code>).</p> <pre><code>$py = \".\\.venv\\Scripts\\python.exe\"\n$in = \"cases/vector_db/inputs/retrieval.jsonl\"\n$out = \"out/vector_db_demo\"\n\nNew-Item -ItemType Directory -Force (Split-Path $in) | Out-Null\nNew-Item -ItemType Directory -Force $out | Out-Null\n\n@'\n{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_002\",\"score\":0.63,\"namespace\":\"kb\",\"source\":\"manual\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n{\"id\":\"doc_102\",\"score\":0.12,\"namespace\":\"tickets\",\"source\":\"ops\"}\n'@ | Set-Content -Encoding utf8 $in\n\n&amp; $py examples/run_vector_db_demo.py `\n  --in $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\ndir $out\n</code></pre> <p>If you see: <code>Unexpected UTF-8 BOM ...</code></p> <p>That means the file has a UTF-8 BOM. Either:</p> <ul> <li>keep the adapter BOM-tolerant (recommended), or</li> <li>rewrite the file without BOM:</li> </ul> <pre><code>$content = Get-Content $in -Raw\n[System.IO.File]::WriteAllText($in, $content, (New-Object System.Text.UTF8Encoding($false)))\n</code></pre>"},{"location":"vector_db_coherence/#run-maclinux","title":"Run (Mac/Linux)","text":"<pre><code>python examples/run_vector_db_demo.py --in cases/vector_db/inputs/retrieval.jsonl --out out/vector_db_demo --tau-global 0.02 --regime-field namespace\n</code></pre>"},{"location":"vector_db_coherence/#what-to-open-first-artifacts","title":"What to open first (artifacts)","text":"<p>In <code>out/vector_db_demo/</code>:</p> <p>1) <code>artifact_1_coherence_map.csv</code> \u2014 \u201cWhich regimes dominate?\u201d (sorted by <code>rho_global_post</code>) 2) <code>artifact_2_active_set.csv</code> \u2014 retained items with global + local shares (<code>rho_*</code>) 3) <code>artifact_3_trace_report.jsonl</code> \u2014 per-item reasoning: pre/post mass, exclusions, ranks</p> <p>Tip: for quick inspection without notebooks, use the helper script:</p> <pre><code>.\\.venv\\Scripts\\python scripts/inspect_vector_db_artifacts.py --out out/vector_db_demo\n</code></pre>"},{"location":"docs/data_sources/","title":"Data Sources &amp; Fetching (legacy path)","text":"<p>This page exists to keep old links working.</p> <p>Go here instead: Data Sources &amp; Fetching</p>"},{"location":"docs/get_started_zero_github/","title":"Start Here (Zero GitHub Knowledge) (moved)","text":"<p>This URL is kept for older links.</p> <p>The canonical page is now:</p> <ul> <li>Start Here (Zero GitHub Knowledge)</li> </ul>"}]}