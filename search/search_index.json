{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Higgins Unity Framework (HUF) \u2014 Documentation","text":"<p>This site is meant to help you run HUF first, then learn the rest in small steps.</p>"},{"location":"#start-here","title":"Start here","text":"<ul> <li>\u2705 Beginner (no GitHub knowledge required): Get Started (Zero GitHub)</li> <li>\u25b6\ufe0f Copy/paste demo runner: Quick Run</li> <li>\ud83e\udded Recommended reading order: Learning Path</li> <li>\ud83d\udce6 Download data (Markham + Toronto): Data Sources &amp; Fetching</li> <li>\u25b6\ufe0f Run examples (\u201ccases\u201d): Cases</li> <li>\ud83c\udd98 Fix common problems: Troubleshooting</li> </ul>"},{"location":"#what-is-huf","title":"What is HUF?","text":"<ul> <li>What is the Higgins Unity Framework?</li> </ul>"},{"location":"#for-developers","title":"For developers","text":"<ul> <li>Start Here (Developer)</li> <li>Reference Manual</li> <li>Theory Notes (optional)</li> <li>GitHub for Beginners</li> </ul>"},{"location":"The_Higgins_Unity_Framework/","title":"The Higgins Unity Framework (HUF)","text":"<p>This project is the HUF Core implementation: a practical toolkit you can run to turn messy real\u2011world datasets into consistent, comparable outputs.</p> <p>If you\u2019re not technical, don\u2019t worry \u2014 you can still use HUF by following the step\u2011by\u2011step guides.</p>"},{"location":"The_Higgins_Unity_Framework/#plainenglish-idea","title":"Plain\u2011English idea","text":"<p>Real systems produce lots of different signals:</p> <ul> <li>budgets, traffic timing, anomalies, logs, counts, categories\u2026</li> <li>all with different units, scales, and missing values</li> </ul> <p>HUF\u2019s core trick is to convert those signals into a normalized representation so that:</p> <ul> <li>different sources can be compared fairly</li> <li>changes over time are easier to detect</li> <li>\u201cwhat matters most\u201d can be ranked without hand\u2011tuning every dataset</li> </ul> <p>In this repo, that \u201cnormalization\u201d mostly shows up as:</p> <ul> <li>cleaning inputs</li> <li>mapping columns into a consistent schema</li> <li>producing standardized outputs you can analyze or visualize</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#what-you-get-from-this-repository","title":"What you get from this repository","text":"<ul> <li>Repeatable demos (\u201ccases\u201d) with real civic datasets (Markham + Toronto)</li> <li>A command line tool (<code>huf ...</code>) to run those cases</li> <li>A structure you can copy to add your own data adapters and cases</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#key-concepts-no-math","title":"Key concepts (no math)","text":""},{"location":"The_Higgins_Unity_Framework/#1-inputs-adapters-outputs","title":"1) Inputs \u2192 adapters \u2192 outputs","text":"<p>A \u201ccase\u201d takes some input file(s), runs a transformation, and writes results to an output folder.</p> <ul> <li>Input examples: <code>.xlsx</code>, <code>.csv</code>, large datasets (Planck is guided/manual)</li> <li>Output examples: cleaned tables, normalized metrics, reports</li> </ul>"},{"location":"The_Higgins_Unity_Framework/#2-normalization-the-unity-idea","title":"2) Normalization (the \u201cunity\u201d idea)","text":"<p>Normalization means turning different kinds of numbers into a consistent scale so they can be compared.</p> <p>Example: - Dataset A ranges from 0\u201310 - Dataset B ranges from 0\u201310,000</p> <p>After normalization, both can live on the same scale, so ranking and anomaly detection are meaningful.</p>"},{"location":"The_Higgins_Unity_Framework/#3-cases-are-learning-modules","title":"3) \u201cCases\u201d are learning modules","text":"<p>Each case is both: - a working example you can run today - a template you can copy when adding your own workflow</p>"},{"location":"The_Higgins_Unity_Framework/#where-to-begin","title":"Where to begin","text":"<ol> <li>Follow the beginner path: Learning Path </li> <li>Run a demo: Cases </li> <li>If you hit errors: Troubleshooting</li> </ol>"},{"location":"The_Higgins_Unity_Framework/#advanced-theory-optional","title":"Advanced / theory (optional)","text":"<p>Some HUF writings discuss deeper mathematics (categories, morphisms, topology, etc.). Those are not required to run the tools in this repo.</p> <p>If you want the deeper background, start with: - Theory Notes - Handbook</p>"},{"location":"The_Higgins_Unity_Framework/#glossary","title":"Glossary","text":"<ul> <li>Case: a runnable example workflow (input \u2192 process \u2192 output).</li> <li>Adapter: code that reads a particular dataset shape and maps it into HUF\u2019s expected schema.</li> <li>Normalization: converting values into a consistent scale to compare across sources.</li> <li>Schema: the column names / fields that HUF expects for a given workflow.</li> </ul> <p>Note: The original author notes and drafts existed as <code>.Markdown</code>. This repo now keeps documentation in Markdown (<code>.md</code>) so it renders well on GitHub and GitHub Pages.</p>"},{"location":"cases/","title":"Included cases","text":"<p>These cases are ready-to-run from a fresh clone.</p> <p>Inputs - \u2705 Markham XLSX: shipped in <code>cases/markham2018/inputs/</code> - \u2705 Toronto traffic CSVs: shipped in <code>cases/traffic_phase/inputs/</code> and <code>cases/traffic_anomaly/inputs/</code> - \u274c Planck FITS: not shipped (large). Use <code>python scripts/fetch_data.py --planck-guide</code> for a copy/paste download guide.</p> <p>Outputs - New runs write to <code>out/&lt;case_name&gt;/</code> (recommended). - Each run produces the same core artifacts:   <code>artifact_1_coherence_map.csv</code>, <code>artifact_2_active_set.csv</code>,   <code>artifact_3_trace_report.jsonl</code>, <code>artifact_4_error_budget.json</code>,   plus <code>meta.json</code> and <code>run_stamp.json</code>.</p>"},{"location":"cases/#quick-commands-windows-powershell","title":"Quick commands (Windows PowerShell)","text":"<p>Tip: run <code>START_HERE_WINDOWS.bat</code> first (it prepends <code>.\\.venv\\Scripts</code> to <code>PATH</code>).</p> <p>Fetch (optional refresh of shipped inputs): <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --markham --toronto --yes\n</code></pre></p> <p>Run Markham: <pre><code>huf markham --xlsx cases\\markham2018\\inputs\\2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out\\markham2018\n</code></pre></p> <p>Run Traffic Phase: <pre><code>huf traffic --csv cases\\traffic_phase\\inputs\\toronto_traffic_signals_phase_status.csv --out out\\traffic_phase\n</code></pre></p> <p>Run Traffic Anomaly: <pre><code>huf traffic-anomaly --csv cases\\traffic_anomaly\\inputs\\toronto_traffic_signals_phase_status.csv --out out\\traffic_anomaly --status \"Green Termination\"\n</code></pre></p> <p>Planck guide (prints download steps, does not download automatically): <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --planck-guide\n</code></pre></p>"},{"location":"cases/#what-each-case-demonstrates","title":"What each case demonstrates","text":""},{"location":"cases/#markham-2018-budget-xlsx","title":"Markham 2018 budget (XLSX)","text":"<ul> <li>Adapter: <code>huf markham ...</code></li> <li>Shows: multi-fund budget compression + cell-level provenance from a public workbook.</li> <li>Best next page: \ud83d\udc49 Markham worked example</li> </ul>"},{"location":"cases/#toronto-traffic-phase-csv","title":"Toronto traffic phase (CSV)","text":"<ul> <li>Adapter: <code>huf traffic ...</code></li> <li>Shows: phase-band compression (lots of rows \u2192 fewer coherent regimes) for operational signals.</li> <li>Best next page: \ud83d\udc49 Traffic Phase worked example</li> </ul>"},{"location":"cases/#toronto-traffic-anomaly-csv","title":"Toronto traffic anomaly (CSV)","text":"<ul> <li>Adapter: <code>huf traffic-anomaly ...</code></li> <li>Shows: diagnostic filtering for a named status (e.g., <code>\"Green Termination\"</code>) with global discard reporting.</li> </ul>"},{"location":"cases/#planck-lfi-70-ghz-fits","title":"Planck LFI 70 GHz (FITS)","text":"<ul> <li>Adapter: <code>huf planck ...</code></li> <li>Shows: pixel-energy compression on a sky map (requires <code>astropy</code>; FITS not bundled).</li> </ul>"},{"location":"cases/#verify-a-run-quickly","title":"Verify a run quickly","text":"<p>After any run, check the output folder has at least: - <code>run_stamp.json</code> - <code>artifact_1_coherence_map.csv</code> - <code>artifact_2_active_set.csv</code></p> <p>Example: <pre><code>Test-Path out\\markham2018\\run_stamp.json\nTest-Path out\\markham2018\\artifact_1_coherence_map.csv\n</code></pre></p>"},{"location":"cases/#links","title":"Links","text":"<ul> <li> <p>Repo case folders (inputs + example artifacts): <code>cases/markham2018/</code>, <code>cases/traffic_phase/</code>, <code>cases/traffic_anomaly/</code>, <code>cases/planck70/</code></p> </li> <li> <p>GitHub (browse raw files):</p> </li> <li>Markham: https://github.com/PeterHIggins19/huf_core_github_v1.1.8_no_inputs/tree/main/cases/markham2018</li> <li>Traffic phase: https://github.com/PeterHIggins19/huf_core_github_v1.1.8_no_inputs/tree/main/cases/traffic_phase</li> <li>Traffic anomaly: https://github.com/PeterHIggins19/huf_core_github_v1.1.8_no_inputs/tree/main/cases/traffic_anomaly</li> <li>Planck: https://github.com/PeterHIggins19/huf_core_github_v1.1.8_no_inputs/tree/main/cases/planck70</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome \u2014 even small things like typo fixes or \u201cthis step confused me\u201d issues help a lot.</p>"},{"location":"contributing/#the-easiest-ways-to-help","title":"The easiest ways to help","text":"<ol> <li>Open an Issue (best for feedback / questions)</li> <li>Describe what you tried, what happened, and what you expected.</li> <li> <p>If it\u2019s about a command, paste the exact command + the terminal output.</p> </li> <li> <p>Send a Pull Request</p> </li> <li>Fork the repo \u2192 create a branch \u2192 make changes \u2192 open a PR.</li> <li>Docs-only PRs are totally fine (they\u2019re often the most valuable).</li> </ol>"},{"location":"contributing/#suggested-contribution-ideas","title":"Suggested contribution ideas","text":"<ul> <li>Add a small new \u201cworked example\u201d page for a dataset you care about</li> <li>Improve Windows copy/paste reliability</li> <li>Add tiny helper scripts (inspect artifacts, sanity checks, etc.)</li> </ul>"},{"location":"contributing/#repo-settings-that-help-contributors","title":"Repo settings that help contributors","text":"<ul> <li>Issues: Enabled</li> <li>Pull requests from forks: Enabled</li> <li>Branch protection (optional): require CI checks on <code>main</code></li> </ul> <p>The canonical contributor guidance lives in the root CONTRIBUTING.md in the repo.</p>"},{"location":"data_sources/","title":"Data Sources &amp; Fetching","text":"<p>This repo ships small inputs for Markham and Toronto examples via <code>scripts/fetch_data.py</code>.</p> <p>Planck is intentionally guide-only because the file is ~480\u2013500MB.</p>"},{"location":"data_sources/#fetch-the-small-inputs-recommended-path","title":"Fetch the small inputs (recommended path)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre> <p>If you haven't created the venv yet, run:</p> <pre><code>python scripts/bootstrap.py\n</code></pre>"},{"location":"data_sources/#markham-2018-budget","title":"Markham (2018 budget)","text":"<p>Source: Markham Open Data / ArcGIS (the public portal link may change over time).</p> <p>Expected local path in this repo:</p> <p><code>cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></p> <p>Run:</p> <pre><code>.\\.venv\\Scripts\\huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n</code></pre>"},{"location":"data_sources/#toronto-traffic-signals-phase-status","title":"Toronto traffic signals (phase status)","text":"<p>Expected local path:</p> <p><code>cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv</code></p> <p>Run:</p> <pre><code>.\\.venv\\Scripts\\huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n</code></pre>"},{"location":"data_sources/#planck-lfi-70-ghz-pr3-guide-only","title":"Planck LFI 70 GHz (PR3) \u2014 guide only","text":"<p>Print the guide:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>The IRSA direct download URL referenced in the guide is:</p> <p><code>https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits</code></p>"},{"location":"data_sources/#powershell-note-about-curl","title":"PowerShell note about <code>curl</code>","text":"<p>In Windows PowerShell, <code>curl</code> is an alias for <code>Invoke-WebRequest</code>, so <code>curl -L</code> fails.</p> <p>Use <code>curl.exe</code>:</p> <pre><code>curl.exe -L -o \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\" \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\n</code></pre> <p>Or use BITS (recommended on Windows):</p> <pre><code>$dest = Join-Path $PWD \"cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits\"\nNew-Item -ItemType Directory -Force (Split-Path $dest) | Out-Null\n$src  = \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\nStart-BitsTransfer -Source $src -Destination $dest\n</code></pre>"},{"location":"data_sources/#docs-preview","title":"Docs preview","text":"<pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre>"},{"location":"get_started_readme/","title":"HUF Get Started Package","text":"<p>Open Start_Here.md or Start_Here.md.</p> <ul> <li>If you already have the HUF GitHub package, run the start scripts in the repo root:</li> <li>Windows: <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: <code>START_HERE_MAC.command</code></li> <li>Linux: <code>start_here_linux.sh</code></li> </ul> <p>This package does not include large input datasets. Data sources and instructions are in <code>docs/data_sources.md</code>.</p>"},{"location":"get_started_zero_github/","title":"Start Here (Zero GitHub Knowledge)","text":"<p>This page is written for Windows PowerShell users who want copy/paste success.</p> <p>Important: HUF installs into a repo-local virtual environment at <code>.venv/</code>. To avoid Conda/PATH collisions, this guide uses explicit venv paths.</p>"},{"location":"get_started_zero_github/#option-1-one-click-starter-recommended","title":"Option 1: One-click starter (recommended)","text":"<p>From the repo root, run:</p> <ul> <li>Windows: <code>START_HERE_WINDOWS.bat</code></li> <li>Mac: <code>START_HERE_MAC.command</code></li> <li>Linux: <code>START_HERE_LINUX.sh</code></li> </ul> <p>These scripts bootstrap the environment and print the exact commands to run next.</p>"},{"location":"get_started_zero_github/#option-2-manual-copypaste","title":"Option 2: Manual (copy/paste)","text":""},{"location":"get_started_zero_github/#0-open-powershell-in-the-repo-root","title":"0) Open PowerShell in the repo root","text":"<p>If your folder is, for example, <code>D:\\GitHub\\HUF-Core\\huf_core_github_v1.1.8_no_inputs</code>, then:</p> <pre><code>cd D:\\GitHub\\HUF-Core\\huf_core_github_v1.1.8_no_inputs\n</code></pre>"},{"location":"get_started_zero_github/#1-create-the-repo-venv-install-dependencies","title":"1) Create the repo venv + install dependencies","text":"<pre><code>python scripts/bootstrap.py\n</code></pre>"},{"location":"get_started_zero_github/#2-fetch-the-small-demo-inputs-markham-toronto","title":"2) Fetch the small demo inputs (Markham + Toronto)","text":"<pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"get_started_zero_github/#3-run-the-demos-always-use-the-repo-venv","title":"3) Run the demos (always use the repo venv)","text":"<p>Markham 2018 budget</p> <pre><code>.\\.venv\\Scripts\\huf markham `\n  --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx `\n  --out  out/markham2018 `\n  --tau-global 0.005 `\n  --tau-local  0.02\n</code></pre> <p>Traffic Phase</p> <pre><code>.\\.venv\\Scripts\\huf traffic `\n  --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv `\n  --out out/traffic_phase `\n  --tau-local 0.05\n</code></pre> <p>Traffic Anomaly</p> <pre><code>.\\.venv\\Scripts\\huf traffic-anomaly `\n  --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv `\n  --out out/traffic_anomaly `\n  --status \"Green Termination\" `\n  --tau-global 0.0005\n</code></pre>"},{"location":"get_started_zero_github/#4-planck-large-file-guide-only","title":"4) Planck (large file \u2014 guide only)","text":"<p>Print the Planck download guide:</p> <pre><code>.\\.venv\\Scripts\\python scripts/fetch_data.py --planck-guide\n</code></pre> <p>After you place the FITS at:</p> <p><code>cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits</code></p> <p>Run:</p> <pre><code>.\\.venv\\Scripts\\huf planck `\n  --fits cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits `\n  --out out/planck70 `\n  --retained-target 0.97 `\n  --nside-out 64\n</code></pre>"},{"location":"get_started_zero_github/#build-preview-the-docs-locally","title":"Build / preview the docs locally","text":"<p>If you ever see:</p> <p><code>mkdocs : The term 'mkdocs' is not recognized ...</code></p> <p>Use this (it bypasses PATH issues):</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n</code></pre> <p>Then open the local URL it prints.</p>"},{"location":"get_started_zero_github/#maclinux-convenience-make-optional","title":"Mac/Linux convenience: <code>make</code> (optional)","text":"<p>If you have <code>make</code> installed, these are shortcuts:</p> <pre><code>make fetch-data\nmake planck-guide\n</code></pre> <p>Windows users should stick to the PowerShell blocks above.</p>"},{"location":"github_for_beginners/","title":"GitHub for HUF (Beginner, GUI-first)","text":"<p>This is a plain-language guide to using HUF on GitHub with minimal jargon.</p> <p>You do not need to learn command-line git to run HUF.</p>"},{"location":"github_for_beginners/#what-is-github","title":"What is GitHub?","text":"<p>GitHub is a website that stores a project folder online and keeps a history of every change.</p> <p>For HUF, GitHub is where: - the code lives (the library + CLI) - the docs live (Handbook + Reference Manual) - fixes and improvements can be shared safely</p>"},{"location":"github_for_beginners/#the-easiest-way-github-desktop-point-and-click","title":"The easiest way: GitHub Desktop (point-and-click)","text":""},{"location":"github_for_beginners/#1-create-a-github-account-optional-but-recommended","title":"1) Create a GitHub account (optional but recommended)","text":"<ul> <li>Go to https://github.com/</li> <li>Create an account with your email and a username</li> </ul> <p>You can still download HUF without an account, but GitHub Desktop works best when signed in.</p>"},{"location":"github_for_beginners/#2-install-github-desktop","title":"2) Install GitHub Desktop","text":"<ul> <li>Download: https://desktop.github.com/</li> <li>Install like any normal app</li> </ul>"},{"location":"github_for_beginners/#3-get-huf-onto-your-computer-clone","title":"3) Get HUF onto your computer (\u201cClone\u201d)","text":"<ol> <li>Open GitHub Desktop</li> <li>File \u2192 Clone repository\u2026</li> <li>Paste the HUF repository URL</li> <li>Choose a local folder (example: <code>Documents/HUF</code>)</li> <li>Click Clone</li> </ol> <p>Now HUF is a normal folder on your computer.</p>"},{"location":"github_for_beginners/#how-to-run-huf-after-cloning","title":"How to run HUF after cloning","text":"<p>From the HUF folder:</p> <ul> <li>Windows: double-click <code>START_HERE_WINDOWS.bat</code></li> <li>macOS: right-click <code>START_HERE_MAC.command</code> \u2192 Open</li> <li>Linux: run <code>./start_here_linux.sh</code></li> </ul> <p>This sets up Python and installs what HUF needs.</p> <p>Then fetch data: - <code>make fetch-data</code> - or <code>python scripts/fetch_data.py --markham --toronto</code></p> <p>Planck is guided/manual: - <code>make planck-guide</code></p> <p>Run a demo: - <code>huf --help</code></p>"},{"location":"github_for_beginners/#how-to-get-updates-no-command-line","title":"How to get updates (no command line)","text":"<p>In GitHub Desktop: 1. Open the HUF repository 2. Click Fetch origin 3. If updates are available, click Pull origin</p> <p>That\u2019s it \u2014 your local folder updates.</p>"},{"location":"github_for_beginners/#do-i-need-branches-and-pull-requests","title":"Do I need branches and pull requests?","text":"<p>Not to run HUF.</p> <p>Branches and pull requests matter when you want to propose changes or safely test edits.</p> <ul> <li>Branch = a safe copy of the project to experiment in</li> <li>Pull Request = a polite way to ask: \u201cCan we add my changes?\u201d</li> </ul> <p>If you are just running the demos, you can ignore these.</p>"},{"location":"github_for_beginners/#where-are-the-record-copies","title":"Where are the \u201crecord copies\u201d ?","text":"<ul> <li><code>docs/handbook.md</code></li> <li><code>docs/reference_manual.md</code></li> <li><code>docs/data_sources.md</code></li> <li><code>docs/start_here.md</code></li> </ul> <p>These are included for users who keep formal records outside GitHub.</p>"},{"location":"gui_quickstart/","title":"GUI Quickstart (non\u2011GitHub\u2011native users)","text":"<p>This page is for people who prefer GUI workflows (e.g., GitHub Desktop, file explorers, Word/Excel) but still want to run HUF and keep record copies.</p>"},{"location":"gui_quickstart/#note","title":"Note","text":"<p>This docs-only package does not include the code/CLI. To run HUF, download the GitHub package release as well.</p>"},{"location":"gui_quickstart/#what-you-can-do-without-git","title":"What you can do without Git","text":"<p>If you don\u2019t want Git at all:</p> <ol> <li>Download the latest release ZIP from GitHub (look for Releases on the right side of the repo page).</li> <li>Unzip it to a folder like <code>Documents/HUF/</code>.</li> <li>Open the Markdown record copies in <code>docs/</code>:</li> <li><code>docs/handbook.md</code></li> <li><code>docs/reference_manual.md</code></li> <li><code>docs/data_sources.md</code></li> </ol> <p>You can still run the CLI from this unzipped folder (see below).</p>"},{"location":"gui_quickstart/#using-github-desktop-recommended-for-updates","title":"Using GitHub Desktop (recommended for updates)","text":"<p>If you want one-click updates:</p> <ol> <li>Install GitHub Desktop.</li> <li>In GitHub Desktop: File \u2192 Clone repository\u2026</li> <li>Pick a local folder (e.g., <code>Documents/GitHub/huf-core</code>).</li> <li>To update later: press Fetch origin then Pull origin.</li> </ol>"},{"location":"gui_quickstart/#one-time-setup-to-run-huf","title":"One-time setup to run HUF","text":"<p>You need Python 3.10+ installed.</p>"},{"location":"gui_quickstart/#step-1-open-a-terminal-in-the-repo-folder","title":"Step 1 \u2014 Open a terminal in the repo folder","text":"<ul> <li>Windows: open File Explorer \u2192 go to the repo folder \u2192 right\u2011click \u2192 Open in Terminal (or PowerShell).</li> <li>macOS: Finder \u2192 repo folder \u2192 right\u2011click \u2192 New Terminal at Folder (or open Terminal and <code>cd</code>).</li> <li>Linux: open Terminal and <code>cd</code> into the folder.</li> </ul>"},{"location":"gui_quickstart/#step-2-run-the-bootstrap-crossplatform","title":"Step 2 \u2014 Run the bootstrap (cross\u2011platform)","text":"<p>From the repo root:</p> <pre><code>python scripts/bootstrap.py\n</code></pre> <p>This creates <code>.venv/</code> and installs everything you need.</p> <p>If you\u2019re on macOS/Linux you can also use: <code>make bootstrap</code></p>"},{"location":"gui_quickstart/#download-the-real-input-data-no-big-inputs-are-bundled","title":"Download the real input data (no big inputs are bundled)","text":""},{"location":"gui_quickstart/#markham-toronto-automatic","title":"Markham + Toronto (automatic)","text":"<p>After bootstrap, run one of these:</p> <pre><code>make fetch-data\n# or:\npython scripts/fetch_data.py --markham --toronto\n</code></pre>"},{"location":"gui_quickstart/#toronto-non-interactive-yes","title":"Toronto non-interactive (<code>--yes</code>)","text":"<p>For scripted demos (no prompts):</p> <pre><code>make fetch-toronto-yes\n# or:\npython scripts/fetch_data.py --toronto --yes\n</code></pre>"},{"location":"gui_quickstart/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<p>Planck files are large, so HUF prints the steps instead of downloading by default:</p> <pre><code>make planck-guide\n# or:\npython scripts/fetch_data.py --planck-guide\n</code></pre>"},{"location":"gui_quickstart/#run-the-demos","title":"Run the demos","text":""},{"location":"gui_quickstart/#markham","title":"Markham","text":"<pre><code>huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018 --tau-global 0.005 --tau-local 0.02\n</code></pre>"},{"location":"gui_quickstart/#toronto-traffic","title":"Toronto traffic","text":"<pre><code>huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase --tau-local 0.05\n</code></pre>"},{"location":"gui_quickstart/#where-outputs-go","title":"Where outputs go","text":"<p>Each run writes a folder like <code>out/markham2018/</code> or <code>out/traffic_phase/</code> containing the mandatory artifacts:</p> <ul> <li><code>artifact_1_coherence_map.csv</code></li> <li><code>artifact_2_active_set.csv</code></li> <li><code>artifact_3_trace_report.jsonl</code></li> <li><code>artifact_4_error_budget.json</code></li> </ul> <p>You can open the CSVs in Excel and keep them with your meeting notes.</p>"},{"location":"handbook/","title":"Higgins Unity Framework (HUF) Handbook","text":"<p>Edition: v1.1.8 (docs refresh) Updated: 2026-02-17  </p> <p>This handbook is the conceptual and contractual description of HUF: what the Unity-Budgeted Hierarchy (UBH) is, how HUF emits auditable artifacts, and how to interpret stability sweeps.</p> <p>Real-data demos included in this repo: - Markham (2018 budget) \u2014 real Excel input fetched from the City of Markham open data site. - Toronto (traffic signals timing) \u2014 real CSV derived from the City of Toronto open data \u201cTraffic signals timing\u201d ZIP. - Planck (70 GHz all-sky map) \u2014 real FITS map not shipped in the repo (too large). You fetch it from PLA or IRSA (guided in <code>scripts/fetch_data.py --planck-guide</code>).</p> <p>Synthetic data: only small \u201ctoy\u201d examples (used for quick sanity checks) are synthetic. The headline demos above are real data.</p>"},{"location":"handbook/#origins-why-this-exists","title":"Origins (why this exists)","text":"<p>HUF grew out of a very practical question: how to solve diffraction and dispersion problems in loudspeakers well enough that the \u201cwhy\u201d became impossible to ignore. The working path was:</p> <ol> <li>solve the physical problem (dispersion / diffraction) empirically</li> <li>notice an \u201cenergy budget\u201d invariant when moving from 2\u03c0 to 4\u03c0 radiation equalization</li> <li>formalize the invariant as an isotropic budget / unity constraint</li> <li>generalize it into a contract for hierarchies \u2192 the Unity\u2011Budgeted Hierarchy (UBH)</li> <li>treat every run as a reproducible artifact emitter \u2192 HUF</li> </ol> <p>That\u2019s the reason the framework is written like a lab protocol: it is designed to let people verify \u201cis this real?\u201d before debating \u201cis this beautiful?\u201d.</p> <p>Higgins Unity Framework (HUF) Handbook</p> <p>A contract-first method for unity\u2011budgeted hierarchies, auditable reduction, and stable anomaly localization</p> <p>Handbook Edition \u2022 Version 1.0 February 2026</p> <p>Peter Higgins</p>"},{"location":"handbook/#front-matter","title":"Front matter","text":"<p>This handbook replaces the earlier \u2018meeting spec\u2019 lineage. It is written to be implementable, teachable, and hard to misread. The tone is intentionally contract\u2011driven: if you cannot verify finite elements, conserve a declared unity budget, emit the required artifacts, and pass stability checks, then you are not doing HUF \u2014 you are doing storytelling.</p> <p>The handbook contains two comprehensive, real-data case studies (Planck 70\u202fGHz and City of Markham public data) and a third operational case study (traffic signal telemetry) as an anomaly\u2011localization template.</p>"},{"location":"handbook/#how-to-use-this-handbook","title":"How to use this handbook","text":"<ul> <li> <p>If you need the method: read Part I and implement the contract (required artifacts + stability packet).</p> </li> <li> <p>If you need proof: read Part II and reproduce the reference runs (Planck and Markham).</p> </li> <li> <p>If you need to teach or deploy: read Part III (implementation patterns, templates, and training exercises).</p> </li> </ul>"},{"location":"handbook/#table-of-contents","title":"Table of contents","text":"<p>In Word: Right\u2011click the TOC \u2192 Update Field \u2192 Update entire table.</p>"},{"location":"handbook/#part-i-huf-core-normative","title":"Part I \u2014 HUF Core (Normative)","text":""},{"location":"handbook/#1-definition-in-one-page-the-core-stripped","title":"1. Definition in one page (the core, stripped)","text":"<p>HUF defines a system as a unity\u2011budgeted hierarchy with auditable finite elements.</p> <ol> <li> <p>Finite elements: verifiable units that contribute to a conserved budget.</p> </li> <li> <p>Regimes: named groupings of finite elements (nestable) used for interpretability.</p> </li> <li> <p>Unity budget: a declared conserved quantity (mass/weight or energy/power) with total sum exactly 1.0.</p> </li> <li> <p>Locked cycle: Normalize \u2192 Propagate \u2192 Aggregate \u2192 Exclude \u2192 Renormalize.</p> </li> <li> <p>Contract: a run is invalid unless it emits the required artifacts and passes declared stability checks.</p> </li> </ol>"},{"location":"handbook/#2-motivation-the-shortest-honest-version","title":"2. Motivation (the shortest honest version)","text":"<p>Every serious system ends up doing some form of reduction: compressing models, pruning portfolios, prioritizing interventions, or summarizing telemetry. The failure mode is consistent: reduction happens, but the justification is ad hoc. HUF exists to make reduction auditable.</p> <p>HUF does not promise \u2018truth.\u2019 It promises four things you can test: (1) unity conservation, (2) explicit retained set, (3) explicit discarded budget, and (4) backward trace to finite elements. That\u2019s the entire game.</p>"},{"location":"handbook/#3-primitives-and-invariants","title":"3. Primitives and invariants","text":"<p>3.1 Finite element</p> <p>A finite element is the smallest unit you agree to audit. It must have: a unique identifier, a repeatable method of computing its contribution, and stored provenance.</p> <p>Minimum finite-element record:</p> <ul> <li> <p>id: stable string key (do not recycle IDs across runs)</p> </li> <li> <p>inputs: pointers to measured data, logs, or upstream artifacts</p> </li> <li> <p>contribution: a non-negative scalar (or paired positive/negative extension) used by the unity budget</p> </li> <li> <p>provenance: hash or stamp sufficient to reproduce the number</p> </li> </ul> <p>3.2 Regime</p> <p>A regime is a partition (or nested partition) used to contextualize budget. A regime answers: \u2018where did the budget go?\u2019 Regimes must not double-count contributions. If an element belongs to multiple regimes, you must explicitly split its budget.</p> <p>3.3 Unity budget</p> <p>Unity is the only invariant HUF treats as sacred: after normalization, the sum of contributions equals 1.0 globally. Local unity (within a regime) may be enforced for a local view, but the global unity must always be satisfied.</p>"},{"location":"handbook/#4-budget-semantics-choose-once-dont-cheat","title":"4. Budget semantics (choose once; don\u2019t cheat)","text":"<p>HUF is ruthless about budget semantics. Declare one of the following and never mix them mid-run:</p> <ul> <li> <p>Mass/weight budget: \u03c1\u1d62 \u2265 0 and \u03a3\u03c1\u1d62 = 1. Examples: expenditure shares, portfolio weights, probability mass.</p> </li> <li> <p>Energy/power budget: \u03c1\u1d62 = e\u1d62 / \u03a3e with e\u1d62 = |x\u1d62|\u00b2 or another Parseval-consistent energy under a declared orthogonal basis.</p> </li> </ul> <p>If your domain has cancellation (signed contributions), do not fake it by allowing negative \u03c1. Use a paired-budget extension (track positive and negative magnitudes separately) or an explicitly signed framework with stability proofs.</p>"},{"location":"handbook/#5-the-locked-cycle-and-what-each-step-is-allowed-to-do","title":"5. The locked cycle and what each step is allowed to do","text":"<p>Figure 1. The locked HUF cycle. You may extend steps, but you may not reorder them without breaking audit expectations.</p> <p>Normalize</p> <p>Normalize converts raw contributions into a unity budget. For mass budgets: \u03c1\u1d62 = w\u1d62 / \u03a3w. For energy budgets: \u03c1\u1d62 = |x\u1d62|\u00b2 / \u03a3|x|\u00b2. Normalization must be deterministic and logged.</p> <p>Propagate</p> <p>Propagation moves budget between representations (e.g., from fine pixels to coarse blocks, from categories to wards, from events to root causes). Propagation is admissible only if it is conservative and traceable.</p> <ul> <li> <p>Conservation check: |\u03a3\u03c1_out \u2212 \u03a3\u03c1_in| \u2264 \u03b5 (declare \u03b5).</p> </li> <li> <p>Traceability check: every output element stores a map back to input elements with weights.</p> </li> <li> <p>No hidden state: propagation must be a pure function of inputs + declared parameters (seeded if stochastic).</p> </li> </ul> <p>Aggregate</p> <p>Aggregation merges elements to reduce complexity while preserving the budget. Examples: cluster similar items, sum within a regime, downsample by known hierarchical structure.</p> <p>Exclude</p> <p>Exclusion removes elements below a threshold \u03c4 or keeps the smallest set reaching a retained budget target. Exclusion must emit a discard ledger (what was removed and how much budget it carried).</p> <p>Renormalize and validate</p> <p>Renormalize after exclusion (and after any operation that may introduce floating-point drift). Then validate the contract: unity checks, trace completeness, artifact emission, and stability packet results.</p>"},{"location":"handbook/#6-the-contract-required-artifacts","title":"6. The contract (required artifacts)","text":"<p>Contract: a HUF run is invalid unless it emits all artifacts</p>"},{"location":"handbook/#7-artifact-schemas-minimum-workable-forms","title":"7. Artifact schemas (minimum workable forms)","text":"<p>HUF does not mandate file formats, but it does mandate fields. Minimal schemas:</p> <p>Schema A \u2014 Active set</p> <p>Schema B \u2014 Backward trace (per retained element)</p> <p>Schema C \u2014 Error/Budget report</p>"},{"location":"handbook/#8-stability-packet-required-anti-brittleness-tests","title":"8. Stability packet (required anti-brittleness tests)","text":"<p>Minimum stability packet</p>"},{"location":"handbook/#9-deployment-hazards-the-things-critics-correctly-attack","title":"9. Deployment hazards (the things critics correctly attack)","text":"<ul> <li> <p>Semantics drift: changing what unity means mid-run (e.g., mixing weight and energy).</p> </li> <li> <p>Black-box propagation: learned or heuristic mapping with no trace and no conservation validation.</p> </li> <li> <p>Double counting: elements belonging to overlapping regimes without explicit splitting.</p> </li> <li> <p>Unstable thresholds: large near-\u03c4 mass and low overlap across sweeps.</p> </li> <li> <p>Overfitting the narrative: tuning \u03c4 until your preferred story appears.</p> </li> </ul> <p>HUF\u2019s job is to make these failures visible. If your run fails, that is not \u2018HUF failing\u2019; that is the system refusing to be compressed honestly.</p>"},{"location":"handbook/#part-ii-comprehensive-reference-runs-real-data","title":"Part II \u2014 Comprehensive Reference Runs (Real Data)","text":""},{"location":"handbook/#10-case-study-a-planck-lfi-70-ghz-healpix-nside1024","title":"10. Case Study A \u2014 Planck LFI 70\u202fGHz (HEALPix, nside=1024)","text":"<p>This case demonstrates energy\u2011budget HUF on a large scientific dataset. Input file: LFI_SkyMap_070_1024_R3.00_full.fits. We use the Stokes I column (I_STOKES). The finite elements are pixels; the energy contribution is I\u00b2.</p>"},{"location":"handbook/#101-data-model","title":"10.1 Data model","text":"<ul> <li> <p>Raw finite elements: nside=1024 pixels (12\u00d71024\u00b2 = 12,582,912 elements).</p> </li> <li> <p>Aggregation: NESTED parent blocks at nside=64 (12\u00d764\u00b2 = 49,152 coarse elements), each covering 256 child pixels.</p> </li> <li> <p>Regimes: 12 HEALPix base faces (each face = 4,096 coarse blocks).</p> </li> <li> <p>Budget: energy share \u03c1\u1d62 = e\u1d62 / \u03a3e, with e\u1d62 = \u03a3child I\u00b2 (for coarse blocks).</p> </li> </ul>"},{"location":"handbook/#102-run-configuration","title":"10.2 Run configuration","text":"<p>Aggregation: nside 1024 \u2192 64 (ratio 16; 256 children per parent).</p> <p>Retain target: 0.97 of total energy.</p> <p>Outcome: K = 18,198 retained coarse blocks out of 49,152. Threshold \u03c4 = 1.66e-06.</p> <p>Energy retained = 0.9700; discarded = 0.0300.</p> <p>Pixel\u2011basis RMSE under keep\u2011or\u2011zero reconstruction = 7.6942e-05 (same units as I_STOKES).</p>"},{"location":"handbook/#103-coherence-map","title":"10.3 Coherence map","text":"<p>Figure 2. Planck 70\u202fGHz \u2014 global retained vs discarded energy share.</p> <p>Figure 3. Planck 70\u202fGHz \u2014 per\u2011face unity bars (faces as regimes).</p> <p>Figure 4. Planck 70\u202fGHz \u2014 active\u2011set growth curve (sorted by \u03c1).</p> <p>Table 10\u2011A. Per\u2011face energy shares (global \u03c1)</p> <p>Table 10\u2011B. Top retained coarse blocks (traceable sample)</p>"},{"location":"handbook/#104-traceability-how-to-audit-a-retained-block","title":"10.4 Traceability (how to audit a retained block)","text":"<p>Because the map uses HEALPix NESTED ordering, each nside=64 parent block corresponds to a contiguous range of 256 nside=1024 child pixels. For a retained parent with index p, the child range is [256p, 256p+255]. This makes backward traces compact and exact.</p> <p>Example: a compact backward trace for an aggregated HEALPix block</p>"},{"location":"handbook/#105-stability-packet-retaintarget-sweep","title":"10.5 Stability packet (retain\u2011target sweep)","text":"<p>Table 10\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 10\u2011D. Active\u2011set overlap (Jaccard) between sweep points</p> <p>Table 10\u2011E. Regime ranking stability (faces) across sweep points</p>"},{"location":"handbook/#106-what-this-run-teaches-and-what-it-does-not","title":"10.6 What this run teaches (and what it does not)","text":"<ul> <li> <p>HUF can reduce 49,152 coarse blocks to ~18k while retaining 97% pixel-basis energy, with exact accounting.</p> </li> <li> <p>Per-regime views (faces) remain stable across threshold sweeps: the \u2018where\u2019 of energy is robust.</p> </li> <li> <p>The discard fraction is a quantitative error bound under the declared reconstruction.</p> </li> <li> <p>This is not cosmological inference. HUF is an auditable reduction layer; domain science still happens above it.</p> </li> </ul>"},{"location":"handbook/#11-case-study-b-city-of-markham-2018-budget-civic-layers","title":"11. Case Study B \u2014 City of Markham (2018 budget + civic layers)","text":"<p>This case demonstrates mass/weight HUF on municipal public data. The conserved quantity is money. Primary budget workbook: 2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx (values in $000). We focus on expenditures (the allocation of outgoing funds), then show a propagation example onto wards using census population as a proxy.</p>"},{"location":"handbook/#111-data-inventory-what-we-used","title":"11.1 Data inventory (what we used)","text":"<ul> <li> <p>2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx \u2014 fund-level revenues/expenditures by category.</p> </li> <li> <p>2018-Operating-Budget-by-Account.xlsx \u2014 operating revenue/expense categories and year comparisons.</p> </li> <li> <p>2016-Tax-Rates.xlsx and 2018-Tax-Rates.xlsx \u2014 rate context (not used as budget, used for narrative checks).</p> </li> <li> <p>GIS layers: WARD.geojson, Parks.geojson, Fire_Stations.geojson, City_Facilities.geojson (used for a propagation demo).</p> </li> <li> <p>Census DA layer (Age/Sex) for Markham \u2014 used only to compute ward population shares (proxy).</p> </li> </ul>"},{"location":"handbook/#112-budget-declaration-and-finite-elements","title":"11.2 Budget declaration and finite elements","text":"<p>Global budget: total 2018 expenditures across all funds = 456,171 ($000). Unity budget is \u2018share of total expenditures\u2019.</p> <p>Finite element for the primary run: (Fund \u00d7 ExpenditureCategory). Regimes: Funds. This gives a clean \u2018where does the city spend money\u2019 decomposition.</p>"},{"location":"handbook/#113-primary-run-results-fundcategory","title":"11.3 Primary run results (Fund\u00d7Category)","text":"<p>Retain target: 0.97. Outcome: K = 23 retained elements out of 67. Threshold \u03c4 = 0.004. Retained = 0.9710; discarded = 0.0290.</p> <p>Figure 5. Markham 2018 expenditures \u2014 global retained vs discarded budget share.</p> <p>Figure 6. Markham 2018 expenditures \u2014 per-fund unity bars (funds as regimes).</p> <p>Figure 7. Markham 2018 expenditures \u2014 active-set growth curve (Fund\u00d7Category).</p> <p>Table 11\u2011A. Fund regimes: totals and global shares</p> <p>Table 11\u2011B. Largest spending contributors (Fund\u00d7Category)</p>"},{"location":"handbook/#114-stability-packet","title":"11.4 Stability packet","text":"<p>Table 11\u2011C. Sweep points (target \u2192 K, \u03c4)</p> <p>Table 11\u2011D. Active-set overlap (Jaccard) across sweep points</p>"},{"location":"handbook/#115-backward-trace-example-auditing-a-spending-line","title":"11.5 Backward trace example (auditing a spending line)","text":"<p>In this run, the backward trace is trivial but non\u2011negotiable: each retained element points back to a specific worksheet row/column (Fund, Category, cell location) plus workbook hash. If you can\u2019t point to the cell, you can\u2019t claim the number.</p> <p>Example: backward trace record for a budget line</p>"},{"location":"handbook/#116-propagation-demo-operating-fund-to-wards-proxy-allocation","title":"11.6 Propagation demo \u2014 Operating Fund to wards (proxy allocation)","text":"<p>This section demonstrates propagation constraints on civic geography. We do NOT claim this is the real ward budget \u2014 the city budget is not ward\u2011allocated in this dataset. We demonstrate a conservative, auditable proxy mapping.</p> <p>Propagation map: allocate Operating Fund expenditures to wards proportional to 2016 census population share. This is admissible as a mapping only if it is declared as a proxy, conservative (sums match), and traceable.</p> <p>Figure 8. Markham wards \u2014 population shares (proxy weights for propagation).</p> <p>Figure 9. Operating Fund propagated to wards \u2014 per-regime unity bars (retained vs discarded at target 0.97).</p> <p>Table 11\u2011E. Ward proxy table: population, facilities counts, and Operating Fund allocation ($M)</p> <p>Why include facilities counts? Not as causal claims \u2014 as audit context. They provide additional regimes for future propagation (e.g., allocate a parks-maintenance budget proportional to park count or area). Any such mapping must be declared and tested for stability.</p>"},{"location":"handbook/#117-what-dominates-and-what-to-do-next","title":"11.7 What dominates and what to do next","text":"<p>The Fund\u00d7Category decomposition typically reveals (a) how concentrated spending is, (b) whether one fund dominates the budget narrative, and (c) which categories are \u2018structural\u2019 versus \u2018tail.\u2019 This run is a starting point.</p> <ul> <li> <p>Next expansion: link operating categories to performance measures (if definitions match).</p> </li> <li> <p>Next expansion: add revenues as a parallel budget and compare structural mismatch (revenue concentration vs expenditure concentration).</p> </li> <li> <p>Next expansion: incorporate capital project lists and apply HUF to project portfolios (true finite elements with trace to project IDs).</p> </li> </ul>"},{"location":"handbook/#12-case-study-c-traffic-signal-telemetry-anomaly-localization-template","title":"12. Case Study C \u2014 Traffic signal telemetry (anomaly localization template)","text":"<p>This case shows how HUF behaves on operational event streams. The goal is not \u2018compress for beauty\u2019 \u2014 it is: what dominates anomalies, and where should you look first?</p>"},{"location":"handbook/#121-finite-element-and-budget-definition-recommended","title":"12.1 Finite element and budget definition (recommended)","text":"<p>Recommended finite element for anomaly work: Finite element = TCS \u00d7 PHASE \u00d7 PHASE_STATUS_TEXT (optionally \u00d7 PHASE_CALL_TEXT) Budget = event share or severity\u2011weighted share (declare weights) Output = which intersections/phases dominate drops/terminations/clearance with full trace to raw rows.</p> <p>In this run we define a simple severity budget: Dropped calls weight 3, Termination statuses weight 2, everything else weight 1, then restrict the anomaly view to rows with severity &gt; 1.</p>"},{"location":"handbook/#122-compressed-phase-activity-distribution-what-dominates-anomalies","title":"12.2 Compressed phase activity distribution (what dominates anomalies)","text":"<p>Figure 10. Traffic telemetry \u2014 anomaly severity budget by intersection (top contributors).</p> <p>Figure 11. Traffic telemetry \u2014 anomaly severity budget by phase.</p> <p>Figure 12. Traffic telemetry \u2014 anomaly severity budget by status.</p> <p>Table 12\u2011A. Top intersections by anomaly severity budget share</p> <p>Table 12\u2011B. Phases dominating the anomaly budget</p> <p>Table 12\u2011C. Status distribution within anomaly budget</p>"},{"location":"handbook/#123-traceability-and-actionability","title":"12.3 Traceability and actionability","text":"<p>A practical HUF anomaly run ends with a short, actionable list: top intersections, top phases, and the raw event rows supporting them. Backward traces should include timestamp ranges and source row IDs so an engineer can replay the evidence.</p> <ul> <li> <p>If one intersection dominates: inspect controller configuration and detector health first.</p> </li> <li> <p>If one phase dominates across many intersections: inspect phase timing policy or coordination logic.</p> </li> <li> <p>If one status dominates: inspect the semantic definition (what exactly triggers \u2018Termination\u2019 in your system).</p> </li> </ul>"},{"location":"handbook/#part-iii-implementation-extension-and-training","title":"Part III \u2014 Implementation, extension, and training","text":""},{"location":"handbook/#13-reference-implementation-patterns","title":"13. Reference implementation patterns","text":"<p>A handbook is useless if it can\u2019t be implemented. This section defines the minimal architecture that prevents HUF from collapsing back into prose.</p> <ul> <li> <p>Core data model: Element(id, rho, regime_path, trace).</p> </li> <li> <p>Adapters: domain-specific loaders and propagators that output the same element schema.</p> </li> <li> <p>I/O: artifact writers (CSV/JSON) that always include run stamps and file hashes.</p> </li> <li> <p>Tests: each reference run must have an automated test that checks unity, artifact emission, and stability packet generation.</p> </li> </ul> <p>Listing 13\u2011A. Reference core (excerpt, huf_core/core.py)</p> <p>(Full source is intended for the accompanying repository/package; this excerpt is included for handbook completeness.)</p>"},{"location":"handbook/#14-how-huf-prunes-itself-expansion-contraction-as-a-method","title":"14. How HUF prunes itself (expansion \u2192 contraction as a method)","text":"<p>The development history that produced this handbook is not a shameful detour \u2014 it is the method. You expand to explore, then you contract to ship. HUF applies to itself:</p> <ol> <li> <p>Expansion phase: explore candidate operations, artifacts, and narratives to discover what actually matters in practice.</p> </li> <li> <p>Contraction phase: declare the contract, delete optionality from the core, and move everything else into extensions.</p> </li> <li> <p>Stability phase: treat the framework definition as a system under HUF \u2014 track which sections survive pruning across reviewer critiques.</p> </li> </ol> <p>A useful internal exercise: assign a unity budget to sections of your draft (by reader time, by risk, or by implementation cost), then run HUF to see which sections dominate confusion or contribute little. That is \u2018HUF on HUF.\u2019</p>"},{"location":"handbook/#15-training-exercises-from-toy-to-real","title":"15. Training exercises (from toy to real)","text":"<p>Exercises are designed to build the habit of declaring budgets, regimes, and traces before you compute.</p> <ol> <li> <p>Take any spreadsheet with line items. Define finite elements and a mass budget. Produce the four artifacts.</p> </li> <li> <p>Repeat with two regime partitions (by department vs by fund). Compare regime stability across thresholds.</p> </li> <li> <p>Take an event log. Define anomaly budget weights. Produce a top\u2011N actionable list with backward traces to row IDs.</p> </li> <li> <p>Design a propagation map (e.g., cost \u2192 ward) and prove conservation + traceability in one paragraph.</p> </li> <li> <p>Perform a stability sweep and write the two-sentence interpretation of the stability packet.</p> </li> </ol>"},{"location":"handbook/#appendix-a-data-samples-print-friendly-excerpts","title":"Appendix A \u2014 Data samples (print-friendly excerpts)","text":"<p>A1. Planck sample (first 5 coarse blocks; energies are in I\u00b2 units)</p> <p>A2. Markham sample (top 10 Fund\u00d7Category elements)</p> <p>A3. Traffic sample (first 12 telemetry rows; severity weights shown)</p>"},{"location":"handbook/#appendix-b-artifact-checklists-what-a-reviewer-will-ask-for","title":"Appendix B \u2014 Artifact checklists (what a reviewer will ask for)","text":"<ul> <li> <p>Unity checks: global \u03a3\u03c1=1.0 after every normalization and renormalization step (log the tolerance).</p> </li> <li> <p>Discard ledger: list of excluded elements with their \u03c1; discarded sum must match 1\u2212retained.</p> </li> <li> <p>Trace completeness: every retained element has a backward trace to finite elements (no null traces).</p> </li> <li> <p>Stability packet: sweep points, overlap metrics, regime rank stability, near\u2011\u03c4 band.</p> </li> <li> <p>Repro stamp: file hashes, code version, run_id, parameters (\u03c4/target, seeds).</p> </li> </ul>"},{"location":"handbook/#appendix-c-glossary-minimal","title":"Appendix C \u2014 Glossary (minimal)","text":"<p>Glossary</p>"},{"location":"handbook/#appendix-d-reproducibility-stamps-recommended-minimum","title":"Appendix D \u2014 Reproducibility stamps (recommended minimum)","text":"<p>Run stamp</p>"},{"location":"jupyter_demos/","title":"Jupyter demos (optional)","text":"<p>Jupyter is optional. It\u2019s useful when you want to read and summarize artifacts interactively.</p>"},{"location":"jupyter_demos/#install-launch-windows-powershell","title":"Install + launch (Windows PowerShell)","text":"<pre><code>.\\.venv\\Scripts\\python -m pip install notebook pandas\n.\\.venv\\Scripts\\python -m notebook\n</code></pre> <p>A browser window opens. Create a new notebook (Python).</p>"},{"location":"jupyter_demos/#important-powershell-is-not-python","title":"Important: PowerShell is not Python","text":"<p>If you type <code>import pandas as pd</code> at a PowerShell prompt, it will fail.</p> <p>Run Python code: - in a notebook cell, or - inside <code>python</code> interactive (<code>.\\.venv\\Scripts\\python</code>), or - from a script file.</p>"},{"location":"jupyter_demos/#suggested-notebook-pattern","title":"Suggested notebook pattern","text":""},{"location":"jupyter_demos/#cell-1-run-a-case-cli","title":"Cell 1 \u2014 run a case (CLI)","text":"<pre><code>import subprocess, sys\nsubprocess.check_call([sys.executable, \"-m\", \"huf_core.cli\", \"--help\"])\n</code></pre> <p>(Or just run the case in PowerShell first, then open artifacts in the next cells.)</p>"},{"location":"jupyter_demos/#cell-2-open-artifacts-markham","title":"Cell 2 \u2014 open artifacts (Markham)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/markham2018/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/markham2018/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(10)\n</code></pre>"},{"location":"jupyter_demos/#cell-3-how-many-items-cover-90","title":"Cell 3 \u2014 \u201chow many items cover 90%?\u201d","text":"<pre><code>active[\"cum\"] = active[\"rho_global_post\"].cumsum()\nactive.loc[active[\"cum\"] &gt;= 0.90, [\"rank\",\"item_id\",\"cum\"]].head(1)\n</code></pre>"},{"location":"jupyter_demos/#cell-4-open-artifacts-traffic-phase","title":"Cell 4 \u2014 open artifacts (Traffic Phase)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/traffic_phase/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/traffic_phase/artifact_2_active_set.csv\").sort_values(\"rank\")\n\ncoh.sort_values(\"rho_global_post\", ascending=False).head(15)\n</code></pre>"},{"location":"jupyter_demos/#export","title":"Export","text":"<p>You can export notebooks to HTML/PDF from the Jupyter UI (File \u2192 Download).</p>"},{"location":"learning_path/","title":"Learning path","text":"<p>HUF is easiest to learn by running a case, then reading the artifacts it produces.</p> <p>This path is designed so the left sidebar is a \u201cdo-this-next\u201d guide.</p> <p>If you\u2019re on Windows</p> <p>Always prefer the repo\u2019s venv when running tools:</p> <pre><code>.\\.venv\\Scripts\\python -m mkdocs serve\n.\\.venv\\Scripts\\python scripts\\fetch_data.py --markham --toronto --yes\n.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"learning_path/#step-1-install-first-run","title":"Step 1 \u2014 Install + first run","text":"<ul> <li>Start here (developer): Start Here \u2192 Developer</li> <li>Start here (beginner): Start Here \u2192 Zero GitHub knowledge</li> </ul> <p>Goal: you can run <code>huf --help</code> and produce an <code>out/.../run_stamp.json</code>.</p>"},{"location":"learning_path/#step-2-run-the-two-core-cases","title":"Step 2 \u2014 Run the \u201ctwo core\u201d cases","text":"<ol> <li>Markham (budget allocation) \u2192 then read:</li> <li> <p>Cases \u2192 Markham worked example</p> </li> <li> <p>Traffic Phase (signal phases) \u2192 then read:</p> </li> <li>Cases \u2192 Traffic phase worked example</li> </ol> <p>These two are the best introductions to how HUF turns a raw table into: - a coherence map (regimes), - an active set (retained items), - and a trace report (auditable, line-by-line).</p>"},{"location":"learning_path/#step-3-try-an-adapter-style-use-case","title":"Step 3 \u2014 Try an adapter-style use case","text":"<ul> <li>Adapters \u2192 Vector DB coherence</li> </ul> <p>This shows how HUF can \u201cexplain\u201d retrieval results by grouping where the score mass comes from (namespaces, sources, etc.) and what gets excluded by <code>tau_global</code>.</p>"},{"location":"learning_path/#step-4-optional-big-data-scientific-demo","title":"Step 4 \u2014 Optional: big-data / scientific demo","text":"<ul> <li>Planck LFI70 (optional): see Start Here \u2192 Developer (Planck section)</li> </ul>"},{"location":"learning_path/#step-5-optional-notebooks","title":"Step 5 \u2014 Optional: notebooks","text":"<ul> <li>Jupyter demos (optional)</li> </ul> <p>If you want plots + interactive exploration, notebooks are a nice fit.</p>"},{"location":"markham_worked_example/","title":"Markham worked example (2018 budget)","text":"<p>\u2190 Back to Cases</p> <p>This page walks through a full, reproducible analysis using the bundled workbook:</p> <p><code>cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></p> <p>Goal: show what HUF reveals that a normal \u201csum + chart\u201d spreadsheet workflow usually hides: concentration, tail mass, stable regime structure, and cell-level provenance.</p>"},{"location":"markham_worked_example/#1-run-it","title":"1) Run it","text":"<p>Windows PowerShell (from repo root): <pre><code>huf markham --xlsx cases\\markham2018\\inputs\\2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out\\markham2018\n</code></pre></p> <p>You should see something like: - <code>active_set=24</code> - <code>coherence_rows=6</code> - <code>discarded_global\u22480.029</code></p>"},{"location":"markham_worked_example/#2-whats-in-the-input","title":"2) What\u2019s in the input","text":"<p>The adapter reads a simple fund \u00d7 account block from the workbook (units: k$): - accounts: rows 18\u201338 - funds: columns 1\u20136 - blanks / zeros are dropped</p> <p>For the shipped workbook, HUF finds: - 67 non-zero cells (elements) - total value in the selected block: 456,172 k$ (\u2248 $456.2M)</p>"},{"location":"markham_worked_example/#3-the-coherence-map-fund-level-regimes","title":"3) The coherence map (fund-level regimes)","text":"<p>Open: - <code>out/markham2018/artifact_1_coherence_map.csv</code></p> <p>This answers: which funds dominate the retained budget, and how much tail mass got dropped.</p> <p>Totals (k$):</p> Fund (regime) Pre total (k$) Discarded (k$) Retained (k$) Share of retained Fund=Operating Fund 218483 10874 207609 0.4687 Fund=Waterworks/Stabilization Capital Reserve 131634 1692 129942 0.2934 Fund=Capital Development Fund 77715 0 77715 0.1754 Fund=Planning &amp; Design 10295 177 10118 0.0228 Fund=Building Fee 9957 200 9757 0.022 Fund=Engineering 8088 277 7811 0.0176 <p>Interpretation: - \u201cShare of retained\u201d sums to 1.0 (unity budget after compression). - \u201cDiscarded (k$)\u201d is what was below the global/local thresholds inside that fund. - Here, the Operating Fund carries the biggest within-fund tail (\u2248 5.0% of its pre-mass is discarded).</p>"},{"location":"markham_worked_example/#4-the-active-set-account-level-winners","title":"4) The active set (account-level winners)","text":"<p>Open: - <code>out/markham2018/artifact_2_active_set.csv</code></p> <p>This answers: which line-items explain most of the budget, globally and within each fund.</p> <p>Top items (k$):</p> Rank Fund (regime) Account Retained (k$) Share of retained Share within fund 1 Operating Fund Salaries &amp; Benefits 131828 0.2976 0.635 2 Waterworks/Stabilization Capital Reserve Contracted Municipal Services 100989 0.228 0.7772 3 Capital Development Fund Capital Expenditures 77715 0.1754 1 4 Operating Fund Transfers to Reserves 28756 0.0649 0.1385 5 Waterworks/Stabilization Capital Reserve Transfers to Reserves 15281 0.0345 0.1176 6 Operating Fund Contracted Municipal Services 11167 0.0252 0.0538 7 Operating Fund Utilities 9121 0.0206 0.0439 8 Waterworks/Stabilization Capital Reserve Salaries &amp; Benefits 7729 0.0174 0.0595 9 Planning &amp; Design Salaries &amp; Benefits 6851 0.0155 0.6771 10 Operating Fund Maintenance &amp; Repair 6848 0.0155 0.033 11 Operating Fund Contracts &amp; Service Agreements 6707 0.0151 0.0323 12 Building Fee Salaries &amp; Benefits 6076 0.0137 0.6227 <p>Two quick \u201chidden\u201d facts this makes obvious: - top 2 line-items cover 52.6% of the retained budget - top 3 cover 70.1% - it takes only 11 line-items to cover 90% of retained spend</p> <p>That\u2019s a concentration story you don\u2019t get from a typical workbook view unless you go hunting.</p>"},{"location":"markham_worked_example/#5-provenance-the-trace-report-the-why-chain","title":"5) Provenance: the trace report (the \u201cwhy\u201d chain)","text":"<p>Open: - <code>out/markham2018/artifact_3_trace_report.jsonl</code></p> <p>Each retained item includes the workbook pointer it came from (sheet + cell), so you can audit the pipeline end-to-end.</p> <p>Example (top 5):</p> Rank Fund (regime) Account Retained (k$) Share of retained Workbook cell 1 Operating Fund Salaries &amp; Benefits 131828 0.2976 B19 2 Waterworks/Stabilization Capital Reserve Contracted Municipal Services 100989 0.228 G34 3 Capital Development Fund Capital Expenditures 77715 0.1754 C37 4 Operating Fund Transfers to Reserves 28756 0.0649 B38 5 Waterworks/Stabilization Capital Reserve Transfers to Reserves 15281 0.0345 G38 <p>If something looks wrong, you can jump straight to those cells in Excel.</p>"},{"location":"markham_worked_example/#6-stability-how-sensitive-is-the-result","title":"6) Stability: how sensitive is the result?","text":"<p>Open: - <code>out/markham2018/stability_packet.csv</code></p> <p>This runs the same case across a few tau values and reports how much the answer changes.</p> tau_global active_count discarded_frac near_tau_count spearman_vs_base jaccard_vs_base 0.0025 30 0.01 2 1 1 0.005 24 0.029 4 1 0.8 0.0075 20 0.0522 1 1 0.667 0.01 20 0.0522 0 1 0.667 0.015 20 0.0522 3 1 0.667 <p>How to read it: - <code>discarded_frac</code> \u2191 means more aggressive pruning. - <code>jaccard_vs_base</code> close to 1.0 means \u201cmostly the same active set\u201d. - <code>near_tau_count</code> high means lots of elements hover around the cutoff (more sensitivity).</p>"},{"location":"markham_worked_example/#7-so-what-did-huf-reveal","title":"7) \u201cSo what did HUF reveal?\u201d","text":"<p>Here\u2019s the story for this workbook:</p> <p>1) Budget mass is extremely concentrated.    A small number of accounts explain most of the retained spend.</p> <p>2) Different funds have different tail behavior.    The Operating Fund sheds the most tail (small accounts below thresholds) while the Capital Development Fund is essentially a single dominant line item.</p> <p>3) Everything is auditable.    The trace report points back to the original spreadsheet cells, so the compression is inspectable, not a black box.</p>"},{"location":"markham_worked_example/#8-explore-further-copypaste","title":"8) Explore further (copy/paste)","text":"<pre><code>import pandas as pd\n\ncoh = pd.read_csv(\"out/markham2018/artifact_1_coherence_map.csv\")\nactive = pd.read_csv(\"out/markham2018/artifact_2_active_set.csv\").sort_values(\"rank\")\n\n# Which funds dominate?\nprint(coh[[\"regime_id\",\"rho_global_post\",\"rho_discarded_pre\"]].sort_values(\"rho_global_post\", ascending=False))\n\n# How many items cover 90%?\nactive[\"cum\"] = active[\"rho_global_post\"].cumsum()\nprint(active.loc[active[\"cum\"] &gt;= 0.90, [\"rank\",\"item_id\",\"cum\"]].head(1))\n\n# Top 10 line-items (global + within-fund shares)\nprint(active.head(10)[[\"rank\",\"regime_id\",\"item_id\",\"value\",\"rho_global_post\",\"rho_local_post\"]])\n</code></pre>"},{"location":"markham_worked_example/#links","title":"Links","text":"<ul> <li>Input workbook: <code>cases/markham2018/inputs/...xlsx</code> (bundled)</li> <li>Case folder (GitHub): https://github.com/PeterHIggins19/huf_core_github_v1.1.8_no_inputs/tree/main/cases/markham2018</li> </ul>"},{"location":"planck/","title":"Planck (LFI 70 GHz) demo","text":"<p>This case demonstrates HUF on a very large HEALPix all\u2011sky map (Planck PR3, LFI 70 GHz). The demo produces the standard HUF artifacts (coherence map, active set, trace report, error budget) so you can inspect what HUF retained vs. discarded at the chosen retained\u2011target.</p> <p>Why this is not auto-downloaded</p> <p>The Planck FITS file is large (~480\u2013500 MB) and some users prefer downloading from ESA\u2019s Planck Legacy Archive vs NASA/IPAC IRSA.</p>"},{"location":"planck/#1-get-the-fits-input","title":"1) Get the FITS input","text":"<p>Expected path in this repo:</p> <pre><code>cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\n</code></pre>"},{"location":"planck/#option-a-recommended-on-windows-bits-download","title":"Option A (recommended on Windows): BITS download","text":"<pre><code>$dest = Join-Path $PWD \"cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits\"\nNew-Item -ItemType Directory -Force (Split-Path $dest) | Out-Null\n$src  = \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\nStart-BitsTransfer -Source $src -Destination $dest\n</code></pre>"},{"location":"planck/#option-b-curlwget","title":"Option B: curl/wget","text":"<pre><code>curl -L -o \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\"   \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\n</code></pre> <p>Windows PowerShell curl alias</p> <p>In Windows PowerShell, <code>curl</code> is an alias for <code>Invoke-WebRequest</code>. Use <code>curl.exe</code> (or use BITS above):</p> <pre><code>curl.exe -L -o \"cases/planck70/inputs/LFI_SkyMap_070_1024_R3.00_full.fits\"       \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\n</code></pre> <p>Preview page (manual download button):</p> <ul> <li>https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/previews/LFI_SkyMap_070_1024_R3.00_full/index.html</li> </ul>"},{"location":"planck/#2-install-planck-extras","title":"2) Install Planck extras","text":"<p>If you are using the repo venv:</p> <pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n</code></pre>"},{"location":"planck/#3-run-the-demo","title":"3) Run the demo","text":"<pre><code>.\\.venv\\Scripts\\huf planck `\n  --fits cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits `\n  --out out\\planck70 `\n  --retained-target 0.97 `\n  --nside-out 64\n</code></pre>"},{"location":"planck/#4-read-the-artifacts","title":"4) Read the artifacts","text":"<p>The output folder contains:</p> <ul> <li><code>artifact_1_coherence_map.csv</code> \u2014 regimes and their retained mass/energy (post\u2011filter)</li> <li><code>artifact_2_active_set.csv</code> \u2014 the retained items (ranked)</li> <li><code>artifact_3_trace_report.jsonl</code> \u2014 what changed across the pass (debug/audit)</li> <li><code>artifact_4_error_budget.json</code> \u2014 global + local discard summary</li> <li><code>run_stamp.json</code>, <code>meta.json</code></li> </ul>"},{"location":"planck/#quick-inspection-no-notebooks-required","title":"Quick inspection (no notebooks required)","text":"<pre><code>.\\.venv\\Scripts\\python - &lt;&lt;'PY'\nimport pandas as pd\ncoh = pd.read_csv('out/planck70/artifact_1_coherence_map.csv')\nact = pd.read_csv('out/planck70/artifact_2_active_set.csv').sort_values('rank')\nprint('\nTop regimes by rho_global_post:')\nprint(coh.sort_values('rho_global_post', ascending=False).head(10).to_string(index=False))\nprint('\nTop 10 retained items:')\nprint(act[['rank','regime_id','item_id','value','rho_global_post','rho_local_post']].head(10).to_string(index=False))\nPY\n</code></pre> <p>What to look for</p> <ul> <li>If one regime dominates the coherence map, it\u2019s a sign the retained budget is concentrated.</li> <li>If you want more/less sparsity, adjust <code>--retained-target</code> or <code>--nside-out</code>.</li> </ul>"},{"location":"quick_run/","title":"Quick Run (copy/paste)","text":"<p>Goal: create a local <code>.venv</code>, fetch inputs, and run the included demos.</p> <p>Run these commands from the repo root (the folder that contains <code>pyproject.toml</code>).</p>"},{"location":"quick_run/#windows-powershell","title":"Windows (PowerShell)","text":""},{"location":"quick_run/#1-bootstrap-install","title":"1) Bootstrap + install","text":"<pre><code>python scripts\\bootstrap.py\n.\\.venv\\Scripts\\python -m pip install -e .\n</code></pre>"},{"location":"quick_run/#2-fetch-markham-toronto-inputs","title":"2) Fetch Markham + Toronto inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"quick_run/#3-run-the-demos","title":"3) Run the demos","text":"<pre><code>.\\.venv\\Scripts\\huf markham `\n  --xlsx cases\\markham2018\\inputs\\2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx `\n  --out out\\markham2018\n\n.\\.venv\\Scripts\\huf traffic `\n  --csv cases\\traffic_phase\\inputs\\toronto_traffic_signals_phase_status.csv `\n  --out out\\traffic_phase\n\n.\\.venv\\Scripts\\huf traffic-anomaly `\n  --csv cases\\traffic_anomaly\\inputs\\toronto_traffic_signals_phase_status.csv `\n  --out out\\traffic_anomaly `\n  --status \"Green Termination\" `\n  --tau-global 0.0005\n</code></pre>"},{"location":"quick_run/#4-optional-planck-fits-is-large","title":"4) Optional: Planck (FITS is large)","text":"<p>Install FITS support: <pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n</code></pre></p> <p>Download the repo\u2019s example FITS to the expected path (resume-friendly): <pre><code>$dest = \"cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits\"\nNew-Item -ItemType Directory -Force (Split-Path $dest) | Out-Null\n$src  = \"https://irsa.ipac.caltech.edu/data/Planck/release_3/all-sky-maps/maps/LFI_SkyMap_070_1024_R3.00_full.fits\"\nStart-BitsTransfer -Source $src -Destination $dest\n</code></pre></p> <p>Run: <pre><code>.\\.venv\\Scripts\\huf planck `\n  --fits cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits `\n  --out out\\planck70 `\n  --retained-target 0.97 `\n  --nside-out 64\n</code></pre></p>"},{"location":"quick_run/#macos-linux-bashzsh","title":"macOS / Linux (bash/zsh)","text":""},{"location":"quick_run/#1-bootstrap-install_1","title":"1) Bootstrap + install","text":"<pre><code>python3 scripts/bootstrap.py\n./.venv/bin/python -m pip install -e .\n</code></pre>"},{"location":"quick_run/#2-fetch-markham-toronto-inputs_1","title":"2) Fetch Markham + Toronto inputs","text":"<pre><code>./.venv/bin/python scripts/fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"quick_run/#3-run-the-demos_1","title":"3) Run the demos","text":"<pre><code>./.venv/bin/huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n./.venv/bin/huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n./.venv/bin/huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"quick_run/#makefile-optional-convenience","title":"Makefile (optional convenience)","text":"<p>If you have <code>make</code> installed: <pre><code>make fetch-data\n</code></pre></p>"},{"location":"quick_run/#output-sanity-check","title":"Output sanity check","text":"<p>Each run writes artifacts to your <code>--out</code> folder, including: - <code>artifact_1_coherence_map.csv</code> - <code>artifact_2_active_set.csv</code> - <code>artifact_3_trace_report.jsonl</code> - <code>artifact_4_error_budget.json</code> - <code>run_stamp.json</code>, <code>meta.json</code>, <code>stability_packet.csv</code></p>"},{"location":"reference_manual/","title":"HUF Reference Manual","text":"<p>Updated: 2026-02-17</p> <p>This manual is the \u201chow to run it\u201d companion to the handbook. It\u2019s written for: - GUI-only users (download a ZIP, double-click a Windows starter), - researchers who live in Excel + theory, and - anyone who wants reproducible artifacts without learning Git on day one.</p>"},{"location":"reference_manual/#1-quick-start-windows-no-git-required","title":"1) Quick Start (Windows, no Git required)","text":""},{"location":"reference_manual/#option-a-easiest-github-release-zip","title":"Option A \u2014 easiest: GitHub Release ZIP","text":"<ol> <li>Open the project Release page on GitHub and download the ZIP (the asset attached to the release).</li> <li>Unzip it somewhere simple (Desktop is fine).</li> <li>Double-click: <code>START_HERE_WINDOWS.bat</code></li> </ol> <p>What it does: - creates a local virtual environment in <code>.venv</code> - installs HUF in editable mode (local) - fetches Markham + Toronto civic inputs automatically - prints the exact commands to run the demos</p> <p>Tip: If Windows shows a security warning the first time, click \u201cMore info\u201d \u2192 \u201cRun anyway\u201d.</p>"},{"location":"reference_manual/#option-b-github-desktop-recommended-once-youre-comfortable","title":"Option B \u2014 GitHub Desktop (recommended once you\u2019re comfortable)","text":"<p>Use GitHub Desktop to keep your folder synced with GitHub. Day-to-day: - Fetch checks for updates. - Pull downloads updates. - Commit records your changes. - Push/Sync uploads your changes.</p>"},{"location":"reference_manual/#2-fetching-input-data-real-public-sources","title":"2) Fetching input data (real public sources)","text":"<p>Run these from the repo root (the folder that contains <code>pyproject.toml</code>).</p>"},{"location":"reference_manual/#markham-2018-budget-allocation-xlsx","title":"Markham (2018 Budget Allocation XLSX)","text":"<p><pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --markham\n</code></pre> Expected file: - <code>cases\\markham2018\\inputs\\2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx</code></p>"},{"location":"reference_manual/#toronto-traffic-signals-timing-csv","title":"Toronto (Traffic signals timing \u2192 CSV)","text":"<p>Non-interactive default selection: <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --toronto --yes\n</code></pre></p> <p>Interactive mode (lets you choose among matching datasets): <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --toronto\n</code></pre></p> <p>Expected files: - <code>cases\\traffic_phase\\inputs\\toronto_traffic_signals_phase_status.csv</code> - <code>cases\\traffic_anomaly\\inputs\\toronto_traffic_signals_phase_status.csv</code></p> <p>Toronto schema expected by HUF traffic adapters: - required: <code>TCS</code>, <code>PHASE</code> - optional: <code>PHASE_STATUS_TEXT</code>, <code>PHASE_CALL_TEXT</code></p>"},{"location":"reference_manual/#planck-guidedmanual","title":"Planck (guided/manual)","text":"<p>Planck maps are large; users often want to choose PLA vs IRSA mirrors and which products to pull.</p> <p>Guidance: <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --planck-guide\n</code></pre></p> <p>You\u2019ll end up with a FITS file such as: - <code>cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits</code></p>"},{"location":"reference_manual/#3-running-the-included-cases","title":"3) Running the included cases","text":""},{"location":"reference_manual/#a-markham-2018-fund-weighted-expenditures","title":"A) Markham 2018 (fund-weighted expenditures)","text":"<pre><code>.\\.venv\\Scripts\\huf markham ^\n  --xlsx cases\\markham2018\\inputs\\2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx ^\n  --out out\\markham2018\n</code></pre> <p>What you should see: - <code>out\\markham2018\\run_stamp.json</code> - <code>out\\markham2018\\artifacts\\markham_fund_weights.png</code> - tabular artifacts suitable for Excel inspection</p> <p>Open the image to sanity-check weights: - <code>docs\\assets\\markham_fund_weights.png</code></p>"},{"location":"reference_manual/#b-toronto-traffic-phase-band-extraction","title":"B) Toronto traffic phase (band extraction)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic ^\n  --csv cases\\traffic_phase\\inputs\\toronto_traffic_signals_phase_status.csv ^\n  --out out\\traffic_phase\n</code></pre> <p>Key outputs: - normalized element table - UBH artifacts and stability packet</p>"},{"location":"reference_manual/#c-toronto-traffic-anomaly-share-hotspots","title":"C) Toronto traffic anomaly (share + hotspots)","text":"<pre><code>.\\.venv\\Scripts\\huf traffic-anomaly ^\n  --csv cases\\traffic_anomaly\\inputs\\toronto_traffic_signals_phase_status.csv ^\n  --out out\\traffic_anomaly\n</code></pre> <p>Sanity-check visualization: - <code>docs\\assets\\traffic_anomaly_share.png</code></p>"},{"location":"reference_manual/#d-planck-70-ghz-map-coherence-stability","title":"D) Planck 70 GHz (map \u2192 coherence \u2192 stability)","text":"<pre><code>.\\.venv\\Scripts\\huf planck ^\n  --fits cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits ^\n  --out out\\planck70\n</code></pre> <p>Expect: - coherence maps and stability sweep artifacts in <code>out\\planck70\\artifacts\\...</code> - (optionally) a stability sweep report describing retained set vs \u03c4</p>"},{"location":"reference_manual/#4-understanding-run_stampjson-your-reproducibility-receipt","title":"4) Understanding <code>run_stamp.json</code> (your reproducibility receipt)","text":"<p>HUF writes a stamp like: <pre><code>{\n  \"dataset_id\": \"...\",\n  \"code_hash\": \"...\",\n  \"param_hash\": \"...\",\n  \"created_utc\": \"...\",\n  \"run_id\": \"...\"\n}\n</code></pre></p> <p>Interpretation: - <code>dataset_id</code> \u2014 identifier derived from the input file(s) (so you can prove what data you ran) - <code>code_hash</code> \u2014 identifier for the code state that produced artifacts - <code>param_hash</code> \u2014 identifier for your parameterization (\u03c4 grid, budgets, etc.) - <code>run_id</code> \u2014 unique run identifier (useful when repeating sweeps)</p> <p>If two runs have the same <code>dataset_id + code_hash + param_hash</code>, their artifacts should match (modulo timestamps).</p>"},{"location":"reference_manual/#5-troubleshooting-windows-focused","title":"5) Troubleshooting (Windows-focused)","text":""},{"location":"reference_manual/#ssl-certificate_verify_failed","title":"\u201cSSL: CERTIFICATE_VERIFY_FAILED\u201d","text":"<p>This is usually a Python installation / certificate store issue (common with very new Python builds or locked-down machines).</p> <p>Try: 1. Ensure you are using the repo venv Python:    <pre><code>.\\.venv\\Scripts\\python -V\n</code></pre> 2. Install certifi into the venv:    <pre><code>.\\.venv\\Scripts\\python -m pip install certifi\n</code></pre> 3. Re-run fetch:    <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --toronto --yes\n</code></pre></p> <p>If it still fails, your network may be intercepting TLS (corporate proxy). In that case, download the Toronto ZIP manually from the browser and place the extracted CSV into: - <code>cases\\traffic_phase\\inputs\\toronto_traffic_signals_phase_status.csv</code></p>"},{"location":"reference_manual/#http-error-404-during-toronto-fetch","title":"\u201cHTTP Error 404\u201d during Toronto fetch","text":"<p>This usually means the CKAN base URL is wrong. Use the default: - <code>https://open.toronto.ca/api/3/action</code></p> <p>You can override explicitly: <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --toronto --yes --toronto-ckan https://open.toronto.ca/api/3/action\n</code></pre></p>"},{"location":"reference_manual/#file-not-found-casesinputs","title":"\u201cFile not found \u2026 cases\\\u2026\\inputs\\\u2026\u201d","text":"<p>Run the fetch step first: <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --markham --toronto --yes\n</code></pre></p>"},{"location":"reference_manual/#6-where-is-that-file-on-github-finding-images-artifacts","title":"6) \u201cWhere is that file on GitHub?\u201d (finding images + artifacts)","text":"<p>Example file you asked about: <code>cases/markham2018/markham_fund_weights.png</code></p> <p>On GitHub.com: 1. Go to the repo home page 2. Click Code (file list) 3. Click cases 4. Click markham2018 5. Click markham_fund_weights.png</p> <p>You can also use GitHub\u2019s search box and type: <code>markham_fund_weights.png</code></p>"},{"location":"reference_manual/#7-data-sources-what-is-shipped-vs-fetched","title":"7) Data sources (what is shipped vs fetched)","text":"<p>See Data Sources in the docs navigation for: - Markham Open Data link(s) - Toronto Open Data link(s) - Planck PLA + IRSA links and \u201chow to pick the right file\u201d</p>"},{"location":"start_here/","title":"Start Here (Developer)","text":"<p>This page assumes you already have the repo locally (git clone or GitHub Desktop). Goal: get a working <code>.venv</code>, fetch inputs, run demos.</p> <p>Run commands from the repo root (folder containing <code>pyproject.toml</code>).</p>"},{"location":"start_here/#windows-powershell","title":"Windows (PowerShell)","text":""},{"location":"start_here/#create-venv-install","title":"Create venv + install","text":"<pre><code>python scripts\\bootstrap.py\n.\\.venv\\Scripts\\python -m pip install -e .\n</code></pre>"},{"location":"start_here/#ensure-the-venv-huf-wins-over-conda","title":"Ensure the venv <code>huf</code> wins over conda","text":"<pre><code>$env:Path = \"$PWD\\.venv\\Scripts;$env:Path\"\nhuf --help\n</code></pre>"},{"location":"start_here/#fetch-inputs","title":"Fetch inputs","text":"<pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --markham --toronto --yes\n</code></pre>"},{"location":"start_here/#run-demos","title":"Run demos","text":"<pre><code>huf markham --xlsx cases\\markham2018\\inputs\\2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out\\markham2018\nhuf traffic --csv cases\\traffic_phase\\inputs\\toronto_traffic_signals_phase_status.csv --out out\\traffic_phase\nhuf traffic-anomaly --csv cases\\traffic_anomaly\\inputs\\toronto_traffic_signals_phase_status.csv --out out\\traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"start_here/#planck-optional","title":"Planck (optional)","text":"<pre><code>.\\.venv\\Scripts\\python -m pip install astropy\n.\\.venv\\Scripts\\python scripts\\fetch_data.py --planck-guide\n# (place the FITS at cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits)\nhuf planck --fits cases\\planck70\\inputs\\LFI_SkyMap_070_1024_R3.00_full.fits --out out\\planck70 --retained-target 0.97 --nside-out 64\n</code></pre>"},{"location":"start_here/#macos-linux-bashzsh","title":"macOS / Linux (bash/zsh)","text":"<pre><code>python3 scripts/bootstrap.py\n./.venv/bin/python -m pip install -e .\n\n./.venv/bin/python scripts/fetch_data.py --markham --toronto --yes\n\n./.venv/bin/huf markham --xlsx cases/markham2018/inputs/2018-Budget-Allocation-of-Revenue-and-Expenditure-by-Fund.xlsx --out out/markham2018\n./.venv/bin/huf traffic --csv cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_phase\n./.venv/bin/huf traffic-anomaly --csv cases/traffic_anomaly/inputs/toronto_traffic_signals_phase_status.csv --out out/traffic_anomaly --status \"Green Termination\" --tau-global 0.0005\n</code></pre>"},{"location":"start_here/#makefile-optional-convenience","title":"Makefile (optional convenience)","text":"<p>If you have <code>make</code> installed (common on macOS/Linux): <pre><code>make fetch-data\n</code></pre></p>"},{"location":"theory_notes/","title":"Theory Notes (HUF / UBH)","text":"<p>Updated: 2026-02-17</p> <p>This repo is deliberately artifact-first: you can run real datasets and inspect outputs without accepting any theory claims.</p> <p>If you do want the formal structure (definitions, taxonomy, and expanded proofs), see:</p> <ul> <li><code>docs/The_Higgins_Unity_Framework.md</code> (full theoretical handbook)</li> <li>Handbook (conceptual + case-study narrative)</li> </ul>"},{"location":"theory_notes/#what-huf-is-in-one-paragraph","title":"What HUF is (in one paragraph)","text":"<p>HUF is a reproducibility wrapper around a single contract: a Unity\u2011Budgeted Hierarchy (UBH). A UBH is a hierarchy where each node\u2019s outgoing weights form a budgeted, normalized distribution (a \u201cunity\u201d constraint). HUF turns inputs into UBH elements, then emits auditable artifacts (tables, maps, images) plus a stability sweep that shows what structure survives across \u03c4.</p>"},{"location":"theory_notes/#why-unity-budget-matters","title":"Why \u201cunity budget\u201d matters","text":"<p>In practice, a unity budget behaves like a conserved quantity: - it forces competing explanations to share the same budget, - it makes comparisons across scales meaningful (local vs global), - it makes stability sweeps interpretable (what stays when \u03c4 tightens?).</p> <p>This was originally motivated by loudspeaker dispersion/diffraction work, but the same contract applies anywhere \u201cparts must sum to a whole\u201d.</p>"},{"location":"theory_notes/#proof-burden-and-how-huf-helps","title":"Proof burden and how HUF helps","text":"<p>HUF does not ask you to \u201cbelieve the proof.\u201d It asks you to: 1) run the same public dataset, 2) confirm you get the same artifacts, 3) inspect the stability packet, 4) only then argue about interpretation.</p> <p>That\u2019s why every run writes a <code>run_stamp.json</code>.</p>"},{"location":"traffic_phase_worked_example/","title":"Traffic Phase worked example (Toronto signals)","text":"<p>\u2190 Back to Cases</p> <p>This page is a guided artifact-reading flow for the Traffic Phase case:</p> <p><code>cases/traffic_phase/inputs/toronto_traffic_signals_phase_status.csv</code></p> <p>Goal: show what HUF reveals that a typical \u201ccount rows / pivot table\u201d workflow usually hides: a ranked, auditable \u201cwhere the mass is\u201d map, per-intersection signatures, and stable compression knobs (tau).</p>"},{"location":"traffic_phase_worked_example/#1-run-it","title":"1) Run it","text":"<p>Windows PowerShell (from repo root): <pre><code>huf traffic --csv cases\\traffic_phase\\inputs\\toronto_traffic_signals_phase_status.csv --out out\\traffic_phase\n</code></pre></p> <p>You should see something like: - <code>active_set\u22481312</code> - <code>coherence_rows\u2248851</code> - <code>discarded_global\u22480.001</code></p>"},{"location":"traffic_phase_worked_example/#2-whats-in-the-input","title":"2) What\u2019s in the input","text":"<p>HUF expects a Toronto traffic phase status CSV with at least: - <code>TCS</code> (signal controller / intersection id) - <code>PHASE</code> (phase number)</p> <p>For the shipped snapshot, the input contains: - 66,912 rows (observations) - 851 distinct <code>TCS</code> values (intersections)</p>"},{"location":"traffic_phase_worked_example/#3-what-the-adapter-does-finite-elements","title":"3) What the adapter does (finite elements)","text":"<p>The Traffic Phase adapter compresses raw rows into finite elements:</p> <ul> <li>Regime (group): <code>TCS=&lt;id&gt;</code> (one regime per intersection)</li> <li>Element (inside a regime): <code>PHASE_BAND=&lt;band&gt;</code></li> </ul> <p>Where <code>PHASE_BAND</code> is a deliberate, human-readable grouping:</p> <ul> <li><code>MajorEven(2,4,6,8)</code></li> <li><code>MinorOdd(1,3,5,7)</code></li> <li><code>Other(9-12)</code></li> </ul> <p>So each intersection becomes a 2\u20133 element \u201csignature vector\u201d:</p> <pre><code>TCS=&lt;id&gt;  -&gt;  [MajorEven share, MinorOdd share, Other share]\n</code></pre> <p>Why this is useful: - You can compare intersections on the same basis (a 3-number signature) - You can rank intersections by global mass (how much of the dataset they explain) - You can filter tiny within-intersection tails with <code>--tau-local</code></p>"},{"location":"traffic_phase_worked_example/#4-the-outputs-what-to-open-first","title":"4) The outputs (what to open first)","text":"<p>A run writes to <code>out/traffic_phase/</code>:</p> <p>1) <code>artifact_1_coherence_map.csv</code> Intersection ranking (one row per <code>TCS</code>) + discard reporting.</p> <p>2) <code>artifact_2_active_set.csv</code> Retained elements (per <code>TCS</code>, which bands survived tau, with local + global shares).</p> <p>3) <code>artifact_3_trace_report.jsonl</code> Provenance chain (item id \u2192 regime path \u2192 input fingerprint \u2192 method).</p> <p>4) <code>artifact_4_error_budget.json</code>    Single number summary: how much budget was discarded.</p> <p>5) <code>stability_packet.csv</code>    A small sweep showing how stable the result is as you change <code>tau</code>.</p>"},{"location":"traffic_phase_worked_example/#5-global-view-what-dominates-this-dataset","title":"5) Global view: what dominates this dataset?","text":""},{"location":"traffic_phase_worked_example/#51-phase-band-totals-simple-but-important","title":"5.1 Phase-band totals (simple, but important)","text":"<p>In the shipped snapshot, the raw rows split like this:</p> Phase band Rows Share MajorEven(2,4,6,8) 54,818 0.8193 MinorOdd(1,3,5,7) 11,298 0.1688 Other(9-12) 796 0.0119 <p>This baseline matters because it tells you what \u201cnormal\u201d looks like globally.</p>"},{"location":"traffic_phase_worked_example/#52-the-coherence-map-where-the-mass-is-by-intersection","title":"5.2 The coherence map = \u201cwhere the mass is\u201d (by intersection)","text":"<p>Open: - <code>out/traffic_phase/artifact_1_coherence_map.csv</code></p> <p>Top intersections by global retained share (shipped snapshot):</p> Rank Intersection (regime) Global share 1 TCS=619 0.005535 2 TCS=175 0.002513 3 TCS=25 0.002498 4 TCS=137 0.002424 5 TCS=440 0.002424 6 TCS=529 0.002349 7 TCS=320 0.002304 8 TCS=70 0.002304 9 TCS=750 0.002214 10 TCS=948 0.002184 <p>Interpretation: - Each <code>TCS=&lt;id&gt;</code> gets a slice of the global unity budget. - With 851 regimes, even the top one is only ~0.55% of the full dataset. - This ranking gives you a fast \u201caudit list\u201d: if you only have time to look at a few intersections, start at the top.</p>"},{"location":"traffic_phase_worked_example/#6-local-signatures-whats-unusual-at-an-intersection","title":"6) Local signatures: what\u2019s unusual at an intersection?","text":"<p>Open: - <code>out/traffic_phase/artifact_2_active_set.csv</code></p> <p>Each row has: - <code>rho_global_post</code> = global share after compression - <code>rho_local_pre</code> / <code>rho_local_post</code> = within-intersection shares (before/after tau filtering) - <code>value</code> = the raw count in that element</p>"},{"location":"traffic_phase_worked_example/#61-example-a-minorodd-dominant-intersection","title":"6.1 Example: a MinorOdd-dominant intersection","text":"<p>For <code>TCS=619</code> (top-ranked by global mass), the retained elements are:</p> Element Count Local share MinorOdd(1,3,5,7) 314 0.8486 MajorEven(2,4,6,8) 56 0.1514 <p>That\u2019s a strong signature: this intersection is minor-phase heavy compared to the global baseline (where MinorOdd is ~16.9%).</p>"},{"location":"traffic_phase_worked_example/#62-example-an-other-heavy-intersection","title":"6.2 Example: an Other-heavy intersection","text":"<p>For <code>TCS=175</code>, the signature is split evenly between MajorEven and Other:</p> Element Count Local share MajorEven(2,4,6,8) 84 0.5000 Other(9-12) 84 0.5000 <p>\u201cOther(9-12)\u201d is only ~1.2% globally, so 50% is a major outlier worth inspecting.</p>"},{"location":"traffic_phase_worked_example/#63-outlier-list-use-this-as-a-reading-guide","title":"6.3 Outlier list (use this as a reading guide)","text":"<p>Most MinorOdd-heavy intersections (top 10, shipped snapshot):</p> TCS Total rows MajorEven MinorOdd Other MinorOdd share 619 370 56 314 0 0.8486 142 68 20 48 0 0.7059 747 70 21 49 0 0.7000 318 64 20 44 0 0.6875 868 105 34 71 0 0.6762 875 78 26 52 0 0.6667 694 80 27 53 0 0.6625 746 40 14 26 0 0.6500 912 93 33 60 0 0.6452 751 111 40 71 0 0.6396 <p>Most Other-heavy intersections (top 10, shipped snapshot):</p> TCS Total rows MajorEven MinorOdd Other Other share 175 168 84 0 84 0.5000 841 126 71 10 45 0.3571 284 71 46 0 25 0.3521 282 92 51 12 29 0.3152 931 132 78 16 38 0.2879 303 115 66 16 33 0.2870 137 162 85 31 46 0.2840 896 67 43 5 19 0.2836 25 167 90 33 44 0.2635 948 146 74 34 38 0.2603 <p>This is the kind of \u201cneedle list\u201d most dashboards don\u2019t give you for free.</p>"},{"location":"traffic_phase_worked_example/#7-what-tau-did-here-and-why-its-safe","title":"7) What tau did here (and why it\u2019s safe)","text":"<p>This case uses local tau (default <code>--tau-local 0.05</code>): - inside each <code>TCS</code>, drop bands below 5% of that intersection\u2019s mass - renormalize the remainder to unity</p> <p>For the shipped snapshot: - input elements (TCS \u00d7 band): 1338 - retained elements: 1312 - dropped elements: 26 - global dropped budget: 0.0010013 (\u2248 0.10%) = 67 rows</p> <p>So tau is doing surgical cleanup (tiny tails), not rewriting the story.</p> <p>If you want the stability proof, open: - <code>out/traffic_phase/stability_packet.csv</code></p> <p>Example (shipped snapshot):</p> tau active_count discarded_budget_global jaccard_vs_baseline 0.02 1335 0.000045 1.0000 0.03 1327 0.000269 0.9940 0.05 1312 0.001001 0.9828 0.07 1298 0.002077 0.9723 0.10 1268 0.005305 0.9498 <p>Takeaway: you can raise/lower tau, and the ordering stays stable, while you trade off a little more discard for a cleaner signature.</p>"},{"location":"traffic_phase_worked_example/#8-provenance-show-me-the-chain","title":"8) Provenance: \u201cshow me the chain\u201d","text":"<p>Open: - <code>out/traffic_phase/artifact_3_trace_report.jsonl</code></p> <p>Each retained item includes: - <code>item_id</code> (e.g., <code>TCS=619/band=MinorOdd(1,3,5,7)</code>)  - <code>regime_path</code> (Global \u2192 TCS \u2192 band) - <code>inputs_ref</code> (file fingerprint) - <code>method_ref</code> (finite-element mapping statement)</p> <p>This is how you keep the analysis auditable when you change thresholds.</p>"},{"location":"traffic_phase_worked_example/#9-next-steps","title":"9) Next steps","text":"<ul> <li> <p>Want a diagnostic lens on a specific status? Use the next case:   \ud83d\udc49 <code>huf traffic-anomaly ... --status \"Green Termination\"</code></p> </li> <li> <p>Want to see more / less structure?</p> </li> <li>lower tau: <code>--tau-local 0.03</code></li> <li> <p>raise tau: <code>--tau-local 0.07</code></p> </li> <li> <p>Want to build your own \u201coutlier report\u201d?   Use <code>artifact_2_active_set.csv</code> as the authoritative retained set, and join to your own intersection metadata.</p> </li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Updated: 2026-02-17</p> <p>This page collects the common \u201cWindows reality\u201d problems people hit when they\u2019re new to Python tooling.</p>"},{"location":"troubleshooting/#1-venv-exists-but-commands-run-the-wrong-python","title":"1) \u201c.venv exists but commands run the wrong Python\u201d","text":"<p>If you see paths like <code>miniconda3\\Scripts\\huf.exe</code>, you\u2019re running a global install, not the repo venv.</p> <p>Use the venv explicitly:</p> <pre><code>.\\.venv\\Scripts\\python -V\n.\\.venv\\Scripts\\huf --help\n</code></pre>"},{"location":"troubleshooting/#2-ssl-certificate-errors-certificate_verify_failed","title":"2) SSL certificate errors (CERTIFICATE_VERIFY_FAILED)","text":"<p>Symptoms: - <code>ssl.SSLCertVerificationError: certificate verify failed</code></p> <p>Fix: <pre><code>.\\.venv\\Scripts\\python -m pip install certifi\n.\\.venv\\Scripts\\python scripts\\fetch_data.py --toronto --yes\n</code></pre></p> <p>If you are on a corporate network or behind a TLS-inspecting proxy, you may need to: - download the dataset ZIP manually in a browser, then place the resulting CSV into the expected <code>cases\\...\\inputs\\</code> folders</p>"},{"location":"troubleshooting/#3-toronto-fetch-gets-http-404","title":"3) Toronto fetch gets HTTP 404","text":"<p>Use the default CKAN base:</p> <ul> <li><code>https://open.toronto.ca/api/3/action</code></li> </ul> <p>Explicit override:</p> <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --toronto --yes --toronto-ckan https://open.toronto.ca/api/3/action\n</code></pre>"},{"location":"troubleshooting/#4-the-windows-starter-bat-prints-weird-characters","title":"4) The Windows starter <code>.bat</code> prints weird characters","text":"<p>If you see \u201c\u0393\u00a3\u00e0\u201d or similar, that\u2019s just a console encoding mismatch. It does not affect the run.</p> <p>If you edited the <code>.bat</code> file, save it as: - ANSI or UTF-8 (not UTF-16) - with normal Windows line endings</p>"},{"location":"troubleshooting/#5-file-not-found-for-case-inputs","title":"5) \u201cFile not found\u201d for case inputs","text":"<p>Run fetch first:</p> <pre><code>.\\.venv\\Scripts\\python scripts\\fetch_data.py --markham --toronto --yes\n</code></pre> <p>Then run the case commands.</p>"},{"location":"vector_db_coherence/","title":"Vector DB coherence (from retrieval results)","text":"<p>This is a small adapter that turns vector retrieval results into a HUF run so you can audit: - which groups/\u201cregimes\u201d dominate the result set, - which items are retained vs discarded (and why), - how much probability mass lives in the long tail.</p> <p>It does not require a live vector database. You provide a JSONL export of results.</p>"},{"location":"vector_db_coherence/#input-format-jsonl","title":"Input format (JSONL)","text":"<p>One JSON object per line:</p> <pre><code>{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n</code></pre> <p>Required fields: - <code>id</code> (string): unique item id - <code>score</code> (number): similarity / relevance score (higher = better)</p> <p>Optional fields: - any grouping field you want to treat as a \u201cregime\u201d, e.g. <code>namespace</code>, <code>collection</code>, <code>source</code></p>"},{"location":"vector_db_coherence/#run-windows-powershell","title":"Run (Windows PowerShell)","text":"<p>PowerShell note: use backticks for line continuation (not <code>\\</code>).</p> <pre><code>$py  = \".\\.venv\\Scripts\\python.exe\"\n$in  = \"cases\\vector_db\\inputs\\retrieval.jsonl\"\n$out = \"out\\vector_db_demo\"\n\nNew-Item -ItemType Directory -Force (Split-Path $in) | Out-Null\nNew-Item -ItemType Directory -Force $out             | Out-Null\n\n@'\n{\"id\":\"doc_001\",\"score\":0.82,\"namespace\":\"kb\",\"source\":\"handbook\"}\n{\"id\":\"doc_002\",\"score\":0.63,\"namespace\":\"kb\",\"source\":\"manual\"}\n{\"id\":\"doc_101\",\"score\":0.77,\"namespace\":\"tickets\",\"source\":\"ops\"}\n{\"id\":\"doc_102\",\"score\":0.12,\"namespace\":\"tickets\",\"source\":\"ops\"}\n'@ | Set-Content -Encoding utf8 $in\n\n&amp; $py examples\\run_vector_db_demo.py `\n  --in  $in `\n  --out $out `\n  --tau-global 0.02 `\n  --regime-field namespace\n\ndir $out\n</code></pre> <p>If you see: <code>Unexpected UTF-8 BOM ...</code> That means the file has a UTF-8 BOM. Either: - keep the adapter BOM-tolerant (recommended), or - rewrite the file without BOM:</p> <pre><code>$content = Get-Content $in -Raw\n[System.IO.File]::WriteAllText($in, $content, (New-Object System.Text.UTF8Encoding($false)))\n</code></pre>"},{"location":"vector_db_coherence/#run-maclinux","title":"Run (Mac/Linux)","text":"<pre><code>python examples/run_vector_db_demo.py   --in  cases/vector_db/inputs/retrieval.jsonl   --out out/vector_db_demo   --tau-global 0.02   --regime-field namespace\n</code></pre>"},{"location":"vector_db_coherence/#what-to-open-first-artifacts","title":"What to open first (artifacts)","text":"<p>In <code>out/vector_db_demo/</code>:</p> <ol> <li> <p><code>artifact_1_coherence_map.csv</code>    \u201cWhich regimes dominate?\u201d (sorted by <code>rho_global_post</code>)</p> </li> <li> <p><code>artifact_2_active_set.csv</code>    The retained items with global + local shares (<code>rho_*</code>)</p> </li> <li> <p><code>artifact_3_trace_report.jsonl</code>    Per-item reasoning: pre/post mass, exclusions, ranks</p> </li> </ol> <p>Tip: For quick inspection without notebooks, use the helper script (if present):</p> <pre><code>.\\.venv\\Scripts\\python scripts\\inspect_vector_db_artifacts.py --out out\\vector_db_demo\n</code></pre>"},{"location":"docs/data_sources/","title":"Data Sources &amp; Fetching (legacy path)","text":"<p>This page exists to keep old links working.</p> <p>Go here instead: Data Sources &amp; Fetching</p>"},{"location":"docs/get_started_zero_github/","title":"Start Here (Zero GitHub Knowledge) (moved)","text":"<p>This URL is kept for older links.</p> <p>The canonical page is now:</p> <ul> <li>Start Here (Zero GitHub Knowledge)</li> </ul>"}]}